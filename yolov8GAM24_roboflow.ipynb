{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21031fc5-5fee-40f3-92b2-c7f38b091dc8",
   "metadata": {},
   "source": [
    "# Install the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d72021-e41b-4d09-9c3b-89036ee6d9b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete. Using torch 1.12.1+cu113 _CudaDeviceProperties(name='Quadro RTX 4000', major=7, minor=5, total_memory=7982MB, multi_processor_count=36)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import shutil\n",
    "from codecarbon import OfflineEmissionsTracker\n",
    "import torch\n",
    "pathInicial=os.getcwd() \n",
    "os.chdir(\"yolov8\")\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f3f5b-bac5-4c91-8315-d6a56ee2734a",
   "metadata": {},
   "source": [
    "# We load the roboflow data of the wheelchair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4ebc8c-b0f1-418b-b7a6-bd27993b45d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good,Â¡The data is already load!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(\"wheelchair-detection-1\"):\n",
    "    from roboflow import Roboflow\n",
    "    rf = Roboflow(api_key=\"GTFcmyUsIPX2cUOUUP8y\")\n",
    "    project = rf.workspace(\"2458761304-qq-com\").project(\"wheelchair-detection\")\n",
    "    dataset = project.version(1).download(\"yolov5\")\n",
    "else:\n",
    "    print(\"Good,Â¡The data is already load!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c7361-f844-485a-aad2-155c10556d96",
   "metadata": {},
   "source": [
    "# Decide if training with the full train dataset or if reducing dataset\n",
    "\n",
    "You must select one of the possible methods:\n",
    "\n",
    "- NONE\n",
    "- SRS\n",
    "- DES\n",
    "- MMS\n",
    "- NRMD\n",
    "- RKM\n",
    "- PHL\n",
    "- PRD\n",
    "- FES\n",
    "\n",
    "You must select a reduction rate, for example if you want a reduction rate of 75%, you have to insert 0.25 in perc, that is to remain only with the 25% of full data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d30b479-2d2a-4b97-a40e-5019925c39f2",
   "metadata": {},
   "source": [
    "First, we are going to create a neural network with all the train data and then one with a subset of the 50% of the data.\n",
    "\n",
    "## Train with full train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2d4113d-8ba6-4da6-b7c3-f30b2dbb6df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 11:10:51.749187: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-11 11:10:51.764573: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-11 11:10:51.769040: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "You have not selected any method, so you are going to train with the complete training set.\n",
      "Number Original Files: 463\n",
      "The training set has a size of:  463\n"
     ]
    }
   ],
   "source": [
    "os.chdir(pathInicial)\n",
    "method = \"NONE\"\n",
    "perc=0.25\n",
    "!python ReductionDatasetRoboflow_yolov8.py --name {method} --perc {perc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514cee79-e1ee-47ad-8b14-7c0d45437102",
   "metadata": {},
   "source": [
    "We updated the data yaml, in order to correctly run the training and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a0f714-2d2a-4ab7-acb0-67efc8587fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"yolov8\")\n",
    "\n",
    "import yaml\n",
    "with open(\"wheelchair-detection-1\" + \"/data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])\n",
    "\n",
    "#customize iPython writefile so we can write variables\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a0bb8a0-1052-4b2d-9d07-bc27c3ec7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writetemplate wheelchair-detection-1/data.yaml\n",
    "names:\n",
    "- people\n",
    "- peopleWithWheelchair\n",
    "nc: 2\n",
    "roboflow:\n",
    "  license: CC BY 4.0\n",
    "  project: wheelchair-detection\n",
    "  url: https://universe.roboflow.com/2458761304-qq-com/wheelchair-detection/dataset/1\n",
    "  version: 1\n",
    "  workspace: 2458761304-qq-com\n",
    "path: wheelchair-detection-1/\n",
    "test: test/images\n",
    "train: train/images\n",
    "val: test/images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca524b-6f55-4f1f-9b15-4a6c793a9e96",
   "metadata": {},
   "source": [
    "#  We train YOLOV8 on our reduced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d37971-cfb7-468f-9806-a2091b87c3fc",
   "metadata": {},
   "source": [
    "Descargamos modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c23d403-3ae6-419b-8689-b4b1e0f5f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(pathInicial + '/yolov8')\n",
    "model = YOLO(\"yolov8m.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b1291f-4181-4330-a3dd-851d59cbaa57",
   "metadata": {},
   "source": [
    "Congelamos 10 capas iniciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf8ce62b-8ec3-4eca-bdce-a27f9054ba16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.model.0.conv.weight False\n",
      "model.model.0.bn.weight False\n",
      "model.model.0.bn.bias False\n",
      "model.model.1.conv.weight False\n",
      "model.model.1.bn.weight False\n",
      "model.model.1.bn.bias False\n",
      "model.model.2.cv1.conv.weight False\n",
      "model.model.2.cv1.bn.weight False\n",
      "model.model.2.cv1.bn.bias False\n",
      "model.model.2.cv2.conv.weight False\n",
      "model.model.2.cv2.bn.weight False\n",
      "model.model.2.cv2.bn.bias False\n",
      "model.model.2.m.0.cv1.conv.weight False\n",
      "model.model.2.m.0.cv1.bn.weight False\n",
      "model.model.2.m.0.cv1.bn.bias False\n",
      "model.model.2.m.0.cv2.conv.weight False\n",
      "model.model.2.m.0.cv2.bn.weight False\n",
      "model.model.2.m.0.cv2.bn.bias False\n",
      "model.model.2.m.1.cv1.conv.weight False\n",
      "model.model.2.m.1.cv1.bn.weight False\n",
      "model.model.2.m.1.cv1.bn.bias False\n",
      "model.model.2.m.1.cv2.conv.weight False\n",
      "model.model.2.m.1.cv2.bn.weight False\n",
      "model.model.2.m.1.cv2.bn.bias False\n",
      "model.model.3.conv.weight False\n",
      "model.model.3.bn.weight False\n",
      "model.model.3.bn.bias False\n",
      "model.model.4.cv1.conv.weight False\n",
      "model.model.4.cv1.bn.weight False\n",
      "model.model.4.cv1.bn.bias False\n",
      "model.model.4.cv2.conv.weight False\n",
      "model.model.4.cv2.bn.weight False\n",
      "model.model.4.cv2.bn.bias False\n",
      "model.model.4.m.0.cv1.conv.weight False\n",
      "model.model.4.m.0.cv1.bn.weight False\n",
      "model.model.4.m.0.cv1.bn.bias False\n",
      "model.model.4.m.0.cv2.conv.weight False\n",
      "model.model.4.m.0.cv2.bn.weight False\n",
      "model.model.4.m.0.cv2.bn.bias False\n",
      "model.model.4.m.1.cv1.conv.weight False\n",
      "model.model.4.m.1.cv1.bn.weight False\n",
      "model.model.4.m.1.cv1.bn.bias False\n",
      "model.model.4.m.1.cv2.conv.weight False\n",
      "model.model.4.m.1.cv2.bn.weight False\n",
      "model.model.4.m.1.cv2.bn.bias False\n",
      "model.model.4.m.2.cv1.conv.weight False\n",
      "model.model.4.m.2.cv1.bn.weight False\n",
      "model.model.4.m.2.cv1.bn.bias False\n",
      "model.model.4.m.2.cv2.conv.weight False\n",
      "model.model.4.m.2.cv2.bn.weight False\n",
      "model.model.4.m.2.cv2.bn.bias False\n",
      "model.model.4.m.3.cv1.conv.weight False\n",
      "model.model.4.m.3.cv1.bn.weight False\n",
      "model.model.4.m.3.cv1.bn.bias False\n",
      "model.model.4.m.3.cv2.conv.weight False\n",
      "model.model.4.m.3.cv2.bn.weight False\n",
      "model.model.4.m.3.cv2.bn.bias False\n",
      "model.model.5.conv.weight False\n",
      "model.model.5.bn.weight False\n",
      "model.model.5.bn.bias False\n",
      "model.model.6.cv1.conv.weight False\n",
      "model.model.6.cv1.bn.weight False\n",
      "model.model.6.cv1.bn.bias False\n",
      "model.model.6.cv2.conv.weight False\n",
      "model.model.6.cv2.bn.weight False\n",
      "model.model.6.cv2.bn.bias False\n",
      "model.model.6.m.0.cv1.conv.weight False\n",
      "model.model.6.m.0.cv1.bn.weight False\n",
      "model.model.6.m.0.cv1.bn.bias False\n",
      "model.model.6.m.0.cv2.conv.weight False\n",
      "model.model.6.m.0.cv2.bn.weight False\n",
      "model.model.6.m.0.cv2.bn.bias False\n",
      "model.model.6.m.1.cv1.conv.weight False\n",
      "model.model.6.m.1.cv1.bn.weight False\n",
      "model.model.6.m.1.cv1.bn.bias False\n",
      "model.model.6.m.1.cv2.conv.weight False\n",
      "model.model.6.m.1.cv2.bn.weight False\n",
      "model.model.6.m.1.cv2.bn.bias False\n",
      "model.model.6.m.2.cv1.conv.weight False\n",
      "model.model.6.m.2.cv1.bn.weight False\n",
      "model.model.6.m.2.cv1.bn.bias False\n",
      "model.model.6.m.2.cv2.conv.weight False\n",
      "model.model.6.m.2.cv2.bn.weight False\n",
      "model.model.6.m.2.cv2.bn.bias False\n",
      "model.model.6.m.3.cv1.conv.weight False\n",
      "model.model.6.m.3.cv1.bn.weight False\n",
      "model.model.6.m.3.cv1.bn.bias False\n",
      "model.model.6.m.3.cv2.conv.weight False\n",
      "model.model.6.m.3.cv2.bn.weight False\n",
      "model.model.6.m.3.cv2.bn.bias False\n",
      "model.model.7.conv.weight False\n",
      "model.model.7.bn.weight False\n",
      "model.model.7.bn.bias False\n",
      "model.model.8.cv1.conv.weight False\n",
      "model.model.8.cv1.bn.weight False\n",
      "model.model.8.cv1.bn.bias False\n",
      "model.model.8.cv2.conv.weight False\n",
      "model.model.8.cv2.bn.weight False\n",
      "model.model.8.cv2.bn.bias False\n",
      "model.model.8.m.0.cv1.conv.weight False\n",
      "model.model.8.m.0.cv1.bn.weight False\n",
      "model.model.8.m.0.cv1.bn.bias False\n",
      "model.model.8.m.0.cv2.conv.weight False\n",
      "model.model.8.m.0.cv2.bn.weight False\n",
      "model.model.8.m.0.cv2.bn.bias False\n",
      "model.model.8.m.1.cv1.conv.weight False\n",
      "model.model.8.m.1.cv1.bn.weight False\n",
      "model.model.8.m.1.cv1.bn.bias False\n",
      "model.model.8.m.1.cv2.conv.weight False\n",
      "model.model.8.m.1.cv2.bn.weight False\n",
      "model.model.8.m.1.cv2.bn.bias False\n",
      "model.model.9.cv1.conv.weight False\n",
      "model.model.9.cv1.bn.weight False\n",
      "model.model.9.cv1.bn.bias False\n",
      "model.model.9.cv2.conv.weight False\n",
      "model.model.9.cv2.bn.weight False\n",
      "model.model.9.cv2.bn.bias False\n",
      "model.model.12.cv1.conv.weight True\n",
      "model.model.12.cv1.bn.weight True\n",
      "model.model.12.cv1.bn.bias True\n",
      "model.model.12.cv2.conv.weight True\n",
      "model.model.12.cv2.bn.weight True\n",
      "model.model.12.cv2.bn.bias True\n",
      "model.model.12.m.0.cv1.conv.weight True\n",
      "model.model.12.m.0.cv1.bn.weight True\n",
      "model.model.12.m.0.cv1.bn.bias True\n",
      "model.model.12.m.0.cv2.conv.weight True\n",
      "model.model.12.m.0.cv2.bn.weight True\n",
      "model.model.12.m.0.cv2.bn.bias True\n",
      "model.model.12.m.1.cv1.conv.weight True\n",
      "model.model.12.m.1.cv1.bn.weight True\n",
      "model.model.12.m.1.cv1.bn.bias True\n",
      "model.model.12.m.1.cv2.conv.weight True\n",
      "model.model.12.m.1.cv2.bn.weight True\n",
      "model.model.12.m.1.cv2.bn.bias True\n",
      "model.model.15.cv1.conv.weight True\n",
      "model.model.15.cv1.bn.weight True\n",
      "model.model.15.cv1.bn.bias True\n",
      "model.model.15.cv2.conv.weight True\n",
      "model.model.15.cv2.bn.weight True\n",
      "model.model.15.cv2.bn.bias True\n",
      "model.model.15.m.0.cv1.conv.weight True\n",
      "model.model.15.m.0.cv1.bn.weight True\n",
      "model.model.15.m.0.cv1.bn.bias True\n",
      "model.model.15.m.0.cv2.conv.weight True\n",
      "model.model.15.m.0.cv2.bn.weight True\n",
      "model.model.15.m.0.cv2.bn.bias True\n",
      "model.model.15.m.1.cv1.conv.weight True\n",
      "model.model.15.m.1.cv1.bn.weight True\n",
      "model.model.15.m.1.cv1.bn.bias True\n",
      "model.model.15.m.1.cv2.conv.weight True\n",
      "model.model.15.m.1.cv2.bn.weight True\n",
      "model.model.15.m.1.cv2.bn.bias True\n",
      "model.model.16.conv.weight True\n",
      "model.model.16.bn.weight True\n",
      "model.model.16.bn.bias True\n",
      "model.model.18.cv1.conv.weight True\n",
      "model.model.18.cv1.bn.weight True\n",
      "model.model.18.cv1.bn.bias True\n",
      "model.model.18.cv2.conv.weight True\n",
      "model.model.18.cv2.bn.weight True\n",
      "model.model.18.cv2.bn.bias True\n",
      "model.model.18.m.0.cv1.conv.weight True\n",
      "model.model.18.m.0.cv1.bn.weight True\n",
      "model.model.18.m.0.cv1.bn.bias True\n",
      "model.model.18.m.0.cv2.conv.weight True\n",
      "model.model.18.m.0.cv2.bn.weight True\n",
      "model.model.18.m.0.cv2.bn.bias True\n",
      "model.model.18.m.1.cv1.conv.weight True\n",
      "model.model.18.m.1.cv1.bn.weight True\n",
      "model.model.18.m.1.cv1.bn.bias True\n",
      "model.model.18.m.1.cv2.conv.weight True\n",
      "model.model.18.m.1.cv2.bn.weight True\n",
      "model.model.18.m.1.cv2.bn.bias True\n",
      "model.model.19.conv.weight True\n",
      "model.model.19.bn.weight True\n",
      "model.model.19.bn.bias True\n",
      "model.model.21.cv1.conv.weight True\n",
      "model.model.21.cv1.bn.weight True\n",
      "model.model.21.cv1.bn.bias True\n",
      "model.model.21.cv2.conv.weight True\n",
      "model.model.21.cv2.bn.weight True\n",
      "model.model.21.cv2.bn.bias True\n",
      "model.model.21.m.0.cv1.conv.weight True\n",
      "model.model.21.m.0.cv1.bn.weight True\n",
      "model.model.21.m.0.cv1.bn.bias True\n",
      "model.model.21.m.0.cv2.conv.weight True\n",
      "model.model.21.m.0.cv2.bn.weight True\n",
      "model.model.21.m.0.cv2.bn.bias True\n",
      "model.model.21.m.1.cv1.conv.weight True\n",
      "model.model.21.m.1.cv1.bn.weight True\n",
      "model.model.21.m.1.cv1.bn.bias True\n",
      "model.model.21.m.1.cv2.conv.weight True\n",
      "model.model.21.m.1.cv2.bn.weight True\n",
      "model.model.21.m.1.cv2.bn.bias True\n",
      "model.model.22.cv2.0.0.conv.weight True\n",
      "model.model.22.cv2.0.0.bn.weight True\n",
      "model.model.22.cv2.0.0.bn.bias True\n",
      "model.model.22.cv2.0.1.conv.weight True\n",
      "model.model.22.cv2.0.1.bn.weight True\n",
      "model.model.22.cv2.0.1.bn.bias True\n",
      "model.model.22.cv2.0.2.weight True\n",
      "model.model.22.cv2.0.2.bias True\n",
      "model.model.22.cv2.1.0.conv.weight True\n",
      "model.model.22.cv2.1.0.bn.weight True\n",
      "model.model.22.cv2.1.0.bn.bias True\n",
      "model.model.22.cv2.1.1.conv.weight True\n",
      "model.model.22.cv2.1.1.bn.weight True\n",
      "model.model.22.cv2.1.1.bn.bias True\n",
      "model.model.22.cv2.1.2.weight True\n",
      "model.model.22.cv2.1.2.bias True\n",
      "model.model.22.cv2.2.0.conv.weight True\n",
      "model.model.22.cv2.2.0.bn.weight True\n",
      "model.model.22.cv2.2.0.bn.bias True\n",
      "model.model.22.cv2.2.1.conv.weight True\n",
      "model.model.22.cv2.2.1.bn.weight True\n",
      "model.model.22.cv2.2.1.bn.bias True\n",
      "model.model.22.cv2.2.2.weight True\n",
      "model.model.22.cv2.2.2.bias True\n",
      "model.model.22.cv3.0.0.conv.weight True\n",
      "model.model.22.cv3.0.0.bn.weight True\n",
      "model.model.22.cv3.0.0.bn.bias True\n",
      "model.model.22.cv3.0.1.conv.weight True\n",
      "model.model.22.cv3.0.1.bn.weight True\n",
      "model.model.22.cv3.0.1.bn.bias True\n",
      "model.model.22.cv3.0.2.weight True\n",
      "model.model.22.cv3.0.2.bias True\n",
      "model.model.22.cv3.1.0.conv.weight True\n",
      "model.model.22.cv3.1.0.bn.weight True\n",
      "model.model.22.cv3.1.0.bn.bias True\n",
      "model.model.22.cv3.1.1.conv.weight True\n",
      "model.model.22.cv3.1.1.bn.weight True\n",
      "model.model.22.cv3.1.1.bn.bias True\n",
      "model.model.22.cv3.1.2.weight True\n",
      "model.model.22.cv3.1.2.bias True\n",
      "model.model.22.cv3.2.0.conv.weight True\n",
      "model.model.22.cv3.2.0.bn.weight True\n",
      "model.model.22.cv3.2.0.bn.bias True\n",
      "model.model.22.cv3.2.1.conv.weight True\n",
      "model.model.22.cv3.2.1.bn.weight True\n",
      "model.model.22.cv3.2.1.bn.bias True\n",
      "model.model.22.cv3.2.2.weight True\n",
      "model.model.22.cv3.2.2.bias True\n",
      "model.model.22.dfl.conv.weight True\n"
     ]
    }
   ],
   "source": [
    "freeze = 10\n",
    "freeze = [f'model.{x}.' for x in range(freeze)]  \n",
    "for k, v in model.named_parameters(): \n",
    "    v.requires_grad = True # train all layers \n",
    "    if any(x in k for x in freeze): \n",
    "      v.requires_grad = False\n",
    "    print(k, v.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b17c5-8071-4e06-8a11-ec227f199e38",
   "metadata": {},
   "source": [
    "Entrenamos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c20e48d5-cb73-4ee8-adcd-48f96a88664b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.91 ðŸš€ Python-3.9.19 torch-1.12.1+cu113 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "WARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=wheelchair-detection-1/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train_yolov8_roboflow_GAM24_fullTrainSet3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train_yolov8_roboflow_GAM24_fullTrainSet3\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train_yolov8_roboflow_GAM24_fullTrainSet3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096842b9f8ad446cb3b699caf94ca2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/6.25M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/vtoscano/VToscano/GA_M24/yolov8/wheelchair-detection-1/train/labels... 463 images, 0 backgrounds, \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/vtoscano/VToscano/GA_M24/yolov8/wheelchair-detection-1/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/vtoscano/VToscano/GA_M24/yolov8/wheelchair-detection-1/test/labels... 51 images, 0 backgrounds, 0 co\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/vtoscano/VToscano/GA_M24/yolov8/wheelchair-detection-1/test/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train_yolov8_roboflow_GAM24_fullTrainSet3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train_yolov8_roboflow_GAM24_fullTrainSet3\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      7.16G      1.343      2.116      1.614         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.418      0.741      0.392      0.209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      7.05G      1.428      1.687      1.668         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120     0.0544      0.497     0.0405     0.0134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      7.03G      1.603      1.791      1.812         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120   0.000161     0.0168    8.2e-05   1.64e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      7.03G      1.665      1.899      1.828         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120    0.00132     0.0503   0.000517   0.000113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100         7G      1.593      1.839      1.791         84        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120     0.0593      0.278     0.0517     0.0166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      7.03G      1.576       1.74      1.774         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.431      0.317      0.273        0.1\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100         7G      1.485      1.649      1.718         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.368      0.446      0.362      0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100         7G      1.516      1.598      1.731         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.283      0.484      0.306       0.12\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100         7G      1.488      1.603      1.693         85        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.605      0.567      0.601      0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      7.03G       1.49      1.579      1.689         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.641      0.583      0.569       0.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100         7G      1.415      1.481      1.629         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.566      0.709      0.655      0.357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100         7G      1.377      1.423      1.604         96        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.501      0.522      0.515      0.282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100       6.9G      1.321      1.404       1.58         82        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.582      0.635      0.624      0.322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      6.99G      1.356      1.384      1.579         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.694      0.648      0.685      0.392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100         7G      1.299      1.332       1.54        151        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.685      0.709      0.705      0.417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      7.02G      1.292      1.301      1.536         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.757      0.711      0.759      0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100         7G      1.331      1.314      1.564         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.696      0.675      0.733      0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100         7G      1.261      1.259      1.523         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.851      0.734      0.812      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      7.03G      1.235      1.232      1.502         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.783      0.689      0.773      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      7.03G      1.232      1.264        1.5         85        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120       0.82      0.666      0.738       0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100         7G       1.23      1.232      1.517         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.752      0.875      0.848      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100         7G      1.173      1.164      1.453         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.923       0.77      0.889      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      7.02G        1.2       1.17      1.486         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.683       0.76      0.787       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      7.02G      1.214      1.196       1.47         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.761      0.734      0.801      0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100         7G      1.196      1.146      1.471         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.834      0.741      0.807       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      7.04G       1.17      1.134      1.453         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.763      0.792      0.823      0.518\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      7.03G      1.168      1.119      1.447         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.785      0.825      0.835      0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      7.03G       1.12      1.056      1.424         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.837      0.715      0.809       0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100         7G      1.126      1.064      1.427         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.897      0.834      0.904      0.562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      7.15G      1.177      1.112      1.442         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.854       0.83      0.858      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      7.03G      1.153      1.078      1.436         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.932      0.756      0.859      0.511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      7.01G      1.151      1.068      1.439         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120       0.95       0.74      0.882      0.569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      7.07G      1.134      1.034      1.415         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.847      0.811      0.873      0.552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      7.03G      1.103      1.055      1.399         75        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.904      0.842      0.894      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      7.03G      1.091      1.001      1.384         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.887      0.739      0.854      0.532\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      7.03G      1.082      1.007      1.393         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.807      0.774      0.828      0.528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      7.02G      1.051      0.952      1.364         85        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.844      0.836      0.865      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      7.16G      1.064     0.9563      1.373         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120       0.88        0.8      0.869      0.533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100         7G      1.043     0.9983      1.366         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.884      0.818      0.877      0.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      6.88G      1.039     0.9402      1.343         91        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.847      0.825      0.857       0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      7.03G      1.058     0.9274      1.355         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.903      0.773      0.898       0.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      6.93G       1.05      0.953      1.348         90        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.865      0.804      0.866      0.568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      7.02G       1.01     0.8965      1.323         65        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.937       0.79      0.878      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100         7G      1.016     0.8864      1.331         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.872      0.789      0.883      0.567\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100         7G     0.9991     0.9172      1.345        101        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.869      0.787      0.866      0.575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      7.03G     0.9731     0.8795      1.316         85        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.811      0.822      0.881      0.577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100         7G     0.9768     0.8761      1.305         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.872      0.829       0.88      0.589\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100         7G     0.9738     0.8666      1.296         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.895      0.842      0.892      0.607\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      7.02G      1.027     0.8836      1.343         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.883      0.829      0.884      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      7.02G     0.9894     0.8685      1.304         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.923      0.778      0.886      0.579\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100         7G     0.9654      0.826      1.308         79        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.857      0.763      0.855      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100         7G      0.968     0.8418      1.313         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.848      0.836      0.877      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      7.02G      0.954     0.8512      1.296         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.853      0.815      0.881      0.579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      7.02G       0.95     0.8425      1.302         73        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.838      0.819       0.88      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      7.05G     0.9682     0.8418      1.307         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.854      0.822      0.883      0.594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      7.03G     0.9334     0.8006      1.282         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.869      0.851      0.881      0.606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      7.02G     0.9528     0.8074      1.284         81        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.879      0.869      0.905      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      6.99G     0.9195     0.8016      1.264         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.933        0.8      0.903      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      7.03G     0.8769     0.7686       1.26         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.848      0.841      0.897      0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      7.03G     0.9059     0.7829      1.273         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120        0.8      0.881      0.896      0.595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      7.06G     0.9091     0.7819      1.263         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.916      0.851      0.944      0.635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100         7G     0.8808     0.7585      1.244         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.885      0.834       0.92      0.617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100         7G     0.8761     0.7578      1.241         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.932      0.831      0.915      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      7.03G     0.8517      0.751      1.234         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.938      0.787      0.897      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100         7G      0.884     0.7404      1.249         77        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.911      0.842      0.918      0.618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      7.02G     0.8312     0.7247       1.21         68        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.927      0.812        0.9        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      7.03G     0.8408     0.6989       1.22         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.933      0.878      0.926      0.615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      7.02G     0.8394      0.715       1.22         83        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.894       0.87      0.912      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100         7G     0.8689     0.7347      1.244         86        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.934      0.857      0.919      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      7.03G     0.7893     0.6826      1.196         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120       0.91      0.833      0.911      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100         7G     0.8196       0.71      1.203         63        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.952      0.781      0.893      0.617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      7.03G     0.8221     0.6839      1.216         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.914       0.84      0.896      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      7.03G     0.8116      0.697      1.202         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.913      0.848      0.911      0.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      7.03G     0.8243     0.6789      1.195         74        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.914      0.828      0.909      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      7.16G     0.8007     0.6959      1.193         70        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.957       0.84      0.928      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100         7G      0.785      0.663      1.197         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.963      0.831      0.918       0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100         7G     0.8067      0.697      1.213         72        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.991      0.801       0.91      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      7.03G     0.7852     0.6717      1.199         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.911      0.866       0.91      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100         7G     0.7705     0.6326      1.176         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.958      0.833      0.918      0.636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      7.02G     0.7685     0.6393      1.177         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.867      0.898      0.917       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      7.02G     0.7683     0.6178      1.181         88        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.836      0.895      0.908      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      6.98G     0.7405     0.6284      1.153         95        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.944      0.825      0.917      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      7.02G     0.7616      0.617      1.168         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.866      0.869       0.91      0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      6.99G     0.7582     0.6276      1.158         70        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.948      0.831      0.908      0.622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      7.07G     0.7168     0.6029       1.15         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.885      0.894       0.92      0.629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100         7G     0.7201     0.5995      1.144         78        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.968      0.824      0.918       0.64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      7.03G     0.7142     0.5932       1.15         98        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.964      0.847       0.91      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100         7G      0.716     0.5943      1.141         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.948      0.842      0.912      0.633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      7.03G     0.7025      0.592      1.146         69        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.892       0.89      0.924      0.635\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100         7G     0.6888     0.5964      1.132         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.921      0.885      0.921      0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      6.98G     0.5832      0.455      1.082         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:11<00:00,  2.6\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120       0.94      0.841      0.902      0.612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      6.98G     0.5691     0.4047      1.053         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.945      0.849       0.91      0.636\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      6.98G     0.5424     0.3902      1.019         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.938      0.842      0.907      0.627\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      6.98G     0.5373     0.3652      1.035         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.917      0.855      0.905       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      7.02G     0.5441     0.3901       1.04         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.907      0.843      0.905      0.631\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      7.15G     0.5312     0.3777      1.041         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.903      0.856      0.914      0.641\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100         7G     0.5031      0.359      1.007         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.944       0.85      0.918      0.641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      7.02G      0.503       0.36      1.009         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120       0.93      0.865      0.929       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      7.15G     0.4778     0.3463     0.9982         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.947      0.857      0.929      0.647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      6.98G     0.4953     0.3505      1.012         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29/29 [00:10<00:00,  2.7\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.924      0.859      0.927      0.649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.333 hours.\n",
      "Optimizer stripped from runs/detect/train_yolov8_roboflow_GAM24_fullTrainSet3/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from runs/detect/train_yolov8_roboflow_GAM24_fullTrainSet3/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating runs/detect/train_yolov8_roboflow_GAM24_fullTrainSet3/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.91 ðŸš€ Python-3.9.19 torch-1.12.1+cu113 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "Model summary (fused): 218 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120       0.93      0.864      0.929       0.65\n",
      "                people         27         55      0.935      0.786      0.889      0.524\n",
      "  peopleWithWheelchair         51         65      0.924      0.941       0.97      0.776\n",
      "Speed: 1.3ms preprocess, 9.7ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train_yolov8_roboflow_GAM24_fullTrainSet3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fcaa81b3880>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0070427,   0.0035214,           0],\n",
       "       [          1,           1,           1, ...,    0.043377,    0.021688,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.31902,     0.31902,     0.40618, ...,           0,           0,           0],\n",
       "       [    0.49805,     0.49805,     0.62171, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.19188,     0.19188,     0.25865, ...,           1,           1,           1],\n",
       "       [    0.33333,     0.33333,     0.45763, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.94545,     0.94545,     0.94545, ...,           0,           0,           0],\n",
       "       [    0.98462,     0.98462,     0.96923, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.6780304863134747\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.52423,     0.77601])\n",
       "names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9297820370630159, 'metrics/recall(B)': 0.8637191997040483, 'metrics/mAP50(B)': 0.9292168922666189, 'metrics/mAP50-95(B)': 0.6501208856520143, 'fitness': 0.6780304863134747}\n",
       "save_dir: PosixPath('runs/detect/train_yolov8_roboflow_GAM24_fullTrainSet3')\n",
       "speed: {'preprocess': 1.2787931105669808, 'inference': 9.670318341722675, 'loss': 0.00051423615100337, 'postprocess': 0.5562679440367455}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(data = \"wheelchair-detection-1/data.yaml\", batch=16, imgsz=640, epochs=100, name =\"train_yolov8_roboflow_GAM24_fullTrainSet\", seed = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2399f44a-d8a8-468c-b780-3f08d6e27b50",
   "metadata": {},
   "source": [
    "Cogemos el mejor modelo de los entrenados y validamos el modelo en el conjunto de test, no hace falta argumentos, ya que la configuraciÃ³n y el dataset son recordados de manera automÃ¡tica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23709098-b8f7-4c6a-aec2-c1b0df19dbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.91 ðŸš€ Python-3.9.19 torch-1.12.1+cu113 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "Model summary (fused): 218 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/vtoscano/VToscano/GA_M24/yolov8/wheelchair-detection-1/test/labels.cache... 51 images, 0 backgrounds\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120       0.93      0.865      0.929      0.652\n",
      "                people         27         55      0.935      0.789      0.888      0.525\n",
      "  peopleWithWheelchair         51         65      0.924      0.942       0.97      0.779\n",
      "Speed: 3.6ms preprocess, 16.1ms inference, 0.0ms loss, 4.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fcaee053970>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0070688,   0.0035344,           0],\n",
       "       [          1,           1,           1, ...,    0.043604,    0.021802,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[       0.32,        0.32,     0.40694, ...,           0,           0,           0],\n",
       "       [        0.5,         0.5,     0.62491, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.19259,     0.19259,     0.25926, ...,           1,           1,           1],\n",
       "       [    0.33508,     0.33508,      0.4611, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.94545,     0.94545,     0.94545, ...,           0,           0,           0],\n",
       "       [    0.98462,     0.98462,     0.96923, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.6798157593790507\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.52546,     0.77881])\n",
       "names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.929879589653364, 'metrics/recall(B)': 0.8650058571611714, 'metrics/mAP50(B)': 0.9289262327476051, 'metrics/mAP50-95(B)': 0.6521368178936557, 'fitness': 0.6798157593790507}\n",
       "save_dir: PosixPath('runs/detect/val')\n",
       "speed: {'preprocess': 3.5872646406585096, 'inference': 16.069552477668314, 'loss': 0.0008227778416053922, 'postprocess': 4.1757985657336665}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel = YOLO(\"runs/detect/train_yolov8_roboflow_GAM24_fullTrainSet/weights/best.pt\")\n",
    "\n",
    "bestmodel.val()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69891bd3-9296-4749-96eb-53984b56fb2b",
   "metadata": {},
   "source": [
    "Make the inference in the video we have choose for the M24 GA of REXASI-PRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5664b2e-bc6d-4f07-b0cd-21b5268b8a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING âš ï¸ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 17.2ms\n",
      "video 1/1 (frame 2/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 3/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 4/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 5/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 6/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 7/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 8/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 9/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 10/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 11/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 12/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.4ms\n",
      "video 1/1 (frame 13/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 14/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 15/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 16/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.4ms\n",
      "video 1/1 (frame 17/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 4 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 18/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 19/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 20/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 21/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 22/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 23/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 24/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 25/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 26/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.4ms\n",
      "video 1/1 (frame 27/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 28/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 29/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 30/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 31/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 32/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 33/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 34/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 35/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 36/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 37/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 38/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 39/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 40/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 41/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 42/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 43/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 44/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 45/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 46/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 47/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 48/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 49/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 50/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 51/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 52/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 53/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 54/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 55/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 56/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 57/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 58/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 59/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 60/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 61/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 62/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 63/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 64/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 65/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 66/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 67/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 68/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 69/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 70/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 71/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 72/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 73/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 74/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 75/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 76/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 77/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 78/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 79/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 80/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 81/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 82/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 83/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 84/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 85/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 86/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 87/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 88/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.4ms\n",
      "video 1/1 (frame 89/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 90/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 91/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 92/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 93/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 94/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 95/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 96/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 97/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 98/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 99/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 100/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 101/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 102/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.4ms\n",
      "video 1/1 (frame 103/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 104/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.4ms\n",
      "video 1/1 (frame 105/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 106/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 107/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 108/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 109/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 110/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 111/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 112/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 113/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 114/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 115/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 116/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 117/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 118/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 119/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 120/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 121/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 122/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 123/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 124/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 125/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 126/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 127/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 128/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 129/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 130/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 131/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 132/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 133/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 134/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 135/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 136/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.4ms\n",
      "video 1/1 (frame 137/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 138/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 139/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 140/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 141/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 142/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 143/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 144/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 145/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 146/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 147/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 148/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 149/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 150/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 151/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 152/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 153/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 154/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 155/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 156/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 157/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 158/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 159/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 160/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 161/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 162/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 163/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.4ms\n",
      "video 1/1 (frame 164/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 165/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 166/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 167/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 168/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 169/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 170/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 171/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 172/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 173/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 174/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.4ms\n",
      "video 1/1 (frame 175/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 176/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 177/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 178/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 179/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 180/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 181/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 182/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 183/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 184/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 185/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 186/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 187/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 188/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 189/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 190/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 191/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 192/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 193/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 194/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 195/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 196/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 197/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 198/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 199/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 200/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 201/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 202/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 203/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 204/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 205/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 206/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 207/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 208/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 209/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 210/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 211/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 212/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 213/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 214/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 215/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 216/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 217/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 218/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 219/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 220/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 221/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 222/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 223/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 224/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 225/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 226/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 227/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 228/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 229/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 230/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 7 peoples, 16.3ms\n",
      "video 1/1 (frame 231/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 7 peoples, 16.3ms\n",
      "video 1/1 (frame 232/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 233/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 7 peoples, 16.3ms\n",
      "video 1/1 (frame 234/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 235/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 236/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 237/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 238/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 239/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 240/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 241/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 242/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 243/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 244/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 245/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 246/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 247/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 248/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 249/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 250/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 251/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 252/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 253/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 254/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 255/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 256/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.4ms\n",
      "video 1/1 (frame 257/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 258/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 259/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 260/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 261/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 262/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 263/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 264/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 265/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 266/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 267/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 268/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 269/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.4ms\n",
      "video 1/1 (frame 270/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 271/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 272/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 273/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 274/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 275/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 276/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 277/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 278/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 279/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 280/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 281/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 282/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 283/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 284/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 285/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 286/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 287/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 288/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 289/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 290/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 291/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 292/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 293/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 294/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 295/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 3 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 296/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 3 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 297/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 3 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 298/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 299/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 300/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 301/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 302/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 303/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 304/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 305/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 306/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.4ms\n",
      "video 1/1 (frame 307/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 308/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 309/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 310/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 311/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 312/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 313/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 314/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 315/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 316/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 317/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 318/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 319/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 320/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 321/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 322/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 323/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 324/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 325/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 326/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 327/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 328/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 329/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 330/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 331/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 332/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 333/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 334/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 335/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 336/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 3 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 337/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 338/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 339/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 340/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 341/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 342/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 343/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 344/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 345/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 346/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 347/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 348/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 349/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 350/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 351/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 352/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 353/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 354/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 355/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 356/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 357/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 358/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 359/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 360/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 361/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 362/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 363/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 364/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 365/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 366/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 367/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 368/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 369/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 370/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 371/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 372/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 373/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 374/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 375/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 376/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 377/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 378/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 379/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 380/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 381/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 382/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 383/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 384/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 385/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 386/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 387/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 388/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 389/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 390/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 391/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 392/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 393/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 394/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 395/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 396/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 397/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 398/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 399/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 400/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.4ms\n",
      "video 1/1 (frame 401/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 402/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 403/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 404/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 405/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 406/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 407/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 408/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 409/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.4ms\n",
      "video 1/1 (frame 410/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 411/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 412/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.4ms\n",
      "video 1/1 (frame 413/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 414/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 415/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 416/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 417/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 418/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 419/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 420/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 421/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 422/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 423/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 424/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 425/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 426/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 427/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 428/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 429/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.4ms\n",
      "video 1/1 (frame 430/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 431/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 432/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 433/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 4 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 434/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 3 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 435/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 436/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 437/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 438/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 439/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 440/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 441/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 442/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 3 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 443/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 444/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.4ms\n",
      "video 1/1 (frame 445/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.4ms\n",
      "video 1/1 (frame 446/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 3 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 447/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 3 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 448/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 449/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 450/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 451/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.7ms\n",
      "video 1/1 (frame 452/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 453/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 454/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 455/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 456/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 457/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 458/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 459/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 460/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 461/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 462/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 463/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 464/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 465/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 466/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 467/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 468/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 469/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 470/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 471/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 472/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 473/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 474/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 475/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 476/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 477/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 478/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 479/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.4ms\n",
      "video 1/1 (frame 480/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 481/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 482/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 483/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 484/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 485/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 486/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 487/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 488/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 489/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 490/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 491/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 492/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 493/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 494/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 495/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 496/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 497/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 498/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 499/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.4ms\n",
      "video 1/1 (frame 500/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 501/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 502/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 503/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 504/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 505/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 506/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 507/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 508/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 509/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 510/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 511/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 512/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 513/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 514/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 515/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 516/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 517/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 518/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 519/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 520/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 521/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 522/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 523/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 524/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 525/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 526/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 527/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 528/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 529/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 530/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 531/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 532/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 533/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 534/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 535/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 536/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 537/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 538/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 539/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 540/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 541/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.4ms\n",
      "video 1/1 (frame 542/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 543/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 544/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 545/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 546/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 547/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 548/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 549/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 550/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 551/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 552/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 553/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 554/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 555/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 556/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 557/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 558/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 559/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 560/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 561/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 562/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 563/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 564/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 565/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 566/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.4ms\n",
      "video 1/1 (frame 567/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 568/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 569/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 570/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 571/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 572/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 573/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 574/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 575/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 576/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 577/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 578/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 579/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 580/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 581/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 582/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 583/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 584/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 585/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.3ms\n",
      "video 1/1 (frame 586/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 587/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 588/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 589/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 590/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 591/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 592/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 16.8ms\n",
      "video 1/1 (frame 593/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 594/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 595/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 596/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 597/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 598/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 599/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 600/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 601/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 602/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 603/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 604/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 605/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 606/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 607/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 608/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 609/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 610/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 611/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 612/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 613/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 614/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 615/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 616/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 617/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 618/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 619/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 620/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 621/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 622/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 623/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 624/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 625/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 626/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 627/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 628/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 629/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 630/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 631/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 632/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 633/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 634/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 635/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 636/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 637/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.4ms\n",
      "video 1/1 (frame 638/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 639/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 640/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.4ms\n",
      "video 1/1 (frame 641/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 642/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 643/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 644/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.4ms\n",
      "video 1/1 (frame 645/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 646/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 647/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.4ms\n",
      "video 1/1 (frame 648/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 649/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 650/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 651/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 652/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 653/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 654/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 655/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 656/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 657/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 658/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 659/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 660/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 661/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 662/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 663/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 664/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "Speed: 2.0ms preprocess, 16.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14,  4,  0],\n",
       "         [14,  4,  0],\n",
       "         [14,  4,  0],\n",
       "         ...,\n",
       "         [39, 21, 26],\n",
       "         [37, 19, 24],\n",
       "         [37, 19, 24]],\n",
       " \n",
       "        [[19,  9,  4],\n",
       "         [19,  9,  4],\n",
       "         [19,  9,  4],\n",
       "         ...,\n",
       "         [38, 20, 25],\n",
       "         [36, 18, 23],\n",
       "         [36, 18, 23]],\n",
       " \n",
       "        [[22, 12,  7],\n",
       "         [22, 12,  7],\n",
       "         [22, 12,  7],\n",
       "         ...,\n",
       "         [37, 19, 24],\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 3.2291412353515625, 'inference': 17.167329788208008, 'postprocess': 0.9858608245849609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [21,  9,  9],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8811225891113281, 'inference': 16.34502410888672, 'postprocess': 0.9524822235107422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [21,  9,  9],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.898050308227539, 'inference': 16.357421875, 'postprocess': 0.9360313415527344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [21,  9,  9],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8787384033203125, 'inference': 16.32237434387207, 'postprocess': 0.9467601776123047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8906593322753906, 'inference': 16.365528106689453, 'postprocess': 0.9829998016357422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.865386962890625, 'inference': 16.330480575561523, 'postprocess': 0.9326934814453125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8680095672607422, 'inference': 16.31903648376465, 'postprocess': 0.9350776672363281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8699169158935547, 'inference': 16.32833480834961, 'postprocess': 0.9760856628417969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9168853759765625, 'inference': 16.32547378540039, 'postprocess': 0.9295940399169922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8973350524902344, 'inference': 16.335487365722656, 'postprocess': 0.9198188781738281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [18,  6,  6],\n",
       "         [14,  2,  2],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [19,  7,  7],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9865036010742188, 'inference': 16.34359359741211, 'postprocess': 0.9229183197021484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [18,  6,  6],\n",
       "         [14,  2,  2],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [19,  7,  7],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8677711486816406, 'inference': 16.353368759155273, 'postprocess': 0.9827613830566406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [18,  6,  6],\n",
       "         [14,  2,  2],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [19,  7,  7],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8994808197021484, 'inference': 16.32380485534668, 'postprocess': 0.9262561798095703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9192695617675781, 'inference': 16.362905502319336, 'postprocess': 0.942230224609375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9123554229736328, 'inference': 16.332149505615234, 'postprocess': 0.9686946868896484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.889394760131836, 'inference': 16.37744903564453, 'postprocess': 1.199483871459961},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8992424011230469, 'inference': 16.34359359741211, 'postprocess': 0.9284019470214844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9538402557373047, 'inference': 16.34979248046875, 'postprocess': 0.9429454803466797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9435882568359375, 'inference': 16.332626342773438, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8906593322753906, 'inference': 16.338586807250977, 'postprocess': 0.9310245513916016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [20,  7, 11],\n",
       "         [18,  5,  9]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9099712371826172, 'inference': 16.33143424987793, 'postprocess': 0.9441375732421875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [20,  7, 11],\n",
       "         [18,  5,  9]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9669532775878906, 'inference': 16.34812355041504, 'postprocess': 0.9264945983886719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8758773803710938, 'inference': 16.346454620361328, 'postprocess': 0.9396076202392578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9190311431884766, 'inference': 16.329288482666016, 'postprocess': 0.93841552734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8908977508544922, 'inference': 16.364574432373047, 'postprocess': 0.9253025054931641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.913309097290039, 'inference': 16.361236572265625, 'postprocess': 0.9279251098632812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.954793930053711, 'inference': 16.341209411621094, 'postprocess': 0.919342041015625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8970966339111328, 'inference': 16.32523536682129, 'postprocess': 0.9253025054931641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9376277923583984, 'inference': 16.32404327392578, 'postprocess': 0.9167194366455078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 6,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         [24, 16, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8999576568603516, 'inference': 16.330242156982422, 'postprocess': 0.9207725524902344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9176006317138672, 'inference': 16.345977783203125, 'postprocess': 0.9493827819824219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.4929046630859375, 'inference': 16.314983367919922, 'postprocess': 0.9198188781738281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9428730010986328, 'inference': 16.341686248779297, 'postprocess': 0.9183883666992188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0062923431396484, 'inference': 16.352415084838867, 'postprocess': 0.9219646453857422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9831657409667969, 'inference': 16.328811645507812, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9142627716064453, 'inference': 16.33286476135254, 'postprocess': 0.9093284606933594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9309520721435547, 'inference': 16.360998153686523, 'postprocess': 0.9739398956298828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.920938491821289, 'inference': 16.342639923095703, 'postprocess': 0.9205341339111328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8961429595947266, 'inference': 16.32094383239746, 'postprocess': 0.9248256683349609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9040107727050781, 'inference': 16.326904296875, 'postprocess': 0.9162425994873047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8143653869628906, 'inference': 16.321420669555664, 'postprocess': 0.9305477142333984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8749237060546875, 'inference': 16.321897506713867, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8854141235351562, 'inference': 16.34049415588379, 'postprocess': 0.9217262268066406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8923282623291016, 'inference': 16.332626342773438, 'postprocess': 0.9446144104003906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.888275146484375, 'inference': 16.329050064086914, 'postprocess': 0.9217262268066406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9736289978027344, 'inference': 16.33143424987793, 'postprocess': 1.0216236114501953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.913309097290039, 'inference': 16.329288482666016, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.786397933959961, 'inference': 16.322612762451172, 'postprocess': 0.9195804595947266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8968582153320312, 'inference': 16.33310317993164, 'postprocess': 0.9286403656005859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8966197967529297, 'inference': 16.33000373840332, 'postprocess': 0.9665489196777344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9116401672363281, 'inference': 16.34073257446289, 'postprocess': 0.949859619140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9271373748779297, 'inference': 16.316890716552734, 'postprocess': 0.9210109710693359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9011497497558594, 'inference': 16.327619552612305, 'postprocess': 0.9195804595947266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9059181213378906, 'inference': 16.340970993041992, 'postprocess': 0.9307861328125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8148422241210938, 'inference': 16.314268112182617, 'postprocess': 0.9369850158691406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8694400787353516, 'inference': 16.32857322692871, 'postprocess': 0.9336471557617188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9626617431640625, 'inference': 16.3424015045166, 'postprocess': 0.9250640869140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8777847290039062, 'inference': 16.337156295776367, 'postprocess': 0.9260177612304688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9123554229736328, 'inference': 16.328096389770508, 'postprocess': 0.9365081787109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]],\n",
       " \n",
       "        [[20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.940011978149414, 'inference': 16.33310317993164, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [18,  3,  4],\n",
       "         [18,  3,  4],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8887519836425781, 'inference': 16.350269317626953, 'postprocess': 0.9624958038330078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9495487213134766, 'inference': 16.327381134033203, 'postprocess': 0.9615421295166016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9342899322509766, 'inference': 16.333818435668945, 'postprocess': 0.9341239929199219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.872467041015625, 'inference': 16.313552856445312, 'postprocess': 0.9124279022216797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9674301147460938, 'inference': 16.346454620361328, 'postprocess': 0.9565353393554688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8923282623291016, 'inference': 16.33620262145996, 'postprocess': 0.9341239929199219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9800662994384766, 'inference': 16.326904296875, 'postprocess': 0.9179115295410156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.91497802734375, 'inference': 16.33143424987793, 'postprocess': 0.9417533874511719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.928091049194336, 'inference': 16.32976531982422, 'postprocess': 0.9176731109619141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8773078918457031, 'inference': 16.321182250976562, 'postprocess': 0.92315673828125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.903533935546875, 'inference': 16.336441040039062, 'postprocess': 1.1065006256103516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8413066864013672, 'inference': 16.326904296875, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9676685333251953, 'inference': 16.333580017089844, 'postprocess': 0.9210109710693359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [15,  0,  1],\n",
       "         [13,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [22,  7,  8],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [27, 12, 13],\n",
       "         [29, 14, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.89208984375, 'inference': 16.340970993041992, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [27, 11, 16],\n",
       "         [29, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.917123794555664, 'inference': 16.324281692504883, 'postprocess': 0.9202957153320312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8696784973144531, 'inference': 16.32213592529297, 'postprocess': 0.9961128234863281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.89971923828125, 'inference': 16.334056854248047, 'postprocess': 0.92315673828125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9092559814453125, 'inference': 16.332149505615234, 'postprocess': 0.9360313415527344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.949310302734375, 'inference': 16.339540481567383, 'postprocess': 0.9703636169433594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [15,  0,  1],\n",
       "         [13,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [22,  7,  8],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.8624534606933594, 'inference': 16.314983367919922, 'postprocess': 0.9167194366455078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8939971923828125, 'inference': 16.331911087036133, 'postprocess': 0.9236335754394531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.89971923828125, 'inference': 16.320228576660156, 'postprocess': 0.9210109710693359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [24, 19, 18],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.888275146484375, 'inference': 16.37721061706543, 'postprocess': 0.9629726409912109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [24, 19, 18],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8901824951171875, 'inference': 16.337871551513672, 'postprocess': 0.9293556213378906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [15,  0,  1],\n",
       "         [13,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [22,  7,  8],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [24, 19, 18],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8932819366455078, 'inference': 16.31951332092285, 'postprocess': 0.9932518005371094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [15,  0,  1],\n",
       "         [13,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [22,  7,  8],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.905679702758789, 'inference': 16.32237434387207, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4],\n",
       "         [17,  2,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8725395202636719, 'inference': 16.333818435668945, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4],\n",
       "         [17,  2,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9764900207519531, 'inference': 16.358137130737305, 'postprocess': 0.9248256683349609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4],\n",
       "         [17,  2,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8205642700195312, 'inference': 16.318082809448242, 'postprocess': 0.9303092956542969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4],\n",
       "         [17,  2,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8758773803710938, 'inference': 16.344785690307617, 'postprocess': 0.9222030639648438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9431114196777344, 'inference': 16.33453369140625, 'postprocess': 0.9207725524902344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.953125, 'inference': 16.32857322692871, 'postprocess': 0.9663105010986328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9216537475585938, 'inference': 16.31927490234375, 'postprocess': 0.9217262268066406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.007007598876953, 'inference': 16.327381134033203, 'postprocess': 0.9133815765380859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9278526306152344, 'inference': 16.34955406188965, 'postprocess': 0.9164810180664062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.843618392944336, 'inference': 16.329050064086914, 'postprocess': 0.9214878082275391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8489360809326172, 'inference': 16.325712203979492, 'postprocess': 0.919342041015625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9288063049316406, 'inference': 16.341209411621094, 'postprocess': 0.9541511535644531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9001960754394531, 'inference': 16.330718994140625, 'postprocess': 0.9348392486572266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8987655639648438, 'inference': 16.3266658782959, 'postprocess': 0.9312629699707031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [16,  4,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9087791442871094, 'inference': 16.327619552612305, 'postprocess': 0.9512901306152344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9557476043701172, 'inference': 16.357898712158203, 'postprocess': 0.9343624114990234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10],\n",
       "         [18,  6,  8]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9218921661376953, 'inference': 16.324281692504883, 'postprocess': 0.9219646453857422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [16,  1,  4],\n",
       "         [ 9,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 15],\n",
       "         [16,  1,  4],\n",
       "         [ 9,  0,  0]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [15,  0,  3],\n",
       "         [10,  0,  0]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9054412841796875, 'inference': 16.36028289794922, 'postprocess': 0.9162425994873047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9199848175048828, 'inference': 16.332149505615234, 'postprocess': 0.9703636169433594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8303394317626953, 'inference': 16.329526901245117, 'postprocess': 0.9863376617431641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9452571868896484, 'inference': 16.323328018188477, 'postprocess': 0.9148120880126953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8367767333984375, 'inference': 16.33143424987793, 'postprocess': 0.9486675262451172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  9],\n",
       "         [18,  3,  6],\n",
       "         [13,  0,  1]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [27, 12, 15],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.89971923828125, 'inference': 16.327857971191406, 'postprocess': 0.9248256683349609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  9],\n",
       "         [18,  3,  6],\n",
       "         [13,  0,  1]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [27, 12, 15],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8794536590576172, 'inference': 16.330480575561523, 'postprocess': 0.9229183197021484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [23,  8, 11],\n",
       "         [18,  3,  6]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [31, 16, 19],\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [35, 20, 23],\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8770694732666016, 'inference': 16.337871551513672, 'postprocess': 0.9250640869140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [23,  8, 11],\n",
       "         [18,  3,  6]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [31, 16, 19],\n",
       "         [24,  9, 12],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [34, 19, 22],\n",
       "         [27, 12, 15],\n",
       "         [23,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.9594898223876953, 'inference': 16.316652297973633, 'postprocess': 0.9179115295410156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [23,  8, 11],\n",
       "         [18,  3,  6]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [31, 16, 19],\n",
       "         [24,  9, 12],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [34, 19, 22],\n",
       "         [27, 12, 15],\n",
       "         [23,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8565654754638672, 'inference': 16.32237434387207, 'postprocess': 0.9329319000244141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.916646957397461, 'inference': 16.326427459716797, 'postprocess': 0.9169578552246094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9447803497314453, 'inference': 16.33763313293457, 'postprocess': 0.9214878082275391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9207000732421875, 'inference': 16.33930206298828, 'postprocess': 0.9255409240722656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9214153289794922, 'inference': 16.335725784301758, 'postprocess': 0.9181499481201172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9214153289794922, 'inference': 16.328811645507812, 'postprocess': 0.95367431640625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9207000732421875, 'inference': 16.329050064086914, 'postprocess': 0.9436607360839844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12],\n",
       "         [18,  3,  6]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [32, 17, 20],\n",
       "         [25, 10, 13],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [35, 20, 23],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.926422119140625, 'inference': 16.343355178833008, 'postprocess': 0.9167194366455078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [22,  7,  8],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [27, 12, 13],\n",
       "         [22,  7,  8]],\n",
       " \n",
       "        [[23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8947124481201172, 'inference': 16.319751739501953, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [22,  7,  8],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [27, 12, 13],\n",
       "         [22,  7,  8]],\n",
       " \n",
       "        [[23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [29, 14, 15],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9528865814208984, 'inference': 16.333341598510742, 'postprocess': 0.9124279022216797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [18,  3,  4],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.936197280883789, 'inference': 16.333818435668945, 'postprocess': 0.9210109710693359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [20,  5,  6],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9290447235107422, 'inference': 16.335248947143555, 'postprocess': 0.9174346923828125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [21,  6,  7],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9042491912841797, 'inference': 16.334056854248047, 'postprocess': 0.9179115295410156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [20,  5,  6],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9922256469726562, 'inference': 16.319751739501953, 'postprocess': 0.9145736694335938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9],\n",
       "         [16,  1,  2]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9330978393554688, 'inference': 16.321659088134766, 'postprocess': 0.9353160858154297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9],\n",
       "         [16,  1,  2]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.105712890625, 'inference': 16.32213592529297, 'postprocess': 0.9176731109619141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9],\n",
       "         [16,  1,  2]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9314289093017578, 'inference': 16.324996948242188, 'postprocess': 0.9272098541259766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9],\n",
       "         [16,  1,  2]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9631385803222656, 'inference': 16.338586807250977, 'postprocess': 0.9467601776123047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [22,  7,  8],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9159317016601562, 'inference': 16.3266658782959, 'postprocess': 0.9245872497558594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [22,  7,  8]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [29, 14, 15],\n",
       "         [23,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9068717956542969, 'inference': 16.326189041137695, 'postprocess': 0.9441375732421875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [22,  7,  8]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [29, 14, 15],\n",
       "         [23,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.972198486328125, 'inference': 16.31760597229004, 'postprocess': 0.9136199951171875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [17,  7,  7],\n",
       "         [11,  1,  1],\n",
       "         [ 9,  0,  0]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [19,  9,  9],\n",
       "         [12,  2,  2],\n",
       "         [10,  0,  0]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [16,  6,  6],\n",
       "         [17,  7,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9392967224121094, 'inference': 16.33286476135254, 'postprocess': 0.9338855743408203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [17,  7,  7],\n",
       "         [11,  1,  1],\n",
       "         [ 9,  0,  0]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [19,  9,  9],\n",
       "         [12,  2,  2],\n",
       "         [10,  0,  0]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [16,  6,  6],\n",
       "         [17,  7,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.924753189086914, 'inference': 16.32213592529297, 'postprocess': 0.92315673828125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [17,  7,  7],\n",
       "         [11,  1,  1],\n",
       "         [ 9,  0,  0]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [19,  9,  9],\n",
       "         [12,  2,  2],\n",
       "         [10,  0,  0]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [16,  6,  6],\n",
       "         [17,  7,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8651485443115234, 'inference': 16.35432243347168, 'postprocess': 0.9555816650390625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8932819366455078, 'inference': 16.327619552612305, 'postprocess': 0.9105205535888672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8985271453857422, 'inference': 16.334056854248047, 'postprocess': 0.9443759918212891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8765926361083984, 'inference': 16.325712203979492, 'postprocess': 0.92315673828125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.916646957397461, 'inference': 16.322851181030273, 'postprocess': 0.9036064147949219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8892288208007812, 'inference': 16.324758529663086, 'postprocess': 0.9291172027587891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9130706787109375, 'inference': 16.31784439086914, 'postprocess': 0.9138584136962891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [27, 12, 13],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8770694732666016, 'inference': 16.328811645507812, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.394437789916992, 'inference': 16.329526901245117, 'postprocess': 1.0073184967041016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0029544830322266, 'inference': 16.329050064086914, 'postprocess': 0.9162425994873047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9633769989013672, 'inference': 16.318559646606445, 'postprocess': 0.9584426879882812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0024776458740234, 'inference': 16.337871551513672, 'postprocess': 0.9286403656005859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8465518951416016, 'inference': 16.31927490234375, 'postprocess': 0.9291172027587891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8873214721679688, 'inference': 16.329050064086914, 'postprocess': 0.9312629699707031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[24, 21, 22],\n",
       "         [24, 21, 22],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [24,  9, 10],\n",
       "         [23,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9457340240478516, 'inference': 16.32380485534668, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [26, 14, 16],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.909494400024414, 'inference': 16.340970993041992, 'postprocess': 0.9205341339111328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9104480743408203, 'inference': 16.31784439086914, 'postprocess': 0.9100437164306641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9347667694091797, 'inference': 16.327857971191406, 'postprocess': 0.9164810180664062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9650459289550781, 'inference': 16.338348388671875, 'postprocess': 0.9119510650634766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.932382583618164, 'inference': 16.324281692504883, 'postprocess': 0.9241104125976562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9173622131347656, 'inference': 16.322612762451172, 'postprocess': 0.9303092956542969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.995086669921875, 'inference': 16.3419246673584, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9512176513671875, 'inference': 16.332149505615234, 'postprocess': 0.9198188781738281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9397735595703125, 'inference': 16.31903648376465, 'postprocess': 0.9250640869140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.886056900024414, 'inference': 16.318798065185547, 'postprocess': 0.9095668792724609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9273757934570312, 'inference': 16.342878341674805, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9230842590332031, 'inference': 16.33930206298828, 'postprocess': 0.9186267852783203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 29, 32],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9292831420898438, 'inference': 16.368627548217773, 'postprocess': 0.9627342224121094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 21, 23],\n",
       "         [30, 18, 20],\n",
       "         [30, 18, 20]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 22, 24],\n",
       "         [33, 21, 23],\n",
       "         [33, 21, 23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9023418426513672, 'inference': 16.33000373840332, 'postprocess': 0.9319782257080078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [37, 20, 23],\n",
       "         [34, 17, 20],\n",
       "         [34, 17, 20]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [38, 21, 24],\n",
       "         [37, 20, 23],\n",
       "         [37, 20, 23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9037723541259766, 'inference': 16.33167266845703, 'postprocess': 0.926971435546875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [38, 16, 20],\n",
       "         [35, 13, 17],\n",
       "         [34, 12, 16]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [41, 19, 23],\n",
       "         [38, 16, 20],\n",
       "         [38, 16, 20]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [42, 20, 24],\n",
       "         [41, 19, 23],\n",
       "         [41, 19, 23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.837015151977539, 'inference': 16.31927490234375, 'postprocess': 0.9486675262451172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9373893737792969, 'inference': 16.328811645507812, 'postprocess': 0.9377002716064453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9116401672363281, 'inference': 16.344308853149414, 'postprocess': 0.9343624114990234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8649101257324219, 'inference': 16.33620262145996, 'postprocess': 0.9713172912597656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9385814666748047, 'inference': 16.324758529663086, 'postprocess': 1.0881423950195312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.105236053466797, 'inference': 16.32523536682129, 'postprocess': 0.9963512420654297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8813610076904297, 'inference': 16.33310317993164, 'postprocess': 0.9641647338867188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.078533172607422, 'inference': 16.330957412719727, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8541812896728516, 'inference': 16.35909080505371, 'postprocess': 0.9217262268066406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8589496612548828, 'inference': 16.322612762451172, 'postprocess': 0.9543895721435547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.9723644256591797, 'inference': 16.31951332092285, 'postprocess': 0.9241104125976562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8932819366455078, 'inference': 16.317367553710938, 'postprocess': 0.9720325469970703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9059181213378906, 'inference': 16.315937042236328, 'postprocess': 0.9222030639648438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.894235610961914, 'inference': 16.330480575561523, 'postprocess': 0.9357929229736328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8870830535888672, 'inference': 16.327857971191406, 'postprocess': 0.9291172027587891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [21,  6,  9],\n",
       "         [20,  5,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12],\n",
       "         [23,  8, 11]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0172595977783203, 'inference': 16.325950622558594, 'postprocess': 0.9260177612304688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [21,  6,  9],\n",
       "         [20,  5,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12],\n",
       "         [23,  8, 11]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0127296447753906, 'inference': 16.325712203979492, 'postprocess': 0.9310245513916016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [21,  6,  9],\n",
       "         [20,  5,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12],\n",
       "         [23,  8, 11]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.077341079711914, 'inference': 16.32833480834961, 'postprocess': 0.9181499481201172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [20, 10, 12],\n",
       "         [17,  7,  9],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [20, 10, 12],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.003192901611328, 'inference': 16.32976531982422, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [20, 10, 12],\n",
       "         [17,  7,  9],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [20, 10, 12],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9314289093017578, 'inference': 16.321897506713867, 'postprocess': 0.9286403656005859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [18,  8, 10],\n",
       "         [14,  4,  6],\n",
       "         [12,  2,  4]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [20, 10, 12],\n",
       "         [17,  7,  9],\n",
       "         [14,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [19,  9, 11],\n",
       "         [17,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.89971923828125, 'inference': 16.3266658782959, 'postprocess': 0.9343624114990234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [18,  8, 10],\n",
       "         [14,  4,  6],\n",
       "         [12,  2,  4]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [20, 10, 12],\n",
       "         [17,  7,  9],\n",
       "         [14,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [19,  9, 11],\n",
       "         [17,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0380020141601562, 'inference': 16.352415084838867, 'postprocess': 0.9207725524902344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.953125, 'inference': 16.323089599609375, 'postprocess': 0.9381771087646484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9834041595458984, 'inference': 16.33000373840332, 'postprocess': 0.9253025054931641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.009868621826172, 'inference': 16.326904296875, 'postprocess': 0.9145736694335938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [12,  5, 11],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [21, 17, 20],\n",
       "         [26, 19, 25],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9083023071289062, 'inference': 16.330242156982422, 'postprocess': 0.9315013885498047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [12,  5, 11],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [21, 17, 20],\n",
       "         [26, 19, 25],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.7463436126708984, 'inference': 16.31617546081543, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9404888153076172, 'inference': 16.323089599609375, 'postprocess': 0.9257793426513672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [36, 16, 20],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [36, 16, 20],\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9843578338623047, 'inference': 16.33620262145996, 'postprocess': 0.9219646453857422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9366741180419922, 'inference': 16.35265350341797, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8689632415771484, 'inference': 16.31951332092285, 'postprocess': 0.9703636169433594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9211769104003906, 'inference': 16.31641387939453, 'postprocess': 0.9317398071289062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8949508666992188, 'inference': 16.336441040039062, 'postprocess': 0.9291172027587891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9147396087646484, 'inference': 16.338586807250977, 'postprocess': 0.9329319000244141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.918792724609375, 'inference': 16.32523536682129, 'postprocess': 0.9136199951171875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9309520721435547, 'inference': 16.324520111083984, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9125938415527344, 'inference': 16.328811645507812, 'postprocess': 0.9312629699707031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9497871398925781, 'inference': 16.360998153686523, 'postprocess': 0.9236335754394531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8885135650634766, 'inference': 16.35456085205078, 'postprocess': 0.9174346923828125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9211769104003906, 'inference': 16.3424015045166, 'postprocess': 0.9255409240722656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9621849060058594, 'inference': 16.330242156982422, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.89208984375, 'inference': 16.33477210998535, 'postprocess': 0.9765625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.8786659240722656, 'inference': 16.32404327392578, 'postprocess': 0.9150505065917969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8966197967529297, 'inference': 16.31927490234375, 'postprocess': 0.9262561798095703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8956661224365234, 'inference': 16.3576602935791, 'postprocess': 0.9143352508544922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9025802612304688, 'inference': 16.329288482666016, 'postprocess': 0.9522438049316406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.886606216430664, 'inference': 16.32523536682129, 'postprocess': 0.9481906890869141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9104480743408203, 'inference': 16.33000373840332, 'postprocess': 0.9386539459228516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9168853759765625, 'inference': 16.330957412719727, 'postprocess': 0.9150505065917969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8687248229980469, 'inference': 16.327619552612305, 'postprocess': 0.9398460388183594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9266605377197266, 'inference': 16.32237434387207, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8994808197021484, 'inference': 16.320466995239258, 'postprocess': 0.9145736694335938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.903533935546875, 'inference': 16.319751739501953, 'postprocess': 0.9207725524902344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.936197280883789, 'inference': 16.33167266845703, 'postprocess': 0.9291172027587891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8684864044189453, 'inference': 16.320228576660156, 'postprocess': 0.9298324584960938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8916130065917969, 'inference': 16.337871551513672, 'postprocess': 0.9214878082275391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9118785858154297, 'inference': 16.330242156982422, 'postprocess': 0.91552734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9106864929199219, 'inference': 16.323566436767578, 'postprocess': 0.9760856628417969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [27,  9, 14],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [ 8,  4,  7],\n",
       "         ...,\n",
       "         [31, 13, 18],\n",
       "         [30, 12, 17],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.783536911010742, 'inference': 16.340970993041992, 'postprocess': 0.9424686431884766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [31, 13, 18],\n",
       "         [30, 12, 17],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9614696502685547, 'inference': 16.332387924194336, 'postprocess': 0.9210109710693359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9481182098388672, 'inference': 16.327619552612305, 'postprocess': 1.0082721710205078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9314289093017578, 'inference': 16.332149505615234, 'postprocess': 0.9613037109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8825531005859375, 'inference': 16.322851181030273, 'postprocess': 0.9212493896484375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8858909606933594, 'inference': 16.32070541381836, 'postprocess': 0.9353160858154297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9311904907226562, 'inference': 16.331911087036133, 'postprocess': 0.9260177612304688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.911163330078125, 'inference': 16.30544662475586, 'postprocess': 0.9279251098632812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9505023956298828, 'inference': 16.330957412719727, 'postprocess': 0.9691715240478516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8801689147949219, 'inference': 16.315460205078125, 'postprocess': 0.9284019470214844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14],\n",
       "         [24,  6, 11]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [27,  9, 14],\n",
       "         [23,  5, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8982887268066406, 'inference': 16.320466995239258, 'postprocess': 0.9210109710693359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [29, 11, 16],\n",
       "         [30, 12, 17]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [30, 12, 17],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9106864929199219, 'inference': 16.32070541381836, 'postprocess': 0.9317398071289062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [27,  9, 14],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [30, 12, 17],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9402503967285156, 'inference': 16.332626342773438, 'postprocess': 0.9202957153320312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [27,  9, 14],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [30, 12, 17],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8985271453857422, 'inference': 16.3266658782959, 'postprocess': 0.9212493896484375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [27,  9, 14],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [30, 12, 17],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.917123794555664, 'inference': 16.324758529663086, 'postprocess': 0.9212493896484375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  6, 11],\n",
       "         [25,  7, 12],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [36, 18, 23],\n",
       "         [36, 18, 23],\n",
       "         [34, 16, 21]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9054412841796875, 'inference': 16.332149505615234, 'postprocess': 0.9591579437255859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [20,  7, 11],\n",
       "         [21,  8, 12],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [27, 14, 18],\n",
       "         [27, 14, 18]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [32, 19, 23],\n",
       "         [32, 19, 23],\n",
       "         [30, 17, 21]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.7730464935302734, 'inference': 16.322612762451172, 'postprocess': 0.9131431579589844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[ 5,  5,  5],\n",
       "         [ 5,  5,  5],\n",
       "         [ 4,  4,  4],\n",
       "         ...,\n",
       "         [32, 20, 22],\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17]],\n",
       " \n",
       "        [[20, 20, 20],\n",
       "         [20, 20, 20],\n",
       "         [20, 20, 20],\n",
       "         ...,\n",
       "         [35, 23, 25],\n",
       "         [32, 20, 22],\n",
       "         [30, 18, 20]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9390583038330078, 'inference': 16.329526901245117, 'postprocess': 0.9219646453857422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [32, 20, 22],\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.897573471069336, 'inference': 16.312837600708008, 'postprocess': 0.9324550628662109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [32, 20, 22],\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9984245300292969, 'inference': 16.328096389770508, 'postprocess': 0.9148120880126953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [32, 20, 22],\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9314289093017578, 'inference': 16.332149505615234, 'postprocess': 0.9400844573974609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [32, 20, 22],\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9299983978271484, 'inference': 16.330242156982422, 'postprocess': 0.9224414825439453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 14, 17],\n",
       "         [25, 10, 13],\n",
       "         [24,  9, 12]],\n",
       " \n",
       "        [[ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [31, 16, 19],\n",
       "         [28, 13, 16],\n",
       "         [27, 12, 15]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [34, 19, 22],\n",
       "         [31, 16, 19],\n",
       "         [28, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9073486328125, 'inference': 16.3271427154541, 'postprocess': 0.934600830078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [24,  7, 10],\n",
       "         [23,  6,  9]],\n",
       " \n",
       "        [[11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9216537475585938, 'inference': 16.31760597229004, 'postprocess': 0.9319782257080078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [24,  7, 10],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9216537475585938, 'inference': 16.34955406188965, 'postprocess': 0.9288787841796875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [24,  7, 10],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9483566284179688, 'inference': 16.34383201599121, 'postprocess': 0.9207725524902344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [24,  7, 10],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.985311508178711, 'inference': 16.324758529663086, 'postprocess': 0.9179115295410156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9161701202392578, 'inference': 16.33620262145996, 'postprocess': 0.9260177612304688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9619464874267578, 'inference': 16.34049415588379, 'postprocess': 0.9210109710693359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9388198852539062, 'inference': 16.329288482666016, 'postprocess': 0.9164810180664062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [30, 14, 19],\n",
       "         [28, 12, 17]],\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [31, 15, 20],\n",
       "         [28, 12, 17]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [35, 19, 24],\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9345283508300781, 'inference': 16.327381134033203, 'postprocess': 0.926971435546875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9109249114990234, 'inference': 16.334056854248047, 'postprocess': 0.9300708770751953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.9137134552001953, 'inference': 16.376495361328125, 'postprocess': 0.9934902191162109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9948482513427734, 'inference': 16.32833480834961, 'postprocess': 0.9126663208007812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.973867416381836, 'inference': 16.330480575561523, 'postprocess': 0.9636878967285156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9745826721191406, 'inference': 16.33000373840332, 'postprocess': 0.9360313415527344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9347667694091797, 'inference': 16.319751739501953, 'postprocess': 0.9253025054931641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9228458404541016, 'inference': 16.327619552612305, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9257068634033203, 'inference': 16.3271427154541, 'postprocess': 0.9169578552246094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8985271453857422, 'inference': 16.325950622558594, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.912832260131836, 'inference': 16.32523536682129, 'postprocess': 0.9210109710693359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8508434295654297, 'inference': 16.314983367919922, 'postprocess': 0.9284019470214844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 7,  4,  5],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9369125366210938, 'inference': 16.338586807250977, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 7,  4,  5],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9519329071044922, 'inference': 16.32857322692871, 'postprocess': 0.9794235229492188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9121170043945312, 'inference': 16.32976531982422, 'postprocess': 0.9262561798095703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8935203552246094, 'inference': 16.350507736206055, 'postprocess': 0.9272098541259766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [28, 13, 14],\n",
       "         [25, 10, 11]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 16, 17],\n",
       "         [28, 13, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8835067749023438, 'inference': 16.320228576660156, 'postprocess': 0.9160041809082031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.917123794555664, 'inference': 16.332626342773438, 'postprocess': 0.9214878082275391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [27, 15, 17]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.8228759765625, 'inference': 16.312360763549805, 'postprocess': 0.9229183197021484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [27, 15, 17]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9540786743164062, 'inference': 16.331911087036133, 'postprocess': 0.9241104125976562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [27, 15, 17]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9702911376953125, 'inference': 16.327381134033203, 'postprocess': 0.9341239929199219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.932382583618164, 'inference': 16.3271427154541, 'postprocess': 0.9279251098632812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9359588623046875, 'inference': 16.329050064086914, 'postprocess': 0.9112358093261719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8944740295410156, 'inference': 16.318798065185547, 'postprocess': 0.9982585906982422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [34, 14, 18],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9631385803222656, 'inference': 16.330718994140625, 'postprocess': 0.9224414825439453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [34, 14, 18],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9350051879882812, 'inference': 16.321659088134766, 'postprocess': 0.9450912475585938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [34, 14, 18],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0003318786621094, 'inference': 16.32857322692871, 'postprocess': 0.9112358093261719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [34, 14, 18],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8622875213623047, 'inference': 16.32833480834961, 'postprocess': 0.9326934814453125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [34, 14, 18],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9116401672363281, 'inference': 16.32523536682129, 'postprocess': 0.9753704071044922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8851757049560547, 'inference': 16.332626342773438, 'postprocess': 0.9293556213378906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9245147705078125, 'inference': 16.341447830200195, 'postprocess': 0.9334087371826172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9307136535644531, 'inference': 16.33596420288086, 'postprocess': 0.9417533874511719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [26,  9, 12],\n",
       "         [23,  6,  9]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9450187683105469, 'inference': 16.335487365722656, 'postprocess': 0.9441375732421875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9054412841796875, 'inference': 16.34049415588379, 'postprocess': 0.9255409240722656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  1],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [12,  6,  9],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [24, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.975940704345703, 'inference': 16.323089599609375, 'postprocess': 0.9272098541259766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.93023681640625, 'inference': 16.33167266845703, 'postprocess': 0.9622573852539062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0360946655273438, 'inference': 16.327619552612305, 'postprocess': 0.9276866912841797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9104480743408203, 'inference': 16.322851181030273, 'postprocess': 0.9286403656005859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9922256469726562, 'inference': 16.33167266845703, 'postprocess': 0.9224414825439453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9190311431884766, 'inference': 16.322851181030273, 'postprocess': 0.9214878082275391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9321441650390625, 'inference': 16.3271427154541, 'postprocess': 0.9219646453857422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [33, 11, 15],\n",
       "         [31,  9, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [34, 12, 16],\n",
       "         [33, 11, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [34, 12, 16],\n",
       "         [34, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9140243530273438, 'inference': 16.32523536682129, 'postprocess': 0.9348392486572266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [33, 11, 15],\n",
       "         [31,  9, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [34, 12, 16],\n",
       "         [33, 11, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [34, 12, 16],\n",
       "         [34, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9347667694091797, 'inference': 16.341447830200195, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [33, 11, 15],\n",
       "         [31,  9, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [34, 12, 16],\n",
       "         [33, 11, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [35, 13, 17],\n",
       "         [35, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.870870590209961, 'inference': 16.330480575561523, 'postprocess': 0.9229183197021484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [33, 11, 15],\n",
       "         [31,  9, 13]],\n",
       " \n",
       "        [[10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [34, 12, 16],\n",
       "         [33, 11, 15]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [35, 13, 17],\n",
       "         [35, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8832683563232422, 'inference': 16.32094383239746, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8873214721679688, 'inference': 16.32380485534668, 'postprocess': 0.9353160858154297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8985271453857422, 'inference': 16.327381134033203, 'postprocess': 0.9307861328125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  3,  5],\n",
       "         [11,  3,  5],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[24, 16, 18],\n",
       "         [24, 16, 18],\n",
       "         [24, 16, 18],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8901824951171875, 'inference': 16.31903648376465, 'postprocess': 0.9768009185791016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9557476043701172, 'inference': 16.337871551513672, 'postprocess': 0.9710788726806641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9636154174804688, 'inference': 16.338825225830078, 'postprocess': 0.9224414825439453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.7534961700439453, 'inference': 16.31617546081543, 'postprocess': 0.9326934814453125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9605159759521484, 'inference': 16.3266658782959, 'postprocess': 0.9303092956542969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [33, 11, 15],\n",
       "         [31,  9, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [34, 12, 16],\n",
       "         [34, 12, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [35, 13, 17],\n",
       "         [35, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9073486328125, 'inference': 16.359567642211914, 'postprocess': 0.9672641754150391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9462108612060547, 'inference': 16.327381134033203, 'postprocess': 0.9472370147705078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 11, 15],\n",
       "         [29,  9, 13],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.951456069946289, 'inference': 16.34812355041504, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9330978393554688, 'inference': 16.327619552612305, 'postprocess': 0.9188652038574219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.985788345336914, 'inference': 16.325712203979492, 'postprocess': 1.1806488037109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.983642578125, 'inference': 16.3266658782959, 'postprocess': 0.9167194366455078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9402503967285156, 'inference': 16.33429527282715, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8744468688964844, 'inference': 16.335487365722656, 'postprocess': 0.9238719940185547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.05230712890625, 'inference': 16.33596420288086, 'postprocess': 0.9245872497558594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9545555114746094, 'inference': 16.33453369140625, 'postprocess': 0.9262561798095703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8863677978515625, 'inference': 16.346216201782227, 'postprocess': 0.9562969207763672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9164085388183594, 'inference': 16.340970993041992, 'postprocess': 1.0058879852294922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.99127197265625, 'inference': 16.33930206298828, 'postprocess': 0.9274482727050781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.901865005493164, 'inference': 16.316652297973633, 'postprocess': 0.9462833404541016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.758026123046875, 'inference': 16.31903648376465, 'postprocess': 0.9794235229492188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9710063934326172, 'inference': 16.333818435668945, 'postprocess': 0.9322166442871094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9793510437011719, 'inference': 16.338348388671875, 'postprocess': 0.91552734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 10, 18],\n",
       "         [26,  7, 15],\n",
       "         [25,  6, 14]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 11, 19],\n",
       "         [29, 10, 18],\n",
       "         [27,  8, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 12, 20],\n",
       "         [31, 12, 20],\n",
       "         [31, 12, 20]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9578933715820312, 'inference': 16.347885131835938, 'postprocess': 0.9281635284423828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [24,  7, 10],\n",
       "         [19,  2,  5]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [23,  6,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9352436065673828, 'inference': 16.316890716552734, 'postprocess': 0.9272098541259766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [24,  7, 10],\n",
       "         [19,  2,  5]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [23,  6,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9998550415039062, 'inference': 16.340255737304688, 'postprocess': 0.9219646453857422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [24,  7, 10],\n",
       "         [20,  3,  6]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [23,  6,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.940011978149414, 'inference': 16.338348388671875, 'postprocess': 0.9264945983886719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [24,  7, 10],\n",
       "         [20,  3,  6]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [23,  6,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9352436065673828, 'inference': 16.332387924194336, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [24,  7, 10],\n",
       "         [20,  3,  6]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [23,  6,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9383430480957031, 'inference': 16.32237434387207, 'postprocess': 0.9195804595947266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [27, 10, 13],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [36, 19, 22],\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [38, 21, 24],\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9066333770751953, 'inference': 16.327857971191406, 'postprocess': 0.9348392486572266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [27, 10, 13],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [36, 19, 22],\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [38, 21, 24],\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9466876983642578, 'inference': 16.32237434387207, 'postprocess': 0.9109973907470703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9733905792236328, 'inference': 16.339778900146484, 'postprocess': 0.9200572967529297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.89971923828125, 'inference': 16.33167266845703, 'postprocess': 0.9372234344482422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9104480743408203, 'inference': 16.333580017089844, 'postprocess': 0.9250640869140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9457340240478516, 'inference': 16.3424015045166, 'postprocess': 0.9317398071289062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.920938491821289, 'inference': 16.327619552612305, 'postprocess': 0.9276866912841797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.6144981384277344, 'inference': 16.321659088134766, 'postprocess': 0.9102821350097656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9767284393310547, 'inference': 16.32976531982422, 'postprocess': 0.9281635284423828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9702911376953125, 'inference': 16.324996948242188, 'postprocess': 0.9176731109619141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9114017486572266, 'inference': 16.334056854248047, 'postprocess': 0.92315673828125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.932382583618164, 'inference': 16.33453369140625, 'postprocess': 0.9267330169677734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9130706787109375, 'inference': 16.32547378540039, 'postprocess': 0.9329319000244141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.001523971557617, 'inference': 16.328096389770508, 'postprocess': 0.9806156158447266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8947124481201172, 'inference': 16.33286476135254, 'postprocess': 0.9567737579345703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[18, 15, 16],\n",
       "         [18, 15, 16],\n",
       "         [18, 15, 16],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9354820251464844, 'inference': 16.330242156982422, 'postprocess': 0.9160041809082031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[18, 15, 16],\n",
       "         [18, 15, 16],\n",
       "         [18, 15, 16],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8649101257324219, 'inference': 16.322851181030273, 'postprocess': 0.9262561798095703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[29, 26, 27],\n",
       "         [29, 26, 27],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8982887268066406, 'inference': 16.330480575561523, 'postprocess': 0.9577274322509766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[29, 26, 27],\n",
       "         [29, 26, 27],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9321441650390625, 'inference': 16.347646713256836, 'postprocess': 0.9198188781738281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[29, 26, 27],\n",
       "         [29, 26, 27],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9288063049316406, 'inference': 16.318798065185547, 'postprocess': 0.9365081787109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8703937530517578, 'inference': 16.31617546081543, 'postprocess': 0.9250640869140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8985271453857422, 'inference': 16.335725784301758, 'postprocess': 0.9665489196777344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9292831420898438, 'inference': 16.336679458618164, 'postprocess': 0.9181499481201172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.568960189819336, 'inference': 16.318082809448242, 'postprocess': 0.9183883666992188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9354820251464844, 'inference': 16.325950622558594, 'postprocess': 0.9229183197021484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.894235610961914, 'inference': 16.329288482666016, 'postprocess': 0.9143352508544922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.932382583618164, 'inference': 16.329050064086914, 'postprocess': 0.9217262268066406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9364356994628906, 'inference': 16.340970993041992, 'postprocess': 0.9508132934570312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9886493682861328, 'inference': 16.327619552612305, 'postprocess': 0.9260177612304688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9178390502929688, 'inference': 16.32094383239746, 'postprocess': 0.9202957153320312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9109249114990234, 'inference': 16.34359359741211, 'postprocess': 0.9427070617675781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 20],\n",
       "         [28, 13, 16],\n",
       "         [27, 12, 15]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 20],\n",
       "         [28, 13, 16],\n",
       "         [27, 12, 15]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 20],\n",
       "         [28, 13, 16],\n",
       "         [27, 12, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8951892852783203, 'inference': 16.338825225830078, 'postprocess': 0.9236335754394531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8305778503417969, 'inference': 16.33310317993164, 'postprocess': 0.9267330169677734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8990039825439453, 'inference': 16.34502410888672, 'postprocess': 0.9186267852783203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9481182098388672, 'inference': 16.339540481567383, 'postprocess': 0.9200572967529297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9345283508300781, 'inference': 16.337156295776367, 'postprocess': 0.9241104125976562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.89208984375, 'inference': 16.329526901245117, 'postprocess': 0.9257793426513672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9447803497314453, 'inference': 16.348600387573242, 'postprocess': 0.9303092956542969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9419193267822266, 'inference': 16.328096389770508, 'postprocess': 0.9479522705078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.6993751525878906, 'inference': 16.33739471435547, 'postprocess': 0.9162425994873047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.924753189086914, 'inference': 16.33429527282715, 'postprocess': 0.9255409240722656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.931905746459961, 'inference': 16.324996948242188, 'postprocess': 0.9260177612304688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.928567886352539, 'inference': 16.33453369140625, 'postprocess': 0.9274482727050781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9061565399169922, 'inference': 16.313552856445312, 'postprocess': 0.9310245513916016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9273757934570312, 'inference': 16.339540481567383, 'postprocess': 0.9205341339111328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.941680908203125, 'inference': 16.324520111083984, 'postprocess': 0.9238719940185547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9328594207763672, 'inference': 16.334056854248047, 'postprocess': 0.9248256683349609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9369125366210938, 'inference': 16.33453369140625, 'postprocess': 0.9326934814453125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.832723617553711, 'inference': 16.326904296875, 'postprocess': 0.9317398071289062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8901824951171875, 'inference': 16.353845596313477, 'postprocess': 0.9336471557617188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8908977508544922, 'inference': 16.323328018188477, 'postprocess': 0.9453296661376953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.015829086303711, 'inference': 16.337871551513672, 'postprocess': 0.9217262268066406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9571781158447266, 'inference': 16.332387924194336, 'postprocess': 0.93841552734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8968582153320312, 'inference': 16.330242156982422, 'postprocess': 0.9276866912841797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.909494400024414, 'inference': 16.34049415588379, 'postprocess': 0.9555816650390625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.7074813842773438, 'inference': 16.328811645507812, 'postprocess': 0.9293556213378906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9388198852539062, 'inference': 16.324520111083984, 'postprocess': 0.9329319000244141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0151138305664062, 'inference': 16.33739471435547, 'postprocess': 0.9338855743408203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9762516021728516, 'inference': 16.329050064086914, 'postprocess': 0.9398460388183594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9202232360839844, 'inference': 16.329050064086914, 'postprocess': 0.9827613830566406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.962423324584961, 'inference': 16.324281692504883, 'postprocess': 0.9670257568359375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.943826675415039, 'inference': 16.335487365722656, 'postprocess': 0.9262561798095703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9717216491699219, 'inference': 16.33620262145996, 'postprocess': 0.9400844573974609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9083023071289062, 'inference': 16.355037689208984, 'postprocess': 0.9205341339111328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8570423126220703, 'inference': 16.34383201599121, 'postprocess': 0.9343624114990234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9097328186035156, 'inference': 16.33620262145996, 'postprocess': 0.9312629699707031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9254684448242188, 'inference': 16.32380485534668, 'postprocess': 0.9136199951171875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9383430480957031, 'inference': 16.338348388671875, 'postprocess': 0.9205341339111328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.007007598876953, 'inference': 16.349315643310547, 'postprocess': 0.9551048278808594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9040107727050781, 'inference': 16.330480575561523, 'postprocess': 0.9260177612304688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9130706787109375, 'inference': 16.318559646606445, 'postprocess': 0.92315673828125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.862691879272461, 'inference': 16.390323638916016, 'postprocess': 0.9241104125976562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9252300262451172, 'inference': 16.33453369140625, 'postprocess': 0.9298324584960938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9421577453613281, 'inference': 16.33596420288086, 'postprocess': 0.9272098541259766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9121170043945312, 'inference': 16.33286476135254, 'postprocess': 0.9369850158691406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9044876098632812, 'inference': 16.338109970092773, 'postprocess': 0.9207725524902344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9118785858154297, 'inference': 16.33620262145996, 'postprocess': 0.9250640869140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.878976821899414, 'inference': 16.330480575561523, 'postprocess': 0.9250640869140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 15, 20],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9173622131347656, 'inference': 16.330957412719727, 'postprocess': 0.9214878082275391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 15, 20],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9252300262451172, 'inference': 16.354799270629883, 'postprocess': 0.9200572967529297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.825094223022461, 'inference': 16.355514526367188, 'postprocess': 0.9305477142333984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9199848175048828, 'inference': 16.35122299194336, 'postprocess': 0.9102821350097656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0072460174560547, 'inference': 16.32833480834961, 'postprocess': 0.9508132934570312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9800662994384766, 'inference': 16.351938247680664, 'postprocess': 0.9112358093261719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9958019256591797, 'inference': 16.33906364440918, 'postprocess': 0.9548664093017578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9221305847167969, 'inference': 16.341686248779297, 'postprocess': 0.9272098541259766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.956939697265625, 'inference': 16.330242156982422, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.353668212890625, 'inference': 16.335010528564453, 'postprocess': 0.9524822235107422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [21,  5, 10],\n",
       "         [17,  1,  6]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [28, 12, 17],\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [28, 12, 17],\n",
       "         [25,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9576549530029297, 'inference': 16.344785690307617, 'postprocess': 0.9255409240722656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [21,  5, 10],\n",
       "         [17,  1,  6]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [28, 12, 17],\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [28, 12, 17],\n",
       "         [25,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9712448120117188, 'inference': 16.35575294494629, 'postprocess': 0.9181499481201172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [21,  5, 10],\n",
       "         [17,  1,  6]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [28, 12, 17],\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [28, 12, 17],\n",
       "         [25,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.958608627319336, 'inference': 16.335487365722656, 'postprocess': 0.9181499481201172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [21,  5, 10],\n",
       "         [17,  1,  6]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [28, 12, 17],\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [28, 12, 17],\n",
       "         [25,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9943714141845703, 'inference': 16.326189041137695, 'postprocess': 0.9455680847167969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9648075103759766, 'inference': 16.330718994140625, 'postprocess': 0.9212493896484375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9657611846923828, 'inference': 16.371488571166992, 'postprocess': 0.9195804595947266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0952224731445312, 'inference': 16.336917877197266, 'postprocess': 0.9210109710693359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9829273223876953, 'inference': 16.344547271728516, 'postprocess': 0.9217262268066406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.934051513671875, 'inference': 16.341447830200195, 'postprocess': 0.9093284606933594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9772052764892578, 'inference': 16.35885238647461, 'postprocess': 0.9255409240722656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0127296447753906, 'inference': 16.33930206298828, 'postprocess': 0.9171962738037109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.032041549682617, 'inference': 16.335725784301758, 'postprocess': 0.9207725524902344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9521713256835938, 'inference': 16.358375549316406, 'postprocess': 0.9167194366455078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9457340240478516, 'inference': 16.330480575561523, 'postprocess': 0.9145736694335938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9803047180175781, 'inference': 16.327857971191406, 'postprocess': 0.9214878082275391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.766847610473633, 'inference': 16.323089599609375, 'postprocess': 0.9183883666992188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9254684448242188, 'inference': 16.31641387939453, 'postprocess': 0.9336471557617188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.985788345336914, 'inference': 16.324996948242188, 'postprocess': 0.9312629699707031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0003318786621094, 'inference': 16.338825225830078, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8856525421142578, 'inference': 16.34526252746582, 'postprocess': 1.0073184967041016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8830299377441406, 'inference': 16.32833480834961, 'postprocess': 0.9293556213378906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.897573471069336, 'inference': 16.333818435668945, 'postprocess': 0.9744167327880859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9054412841796875, 'inference': 16.332149505615234, 'postprocess': 0.9331703186035156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8928050994873047, 'inference': 16.321897506713867, 'postprocess': 0.9157657623291016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8434524536132812, 'inference': 16.335725784301758, 'postprocess': 0.9379386901855469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.886606216430664, 'inference': 16.329288482666016, 'postprocess': 0.942230224609375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9190311431884766, 'inference': 16.321182250976562, 'postprocess': 0.9274482727050781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8706321716308594, 'inference': 16.35265350341797, 'postprocess': 0.9589195251464844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8961429595947266, 'inference': 16.353130340576172, 'postprocess': 0.9264945983886719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9021034240722656, 'inference': 16.32380485534668, 'postprocess': 0.9219646453857422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8839836120605469, 'inference': 16.329288482666016, 'postprocess': 0.9315013885498047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.9561519622802734, 'inference': 16.33000373840332, 'postprocess': 0.9241104125976562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [23, 10, 14],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [32, 19, 23],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[22, 17, 18],\n",
       "         [22, 17, 18],\n",
       "         [23, 18, 19],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9080638885498047, 'inference': 16.331911087036133, 'postprocess': 0.9217262268066406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [32, 19, 23],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [32, 19, 23],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[22, 17, 18],\n",
       "         [22, 17, 18],\n",
       "         [23, 18, 19],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8949508666992188, 'inference': 16.33739471435547, 'postprocess': 0.9257793426513672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9075870513916016, 'inference': 16.734600067138672, 'postprocess': 0.9238719940185547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9116401672363281, 'inference': 16.33620262145996, 'postprocess': 0.9176731109619141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9078254699707031, 'inference': 16.32523536682129, 'postprocess': 0.9274482727050781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9304752349853516, 'inference': 16.3266658782959, 'postprocess': 0.9326934814453125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9202232360839844, 'inference': 16.315937042236328, 'postprocess': 0.9212493896484375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9025802612304688, 'inference': 16.322612762451172, 'postprocess': 0.9191036224365234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9414424896240234, 'inference': 16.320228576660156, 'postprocess': 0.9298324584960938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9383430480957031, 'inference': 16.33429527282715, 'postprocess': 0.9253025054931641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.947641372680664, 'inference': 16.33429527282715, 'postprocess': 0.9238719940185547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [18, 14, 17],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9345283508300781, 'inference': 16.327857971191406, 'postprocess': 0.9229183197021484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9254684448242188, 'inference': 16.332149505615234, 'postprocess': 0.9298324584960938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8985271453857422, 'inference': 16.32976531982422, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [17, 13, 16],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9195079803466797, 'inference': 16.33286476135254, 'postprocess': 0.9334087371826172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [21, 17, 20],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [30, 18, 20],\n",
       "         [32, 20, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.958059310913086, 'inference': 16.330957412719727, 'postprocess': 0.9431838989257812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [21, 17, 20],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [30, 18, 20],\n",
       "         [32, 20, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9621849060058594, 'inference': 16.332149505615234, 'postprocess': 0.9162425994873047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]],\n",
       " \n",
       "        [[25, 21, 24],\n",
       "         [26, 22, 25],\n",
       "         [28, 24, 27],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [30, 18, 20],\n",
       "         [32, 20, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.951456069946289, 'inference': 16.330957412719727, 'postprocess': 0.9169578552246094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [23, 15, 17]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [24, 16, 18],\n",
       "         [24, 16, 18]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [22, 18, 21],\n",
       "         [25, 21, 24],\n",
       "         ...,\n",
       "         [26, 18, 20],\n",
       "         [26, 18, 20],\n",
       "         [28, 20, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.978158950805664, 'inference': 16.332149505615234, 'postprocess': 0.9207725524902344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [21, 13, 15],\n",
       "         [21, 13, 15]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [22, 18, 21],\n",
       "         [25, 21, 24],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [25, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9640922546386719, 'inference': 16.33286476135254, 'postprocess': 0.957489013671875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [21, 13, 15],\n",
       "         [21, 13, 15]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [22, 18, 21],\n",
       "         [25, 21, 24],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [25, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9109249114990234, 'inference': 16.338825225830078, 'postprocess': 0.9152889251708984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [21, 13, 15],\n",
       "         [21, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [25, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9054412841796875, 'inference': 16.337156295776367, 'postprocess': 0.9284019470214844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [21, 13, 15],\n",
       "         [21, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [25, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.936197280883789, 'inference': 16.322851181030273, 'postprocess': 0.9453296661376953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [21, 13, 15],\n",
       "         [21, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [25, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.897573471069336, 'inference': 16.326189041137695, 'postprocess': 0.9248256683349609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [29, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9223690032958984, 'inference': 16.333580017089844, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [29, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8830299377441406, 'inference': 16.330242156982422, 'postprocess': 0.9198188781738281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [29, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9328594207763672, 'inference': 16.330957412719727, 'postprocess': 0.9469985961914062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [29, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9567012786865234, 'inference': 16.315937042236328, 'postprocess': 0.9191036224365234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9774436950683594, 'inference': 16.31951332092285, 'postprocess': 0.9260177612304688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9102096557617188, 'inference': 16.317367553710938, 'postprocess': 0.9250640869140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [28, 16, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.920938491821289, 'inference': 16.356468200683594, 'postprocess': 0.9336471557617188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [28, 16, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 3.006458282470703, 'inference': 16.330480575561523, 'postprocess': 0.9732246398925781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [27, 12, 15],\n",
       "         [25, 10, 13],\n",
       "         [27, 12, 15]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [29, 14, 17],\n",
       "         [29, 14, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [31, 16, 19],\n",
       "         [30, 15, 18],\n",
       "         [31, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8873214721679688, 'inference': 16.360044479370117, 'postprocess': 0.9419918060302734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [28, 16, 18],\n",
       "         [29, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8939971923828125, 'inference': 16.326904296875, 'postprocess': 0.9295940399169922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [23, 13, 15]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [25, 15, 17],\n",
       "         [25, 15, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [26, 16, 18],\n",
       "         [27, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9092559814453125, 'inference': 16.343116760253906, 'postprocess': 0.9286403656005859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [23, 13, 15]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [25, 15, 17],\n",
       "         [25, 15, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [26, 16, 18],\n",
       "         [27, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9350051879882812, 'inference': 16.312360763549805, 'postprocess': 0.9157657623291016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9183158874511719, 'inference': 16.324758529663086, 'postprocess': 0.9181499481201172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.909494400024414, 'inference': 16.342878341674805, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9717216491699219, 'inference': 16.33596420288086, 'postprocess': 0.9236335754394531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9114017486572266, 'inference': 16.338586807250977, 'postprocess': 0.9598731994628906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8548965454101562, 'inference': 16.32833480834961, 'postprocess': 0.9534358978271484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8856525421142578, 'inference': 16.323566436767578, 'postprocess': 0.9353160858154297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9066333770751953, 'inference': 16.329526901245117, 'postprocess': 0.9200572967529297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8961429595947266, 'inference': 16.336917877197266, 'postprocess': 0.9279251098632812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  4,  4],\n",
       "         [ 4,  4,  4],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]],\n",
       " \n",
       "        [[ 5,  5,  5],\n",
       "         [ 5,  5,  5],\n",
       "         [ 4,  4,  4],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [25, 15, 17],\n",
       "         [26, 16, 18]],\n",
       " \n",
       "        [[17, 17, 17],\n",
       "         [17, 17, 17],\n",
       "         [18, 18, 18],\n",
       "         ...,\n",
       "         [28, 18, 20],\n",
       "         [27, 17, 19],\n",
       "         [28, 18, 20]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8856525421142578, 'inference': 16.33429527282715, 'postprocess': 0.9171962738037109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13],\n",
       "         [24, 14, 14]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [25, 15, 15],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [26, 16, 16],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9423961639404297, 'inference': 16.333580017089844, 'postprocess': 0.9257793426513672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9178390502929688, 'inference': 16.32857322692871, 'postprocess': 0.9212493896484375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.8417110443115234, 'inference': 16.388416290283203, 'postprocess': 0.949859619140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9388198852539062, 'inference': 16.32523536682129, 'postprocess': 0.9300708770751953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9612312316894531, 'inference': 16.32404327392578, 'postprocess': 0.9245872497558594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8885135650634766, 'inference': 16.35432243347168, 'postprocess': 0.9281635284423828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 11, 16],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [29, 13, 18],\n",
       "         [28, 12, 17],\n",
       "         [29, 13, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8908977508544922, 'inference': 16.34669303894043, 'postprocess': 0.9360313415527344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 11, 16],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [29, 13, 18],\n",
       "         [28, 12, 17],\n",
       "         [29, 13, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8756389617919922, 'inference': 16.326189041137695, 'postprocess': 0.9250640869140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9042491912841797, 'inference': 16.321897506713867, 'postprocess': 0.9484291076660156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [12,  9, 10],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [29, 26, 27],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.903533935546875, 'inference': 16.341447830200195, 'postprocess': 0.9608268737792969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [12,  9, 10],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [29, 26, 27],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8935203552246094, 'inference': 16.32380485534668, 'postprocess': 0.926971435546875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13],\n",
       "         [24, 14, 14]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [12,  9, 10],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [25, 15, 15],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [29, 26, 27],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8815994262695312, 'inference': 16.335487365722656, 'postprocess': 0.9407997131347656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13],\n",
       "         [24, 14, 14]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [12,  9, 10],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [25, 15, 15],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [29, 26, 27],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9817352294921875, 'inference': 16.33906364440918, 'postprocess': 0.9310245513916016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13],\n",
       "         [24, 14, 14]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [12,  9, 10],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [25, 15, 15],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [29, 26, 27],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9016265869140625, 'inference': 16.344308853149414, 'postprocess': 0.9281635284423828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [31, 11, 13],\n",
       "         [31, 11, 13],\n",
       "         [32, 12, 14]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [33, 13, 15],\n",
       "         [33, 13, 15],\n",
       "         [34, 14, 16]],\n",
       " \n",
       "        [[28, 25, 26],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [35, 15, 17],\n",
       "         [35, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9605159759521484, 'inference': 16.328096389770508, 'postprocess': 0.9222030639648438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [22, 10, 10],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 13, 13],\n",
       "         [23, 11, 11],\n",
       "         [25, 13, 13]],\n",
       " \n",
       "        [[28, 25, 26],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9233226776123047, 'inference': 16.321897506713867, 'postprocess': 0.9572505950927734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [22, 10, 10],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 13, 13],\n",
       "         [23, 11, 11],\n",
       "         [25, 13, 13]],\n",
       " \n",
       "        [[28, 25, 26],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8970966339111328, 'inference': 16.32547378540039, 'postprocess': 0.9214878082275391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.890420913696289, 'inference': 16.312599182128906, 'postprocess': 0.9253025054931641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.9294490814208984, 'inference': 16.324996948242188, 'postprocess': 0.9555816650390625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9381046295166016, 'inference': 16.334056854248047, 'postprocess': 0.9481906890869141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.947641372680664, 'inference': 16.335010528564453, 'postprocess': 0.9491443634033203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0155906677246094, 'inference': 16.341447830200195, 'postprocess': 0.9179115295410156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.950979232788086, 'inference': 16.32404327392578, 'postprocess': 0.9169578552246094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9712448120117188, 'inference': 16.329050064086914, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9903182983398438, 'inference': 16.327619552612305, 'postprocess': 0.9162425994873047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.972198486328125, 'inference': 16.332387924194336, 'postprocess': 0.9238719940185547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [24, 14, 14],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [26, 16, 16],\n",
       "         [27, 17, 17]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.943349838256836, 'inference': 16.321420669555664, 'postprocess': 0.9510517120361328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [24, 14, 14],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [26, 16, 16],\n",
       "         [27, 17, 17]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8265247344970703, 'inference': 16.35599136352539, 'postprocess': 0.9238719940185547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [24, 12, 19],\n",
       "         [26, 14, 21]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [26, 14, 21],\n",
       "         [27, 15, 22]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [27, 15, 22],\n",
       "         [27, 15, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9218921661376953, 'inference': 16.346454620361328, 'postprocess': 0.9174346923828125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [24, 12, 19],\n",
       "         [26, 14, 21]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [26, 14, 21],\n",
       "         [27, 15, 22]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [27, 15, 22],\n",
       "         [27, 15, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9683837890625, 'inference': 16.33429527282715, 'postprocess': 0.9183883666992188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9540786743164062, 'inference': 16.329526901245117, 'postprocess': 0.9205341339111328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[35, 30, 31],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9485950469970703, 'inference': 16.329526901245117, 'postprocess': 0.9279251098632812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[35, 30, 31],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.88446044921875, 'inference': 16.327619552612305, 'postprocess': 0.9646415710449219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[22, 17, 18],\n",
       "         [22, 17, 18],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[26, 21, 22],\n",
       "         [26, 21, 22],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         [31, 26, 27],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9729137420654297, 'inference': 16.3116455078125, 'postprocess': 0.9303092956542969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[33, 28, 29],\n",
       "         [33, 28, 29],\n",
       "         [31, 26, 27],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[40, 35, 36],\n",
       "         [40, 35, 36],\n",
       "         [38, 33, 34],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[40, 35, 36],\n",
       "         [40, 35, 36],\n",
       "         [40, 35, 36],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.8944015502929688, 'inference': 16.376733779907227, 'postprocess': 0.9291172027587891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[40, 35, 36],\n",
       "         [40, 35, 36],\n",
       "         [40, 35, 36],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[38, 33, 34],\n",
       "         [38, 33, 34],\n",
       "         [38, 33, 34],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[38, 33, 34],\n",
       "         [38, 33, 34],\n",
       "         [38, 33, 34],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9483566284179688, 'inference': 16.329526901245117, 'postprocess': 0.9202957153320312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[35, 30, 31],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [35, 30, 31],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9364356994628906, 'inference': 16.329288482666016, 'postprocess': 0.9260177612304688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.007007598876953, 'inference': 16.31927490234375, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9304752349853516, 'inference': 16.333341598510742, 'postprocess': 0.9236335754394531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[40, 30, 32],\n",
       "         [40, 30, 32],\n",
       "         [40, 30, 32],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[41, 31, 33],\n",
       "         [41, 31, 33],\n",
       "         [41, 31, 33],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[41, 31, 33],\n",
       "         [41, 31, 33],\n",
       "         [41, 31, 33],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9483566284179688, 'inference': 16.330957412719727, 'postprocess': 0.9253025054931641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9915103912353516, 'inference': 16.339778900146484, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.953125, 'inference': 16.3266658782959, 'postprocess': 0.9496212005615234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9314289093017578, 'inference': 16.315698623657227, 'postprocess': 0.9379386901855469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.909017562866211, 'inference': 16.334056854248047, 'postprocess': 0.9281635284423828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8961429595947266, 'inference': 16.31903648376465, 'postprocess': 0.9219646453857422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8932819366455078, 'inference': 16.346454620361328, 'postprocess': 0.9527206420898438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9495487213134766, 'inference': 16.352415084838867, 'postprocess': 0.9515285491943359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[33, 23, 25],\n",
       "         [33, 23, 25],\n",
       "         [34, 24, 26],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [24,  9, 12],\n",
       "         [25, 10, 13]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [35, 20, 23],\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8782615661621094, 'inference': 16.35265350341797, 'postprocess': 0.9551048278808594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 24, 26],\n",
       "         [34, 24, 26],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [24,  9, 12],\n",
       "         [25, 10, 13]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [35, 20, 23],\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.918792724609375, 'inference': 16.335248947143555, 'postprocess': 0.9214878082275391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 24, 26],\n",
       "         [34, 24, 26],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [20,  5,  8],\n",
       "         [23,  8, 11],\n",
       "         [23,  8, 11]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [32, 17, 20],\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9321441650390625, 'inference': 16.329526901245117, 'postprocess': 0.9143352508544922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 24, 26],\n",
       "         [34, 24, 26],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 3.0677318572998047, 'inference': 16.325950622558594, 'postprocess': 0.911712646484375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 24, 26],\n",
       "         [34, 24, 26],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9123554229736328, 'inference': 16.337871551513672, 'postprocess': 0.9846687316894531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 24, 26],\n",
       "         [34, 24, 26],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.934051513671875, 'inference': 16.32404327392578, 'postprocess': 0.9248256683349609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9147396087646484, 'inference': 16.335725784301758, 'postprocess': 0.95367431640625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9202232360839844, 'inference': 16.324758529663086, 'postprocess': 0.919342041015625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9037723541259766, 'inference': 16.33477210998535, 'postprocess': 0.9236335754394531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9252300262451172, 'inference': 16.33143424987793, 'postprocess': 0.9245872497558594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9183158874511719, 'inference': 16.326904296875, 'postprocess': 0.9510517120361328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [21,  6,  9],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.962900161743164, 'inference': 16.335725784301758, 'postprocess': 0.9157657623291016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [21,  6,  9],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8832683563232422, 'inference': 16.351699829101562, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9521713256835938, 'inference': 16.324758529663086, 'postprocess': 0.9224414825439453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9075870513916016, 'inference': 16.33167266845703, 'postprocess': 0.9210109710693359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8951892852783203, 'inference': 16.33429527282715, 'postprocess': 0.9496212005615234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9690990447998047, 'inference': 16.326904296875, 'postprocess': 0.9102821350097656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8911361694335938, 'inference': 16.31951332092285, 'postprocess': 0.9329319000244141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[28, 24, 27],\n",
       "         [28, 24, 27],\n",
       "         [27, 23, 26],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[29, 25, 28],\n",
       "         [29, 25, 28],\n",
       "         [29, 25, 28],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.909017562866211, 'inference': 16.330957412719727, 'postprocess': 0.919342041015625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[28, 24, 27],\n",
       "         [28, 24, 27],\n",
       "         [27, 23, 26],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[29, 25, 28],\n",
       "         [29, 25, 28],\n",
       "         [29, 25, 28],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.927064895629883, 'inference': 16.343116760253906, 'postprocess': 0.9579658508300781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[25, 21, 24],\n",
       "         [25, 21, 24],\n",
       "         [25, 21, 24],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [26, 22, 25],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9195079803466797, 'inference': 16.333341598510742, 'postprocess': 0.9169578552246094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[25, 21, 24],\n",
       "         [25, 21, 24],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9235610961914062, 'inference': 16.33167266845703, 'postprocess': 0.9195804595947266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[13,  9, 12],\n",
       "         [13,  9, 12],\n",
       "         [13,  9, 12],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9288063049316406, 'inference': 16.32404327392578, 'postprocess': 0.9708404541015625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9116401672363281, 'inference': 16.332149505615234, 'postprocess': 0.9276866912841797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9168853759765625, 'inference': 16.322851181030273, 'postprocess': 0.9179115295410156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8913745880126953, 'inference': 16.356468200683594, 'postprocess': 0.9171962738037109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9352436065673828, 'inference': 16.347646713256836, 'postprocess': 0.9272098541259766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9364356994628906, 'inference': 16.34502410888672, 'postprocess': 0.9162425994873047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9414424896240234, 'inference': 16.348838806152344, 'postprocess': 0.9334087371826172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9292831420898438, 'inference': 16.332626342773438, 'postprocess': 0.9336471557617188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9316673278808594, 'inference': 16.327381134033203, 'postprocess': 0.9462833404541016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.924753189086914, 'inference': 16.341686248779297, 'postprocess': 0.9036064147949219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9140243530273438, 'inference': 16.332387924194336, 'postprocess': 0.965118408203125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.924276351928711, 'inference': 16.34383201599121, 'postprocess': 0.9245872497558594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9619464874267578, 'inference': 16.335725784301758, 'postprocess': 1.0647773742675781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 3.0460357666015625, 'inference': 16.31927490234375, 'postprocess': 0.9095668792724609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9137859344482422, 'inference': 16.330718994140625, 'postprocess': 0.9284019470214844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9299983978271484, 'inference': 16.340970993041992, 'postprocess': 0.9303092956542969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9485950469970703, 'inference': 16.329526901245117, 'postprocess': 0.9276866912841797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9345283508300781, 'inference': 16.333818435668945, 'postprocess': 0.9212493896484375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9068717956542969, 'inference': 16.329526901245117, 'postprocess': 0.9281635284423828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.0825862884521484, 'inference': 16.33310317993164, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9528865814208984, 'inference': 16.327381134033203, 'postprocess': 0.9181499481201172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9061565399169922, 'inference': 16.339778900146484, 'postprocess': 0.9264945983886719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9364356994628906, 'inference': 16.31760597229004, 'postprocess': 0.9179115295410156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8565654754638672, 'inference': 16.32547378540039, 'postprocess': 0.9634494781494141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9345283508300781, 'inference': 16.334056854248047, 'postprocess': 0.9167194366455078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.882791519165039, 'inference': 16.33739471435547, 'postprocess': 0.9241104125976562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.939535140991211, 'inference': 16.32547378540039, 'postprocess': 0.9143352508544922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.882791519165039, 'inference': 16.329288482666016, 'postprocess': 0.9305477142333984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [19,  7,  7],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [25, 13, 13],\n",
       "         [22, 10, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [27, 15, 15],\n",
       "         [25, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8913745880126953, 'inference': 16.32380485534668, 'postprocess': 1.06048583984375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [19,  7,  7],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [25, 13, 13],\n",
       "         [22, 10, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [27, 15, 15],\n",
       "         [25, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.99072265625, 'inference': 16.751766204833984, 'postprocess': 0.9028911590576172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.934051513671875, 'inference': 16.31450653076172, 'postprocess': 0.9202957153320312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.893758773803711, 'inference': 16.32547378540039, 'postprocess': 0.9295940399169922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9221305847167969, 'inference': 16.34693145751953, 'postprocess': 0.9140968322753906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.973867416381836, 'inference': 16.318559646606445, 'postprocess': 0.9181499481201172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9030570983886719, 'inference': 16.33143424987793, 'postprocess': 0.9198188781738281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.924276351928711, 'inference': 16.31784439086914, 'postprocess': 0.9195804595947266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8889904022216797, 'inference': 16.331195831298828, 'postprocess': 0.9348392486572266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.890420913696289, 'inference': 16.344547271728516, 'postprocess': 0.9195804595947266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25,  8,  9],\n",
       "         [20,  3,  4],\n",
       "         [18,  1,  2]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [29, 12, 13],\n",
       "         [24,  7,  8],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [27, 10, 11],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8804073333740234, 'inference': 16.324281692504883, 'postprocess': 0.9663105010986328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [22,  5,  6],\n",
       "         [19,  2,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [25,  8,  9],\n",
       "         [23,  6,  7]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [32, 15, 16],\n",
       "         [27, 10, 11],\n",
       "         [26,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9669532775878906, 'inference': 16.318321228027344, 'postprocess': 0.9186267852783203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  5,  6],\n",
       "         [17,  0,  1],\n",
       "         [15,  0,  0]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [25,  8,  9],\n",
       "         [19,  2,  3],\n",
       "         [17,  0,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [20,  3,  4]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9307136535644531, 'inference': 16.34669303894043, 'postprocess': 0.9112358093261719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  5,  6],\n",
       "         [17,  0,  1],\n",
       "         [15,  0,  0]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [25,  8,  9],\n",
       "         [19,  2,  3],\n",
       "         [17,  0,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [20,  3,  4]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8768310546875, 'inference': 16.35003089904785, 'postprocess': 0.9510517120361328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  5,  6],\n",
       "         [17,  0,  1],\n",
       "         [15,  0,  0]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [25,  8,  9],\n",
       "         [19,  2,  3],\n",
       "         [17,  0,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [20,  3,  4]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8889904022216797, 'inference': 16.37864112854004, 'postprocess': 0.9126663208007812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [19,  2,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.886606216430664, 'inference': 16.322851181030273, 'postprocess': 0.9274482727050781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [19,  2,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9245147705078125, 'inference': 16.31903648376465, 'postprocess': 0.9145736694335938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [20,  3,  4],\n",
       "         [18,  1,  2]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.953052520751953, 'inference': 16.32976531982422, 'postprocess': 0.9183883666992188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [20,  3,  4],\n",
       "         [19,  2,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9066333770751953, 'inference': 16.321897506713867, 'postprocess': 0.9219646453857422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [20,  3,  4],\n",
       "         [19,  2,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9848346710205078, 'inference': 16.340255737304688, 'postprocess': 0.9250640869140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [19,  2,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9369125366210938, 'inference': 16.329288482666016, 'postprocess': 0.9133815765380859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [19,  2,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9383430480957031, 'inference': 16.329288482666016, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [22,  4,  9],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [23,  5, 10],\n",
       "         [22,  4,  9]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [25,  7, 12],\n",
       "         [24,  6, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9233226776123047, 'inference': 16.3266658782959, 'postprocess': 0.91552734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [25,  7, 12],\n",
       "         [22,  4,  9]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [36, 18, 23],\n",
       "         [27,  9, 14],\n",
       "         [24,  6, 11]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [36, 18, 23],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9383430480957031, 'inference': 16.327619552612305, 'postprocess': 0.9615421295166016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [19,  6, 10],\n",
       "         [18,  5,  9]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [21,  8, 12],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [21,  8, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9640922546386719, 'inference': 16.31760597229004, 'postprocess': 0.9229183197021484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [19,  6, 10],\n",
       "         [18,  5,  9]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [21,  8, 12],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [21,  8, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8966197967529297, 'inference': 16.341447830200195, 'postprocess': 0.9160041809082031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13,  8],\n",
       "         [19,  9,  4],\n",
       "         [18,  8,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 16, 11],\n",
       "         [21, 11,  6],\n",
       "         [20, 10,  5]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 17, 12],\n",
       "         [22, 12,  7],\n",
       "         [21, 11,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8849372863769531, 'inference': 16.314268112182617, 'postprocess': 0.9586811065673828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [19,  7,  7],\n",
       "         [18,  6,  6]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [21,  9,  9],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [22, 10, 10],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8868446350097656, 'inference': 16.326904296875, 'postprocess': 0.9241104125976562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [19,  7,  7],\n",
       "         [18,  6,  6]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [21,  9,  9],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [22, 10, 10],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.875162124633789, 'inference': 16.327857971191406, 'postprocess': 0.91552734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [19,  7,  7],\n",
       "         [18,  6,  6]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [21,  9,  9],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [22, 10, 10],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.91497802734375, 'inference': 16.34359359741211, 'postprocess': 0.9145736694335938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9006729125976562, 'inference': 16.33596420288086, 'postprocess': 0.9229183197021484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8794536590576172, 'inference': 16.32380485534668, 'postprocess': 0.9362697601318359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8939971923828125, 'inference': 16.33310317993164, 'postprocess': 0.9140968322753906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 2.932310104370117, 'inference': 16.369104385375977, 'postprocess': 0.9152889251708984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8982887268066406, 'inference': 16.319990158081055, 'postprocess': 0.9257793426513672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8815994262695312, 'inference': 16.326189041137695, 'postprocess': 0.9217262268066406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8949508666992188, 'inference': 16.322851181030273, 'postprocess': 0.9245872497558594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8880367279052734, 'inference': 16.360044479370117, 'postprocess': 0.9479522705078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8765926361083984, 'inference': 16.35122299194336, 'postprocess': 0.9775161743164062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [19,  7,  7],\n",
       "         [18,  6,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [21,  9,  9],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [22, 10, 10],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8818378448486328, 'inference': 16.324758529663086, 'postprocess': 0.9338855743408203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.890420913696289, 'inference': 16.340017318725586, 'postprocess': 0.9226799011230469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8811225891113281, 'inference': 16.33596420288086, 'postprocess': 0.9162425994873047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.956939697265625, 'inference': 16.34812355041504, 'postprocess': 0.9210109710693359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9414424896240234, 'inference': 16.324281692504883, 'postprocess': 0.9076595306396484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9054412841796875, 'inference': 16.336679458618164, 'postprocess': 0.9164810180664062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8837451934814453, 'inference': 16.319751739501953, 'postprocess': 0.9837150573730469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8985271453857422, 'inference': 16.35885238647461, 'postprocess': 0.9307861328125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9626617431640625, 'inference': 16.330480575561523, 'postprocess': 0.9229183197021484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8830299377441406, 'inference': 16.329050064086914, 'postprocess': 0.9224414825439453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 3.0159950256347656, 'inference': 16.354084014892578, 'postprocess': 0.9198188781738281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [18,  8, 10],\n",
       "         [10,  0,  2],\n",
       "         [ 6,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [13,  3,  5],\n",
       "         [10,  0,  2]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [16,  6,  8],\n",
       "         [12,  2,  4]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.911163330078125, 'inference': 16.32547378540039, 'postprocess': 0.9212493896484375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [18,  8, 10],\n",
       "         [10,  0,  2],\n",
       "         [ 6,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [13,  3,  5],\n",
       "         [10,  0,  2]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [16,  6,  8],\n",
       "         [12,  2,  4]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9161701202392578, 'inference': 16.3271427154541, 'postprocess': 0.9236335754394531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [17,  7,  9],\n",
       "         [13,  3,  5]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [20, 10, 12],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9214153289794922, 'inference': 16.32237434387207, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9736289978027344, 'inference': 16.37434959411621, 'postprocess': 0.9143352508544922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.911163330078125, 'inference': 16.329526901245117, 'postprocess': 0.9245872497558594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.893758773803711, 'inference': 16.320228576660156, 'postprocess': 0.9157657623291016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [21,  8, 12],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [27, 14, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8856525421142578, 'inference': 16.360998153686523, 'postprocess': 0.9219646453857422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9414424896240234, 'inference': 16.33167266845703, 'postprocess': 0.9584426879882812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8854141235351562, 'inference': 16.326427459716797, 'postprocess': 0.9183883666992188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9502639770507812, 'inference': 16.328096389770508, 'postprocess': 0.9076595306396484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8739700317382812, 'inference': 16.309738159179688, 'postprocess': 0.9062290191650391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [21,  8, 12],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [27, 14, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.7859935760498047, 'inference': 16.323328018188477, 'postprocess': 0.9090900421142578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [21,  8, 12],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [27, 14, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8172264099121094, 'inference': 16.325950622558594, 'postprocess': 0.9112358093261719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [18,  5,  9],\n",
       "         [18,  5,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [21,  8, 12],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8808841705322266, 'inference': 16.320466995239258, 'postprocess': 0.9136199951171875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [20,  7, 11],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [22,  9, 13],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [26, 13, 17],\n",
       "         [26, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.7843246459960938, 'inference': 16.33167266845703, 'postprocess': 0.9541511535644531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [20,  7, 11],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [22,  9, 13],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [26, 13, 17],\n",
       "         [26, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8241405487060547, 'inference': 16.317367553710938, 'postprocess': 0.9608268737792969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [24,  6, 11],\n",
       "         [23,  5, 10],\n",
       "         [23,  5, 10]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9066333770751953, 'inference': 16.329526901245117, 'postprocess': 0.9076595306396484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [25,  7, 12],\n",
       "         [24,  6, 11],\n",
       "         [24,  6, 11]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8253326416015625, 'inference': 16.326427459716797, 'postprocess': 0.9224414825439453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [25,  7, 12],\n",
       "         [24,  6, 11],\n",
       "         [24,  6, 11]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8897056579589844, 'inference': 16.326904296875, 'postprocess': 0.9419918060302734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [25,  7, 12],\n",
       "         [24,  6, 11],\n",
       "         [24,  6, 11]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8532276153564453, 'inference': 16.32094383239746, 'postprocess': 0.9100437164306641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 13],\n",
       "         [18,  6,  6],\n",
       "         [14,  2,  2]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [20,  8,  8],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [29, 17, 17],\n",
       "         [23, 11, 11],\n",
       "         [19,  7,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.8532276153564453, 'inference': 16.312837600708008, 'postprocess': 0.9081363677978516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [14,  2,  2],\n",
       "         [11,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [16,  4,  4],\n",
       "         [13,  1,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [20,  8,  8],\n",
       "         [15,  3,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9001960754394531, 'inference': 16.33739471435547, 'postprocess': 0.8985996246337891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [15,  3,  3],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [16,  4,  4],\n",
       "         [13,  1,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [20,  8,  8],\n",
       "         [15,  3,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9364356994628906, 'inference': 16.31951332092285, 'postprocess': 0.9095668792724609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [15,  3,  3],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [16,  4,  4],\n",
       "         [13,  1,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [20,  8,  8],\n",
       "         [15,  3,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict'\n",
       " speed: {'preprocess': 1.9195079803466797, 'inference': 16.32094383239746, 'postprocess': 0.9729862213134766}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel.predict(\"../GAM24_video.mp4\",save=True,imgsz=640,conf=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0ee709-4874-4b64-bcba-ce0a172f4327",
   "metadata": {},
   "source": [
    "## Train with a subset of the 50% of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64d898c0-5296-4540-944c-fc4a087e48a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 11:34:32.430785: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-11 11:34:32.446186: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-11 11:34:32.450648: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Selected Method:  SRS\n",
      "Selected reduction rate:  0.5\n",
      "There are 463 images in the path yolov8/wheelchair-detection-1/train\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8m.pt to 'yolov8m.pt'...\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 49.7M/49.7M [00:01<00:00, 37.1MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 463/463 [02:37<00:00,  2.94it/s]\n",
      "[codecarbon INFO @ 11:37:14] offline tracker init\n",
      "Estimated emissions:  1.1935840868738376e-05  CO2 grams\n",
      "The computing time of SRS with a reduction of 0.5 has been of: 0.012971162796020508 seconds\n",
      "The time to calculate epsilon-representativity (1.760362684726715) has been of 0.01908731460571289 seconds\n",
      "Process completed.\n",
      "Number of original files: 463\n",
      "Files after using SRS  reduction method and a percentage of reduction of  0.5 :  232\n"
     ]
    }
   ],
   "source": [
    "os.chdir(pathInicial)\n",
    "method = \"SRS\"\n",
    "perc=0.5\n",
    "!python ReductionDatasetRoboflow_yolov8.py --name {method} --perc {perc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc882af6-e5a0-40d2-afec-d2f6b5b51c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.model.0.conv.weight False\n",
      "model.model.0.bn.weight False\n",
      "model.model.0.bn.bias False\n",
      "model.model.1.conv.weight False\n",
      "model.model.1.bn.weight False\n",
      "model.model.1.bn.bias False\n",
      "model.model.2.cv1.conv.weight False\n",
      "model.model.2.cv1.bn.weight False\n",
      "model.model.2.cv1.bn.bias False\n",
      "model.model.2.cv2.conv.weight False\n",
      "model.model.2.cv2.bn.weight False\n",
      "model.model.2.cv2.bn.bias False\n",
      "model.model.2.m.0.cv1.conv.weight False\n",
      "model.model.2.m.0.cv1.bn.weight False\n",
      "model.model.2.m.0.cv1.bn.bias False\n",
      "model.model.2.m.0.cv2.conv.weight False\n",
      "model.model.2.m.0.cv2.bn.weight False\n",
      "model.model.2.m.0.cv2.bn.bias False\n",
      "model.model.2.m.1.cv1.conv.weight False\n",
      "model.model.2.m.1.cv1.bn.weight False\n",
      "model.model.2.m.1.cv1.bn.bias False\n",
      "model.model.2.m.1.cv2.conv.weight False\n",
      "model.model.2.m.1.cv2.bn.weight False\n",
      "model.model.2.m.1.cv2.bn.bias False\n",
      "model.model.3.conv.weight False\n",
      "model.model.3.bn.weight False\n",
      "model.model.3.bn.bias False\n",
      "model.model.4.cv1.conv.weight False\n",
      "model.model.4.cv1.bn.weight False\n",
      "model.model.4.cv1.bn.bias False\n",
      "model.model.4.cv2.conv.weight False\n",
      "model.model.4.cv2.bn.weight False\n",
      "model.model.4.cv2.bn.bias False\n",
      "model.model.4.m.0.cv1.conv.weight False\n",
      "model.model.4.m.0.cv1.bn.weight False\n",
      "model.model.4.m.0.cv1.bn.bias False\n",
      "model.model.4.m.0.cv2.conv.weight False\n",
      "model.model.4.m.0.cv2.bn.weight False\n",
      "model.model.4.m.0.cv2.bn.bias False\n",
      "model.model.4.m.1.cv1.conv.weight False\n",
      "model.model.4.m.1.cv1.bn.weight False\n",
      "model.model.4.m.1.cv1.bn.bias False\n",
      "model.model.4.m.1.cv2.conv.weight False\n",
      "model.model.4.m.1.cv2.bn.weight False\n",
      "model.model.4.m.1.cv2.bn.bias False\n",
      "model.model.4.m.2.cv1.conv.weight False\n",
      "model.model.4.m.2.cv1.bn.weight False\n",
      "model.model.4.m.2.cv1.bn.bias False\n",
      "model.model.4.m.2.cv2.conv.weight False\n",
      "model.model.4.m.2.cv2.bn.weight False\n",
      "model.model.4.m.2.cv2.bn.bias False\n",
      "model.model.4.m.3.cv1.conv.weight False\n",
      "model.model.4.m.3.cv1.bn.weight False\n",
      "model.model.4.m.3.cv1.bn.bias False\n",
      "model.model.4.m.3.cv2.conv.weight False\n",
      "model.model.4.m.3.cv2.bn.weight False\n",
      "model.model.4.m.3.cv2.bn.bias False\n",
      "model.model.5.conv.weight False\n",
      "model.model.5.bn.weight False\n",
      "model.model.5.bn.bias False\n",
      "model.model.6.cv1.conv.weight False\n",
      "model.model.6.cv1.bn.weight False\n",
      "model.model.6.cv1.bn.bias False\n",
      "model.model.6.cv2.conv.weight False\n",
      "model.model.6.cv2.bn.weight False\n",
      "model.model.6.cv2.bn.bias False\n",
      "model.model.6.m.0.cv1.conv.weight False\n",
      "model.model.6.m.0.cv1.bn.weight False\n",
      "model.model.6.m.0.cv1.bn.bias False\n",
      "model.model.6.m.0.cv2.conv.weight False\n",
      "model.model.6.m.0.cv2.bn.weight False\n",
      "model.model.6.m.0.cv2.bn.bias False\n",
      "model.model.6.m.1.cv1.conv.weight False\n",
      "model.model.6.m.1.cv1.bn.weight False\n",
      "model.model.6.m.1.cv1.bn.bias False\n",
      "model.model.6.m.1.cv2.conv.weight False\n",
      "model.model.6.m.1.cv2.bn.weight False\n",
      "model.model.6.m.1.cv2.bn.bias False\n",
      "model.model.6.m.2.cv1.conv.weight False\n",
      "model.model.6.m.2.cv1.bn.weight False\n",
      "model.model.6.m.2.cv1.bn.bias False\n",
      "model.model.6.m.2.cv2.conv.weight False\n",
      "model.model.6.m.2.cv2.bn.weight False\n",
      "model.model.6.m.2.cv2.bn.bias False\n",
      "model.model.6.m.3.cv1.conv.weight False\n",
      "model.model.6.m.3.cv1.bn.weight False\n",
      "model.model.6.m.3.cv1.bn.bias False\n",
      "model.model.6.m.3.cv2.conv.weight False\n",
      "model.model.6.m.3.cv2.bn.weight False\n",
      "model.model.6.m.3.cv2.bn.bias False\n",
      "model.model.7.conv.weight False\n",
      "model.model.7.bn.weight False\n",
      "model.model.7.bn.bias False\n",
      "model.model.8.cv1.conv.weight False\n",
      "model.model.8.cv1.bn.weight False\n",
      "model.model.8.cv1.bn.bias False\n",
      "model.model.8.cv2.conv.weight False\n",
      "model.model.8.cv2.bn.weight False\n",
      "model.model.8.cv2.bn.bias False\n",
      "model.model.8.m.0.cv1.conv.weight False\n",
      "model.model.8.m.0.cv1.bn.weight False\n",
      "model.model.8.m.0.cv1.bn.bias False\n",
      "model.model.8.m.0.cv2.conv.weight False\n",
      "model.model.8.m.0.cv2.bn.weight False\n",
      "model.model.8.m.0.cv2.bn.bias False\n",
      "model.model.8.m.1.cv1.conv.weight False\n",
      "model.model.8.m.1.cv1.bn.weight False\n",
      "model.model.8.m.1.cv1.bn.bias False\n",
      "model.model.8.m.1.cv2.conv.weight False\n",
      "model.model.8.m.1.cv2.bn.weight False\n",
      "model.model.8.m.1.cv2.bn.bias False\n",
      "model.model.9.cv1.conv.weight False\n",
      "model.model.9.cv1.bn.weight False\n",
      "model.model.9.cv1.bn.bias False\n",
      "model.model.9.cv2.conv.weight False\n",
      "model.model.9.cv2.bn.weight False\n",
      "model.model.9.cv2.bn.bias False\n",
      "model.model.12.cv1.conv.weight True\n",
      "model.model.12.cv1.bn.weight True\n",
      "model.model.12.cv1.bn.bias True\n",
      "model.model.12.cv2.conv.weight True\n",
      "model.model.12.cv2.bn.weight True\n",
      "model.model.12.cv2.bn.bias True\n",
      "model.model.12.m.0.cv1.conv.weight True\n",
      "model.model.12.m.0.cv1.bn.weight True\n",
      "model.model.12.m.0.cv1.bn.bias True\n",
      "model.model.12.m.0.cv2.conv.weight True\n",
      "model.model.12.m.0.cv2.bn.weight True\n",
      "model.model.12.m.0.cv2.bn.bias True\n",
      "model.model.12.m.1.cv1.conv.weight True\n",
      "model.model.12.m.1.cv1.bn.weight True\n",
      "model.model.12.m.1.cv1.bn.bias True\n",
      "model.model.12.m.1.cv2.conv.weight True\n",
      "model.model.12.m.1.cv2.bn.weight True\n",
      "model.model.12.m.1.cv2.bn.bias True\n",
      "model.model.15.cv1.conv.weight True\n",
      "model.model.15.cv1.bn.weight True\n",
      "model.model.15.cv1.bn.bias True\n",
      "model.model.15.cv2.conv.weight True\n",
      "model.model.15.cv2.bn.weight True\n",
      "model.model.15.cv2.bn.bias True\n",
      "model.model.15.m.0.cv1.conv.weight True\n",
      "model.model.15.m.0.cv1.bn.weight True\n",
      "model.model.15.m.0.cv1.bn.bias True\n",
      "model.model.15.m.0.cv2.conv.weight True\n",
      "model.model.15.m.0.cv2.bn.weight True\n",
      "model.model.15.m.0.cv2.bn.bias True\n",
      "model.model.15.m.1.cv1.conv.weight True\n",
      "model.model.15.m.1.cv1.bn.weight True\n",
      "model.model.15.m.1.cv1.bn.bias True\n",
      "model.model.15.m.1.cv2.conv.weight True\n",
      "model.model.15.m.1.cv2.bn.weight True\n",
      "model.model.15.m.1.cv2.bn.bias True\n",
      "model.model.16.conv.weight True\n",
      "model.model.16.bn.weight True\n",
      "model.model.16.bn.bias True\n",
      "model.model.18.cv1.conv.weight True\n",
      "model.model.18.cv1.bn.weight True\n",
      "model.model.18.cv1.bn.bias True\n",
      "model.model.18.cv2.conv.weight True\n",
      "model.model.18.cv2.bn.weight True\n",
      "model.model.18.cv2.bn.bias True\n",
      "model.model.18.m.0.cv1.conv.weight True\n",
      "model.model.18.m.0.cv1.bn.weight True\n",
      "model.model.18.m.0.cv1.bn.bias True\n",
      "model.model.18.m.0.cv2.conv.weight True\n",
      "model.model.18.m.0.cv2.bn.weight True\n",
      "model.model.18.m.0.cv2.bn.bias True\n",
      "model.model.18.m.1.cv1.conv.weight True\n",
      "model.model.18.m.1.cv1.bn.weight True\n",
      "model.model.18.m.1.cv1.bn.bias True\n",
      "model.model.18.m.1.cv2.conv.weight True\n",
      "model.model.18.m.1.cv2.bn.weight True\n",
      "model.model.18.m.1.cv2.bn.bias True\n",
      "model.model.19.conv.weight True\n",
      "model.model.19.bn.weight True\n",
      "model.model.19.bn.bias True\n",
      "model.model.21.cv1.conv.weight True\n",
      "model.model.21.cv1.bn.weight True\n",
      "model.model.21.cv1.bn.bias True\n",
      "model.model.21.cv2.conv.weight True\n",
      "model.model.21.cv2.bn.weight True\n",
      "model.model.21.cv2.bn.bias True\n",
      "model.model.21.m.0.cv1.conv.weight True\n",
      "model.model.21.m.0.cv1.bn.weight True\n",
      "model.model.21.m.0.cv1.bn.bias True\n",
      "model.model.21.m.0.cv2.conv.weight True\n",
      "model.model.21.m.0.cv2.bn.weight True\n",
      "model.model.21.m.0.cv2.bn.bias True\n",
      "model.model.21.m.1.cv1.conv.weight True\n",
      "model.model.21.m.1.cv1.bn.weight True\n",
      "model.model.21.m.1.cv1.bn.bias True\n",
      "model.model.21.m.1.cv2.conv.weight True\n",
      "model.model.21.m.1.cv2.bn.weight True\n",
      "model.model.21.m.1.cv2.bn.bias True\n",
      "model.model.22.cv2.0.0.conv.weight True\n",
      "model.model.22.cv2.0.0.bn.weight True\n",
      "model.model.22.cv2.0.0.bn.bias True\n",
      "model.model.22.cv2.0.1.conv.weight True\n",
      "model.model.22.cv2.0.1.bn.weight True\n",
      "model.model.22.cv2.0.1.bn.bias True\n",
      "model.model.22.cv2.0.2.weight True\n",
      "model.model.22.cv2.0.2.bias True\n",
      "model.model.22.cv2.1.0.conv.weight True\n",
      "model.model.22.cv2.1.0.bn.weight True\n",
      "model.model.22.cv2.1.0.bn.bias True\n",
      "model.model.22.cv2.1.1.conv.weight True\n",
      "model.model.22.cv2.1.1.bn.weight True\n",
      "model.model.22.cv2.1.1.bn.bias True\n",
      "model.model.22.cv2.1.2.weight True\n",
      "model.model.22.cv2.1.2.bias True\n",
      "model.model.22.cv2.2.0.conv.weight True\n",
      "model.model.22.cv2.2.0.bn.weight True\n",
      "model.model.22.cv2.2.0.bn.bias True\n",
      "model.model.22.cv2.2.1.conv.weight True\n",
      "model.model.22.cv2.2.1.bn.weight True\n",
      "model.model.22.cv2.2.1.bn.bias True\n",
      "model.model.22.cv2.2.2.weight True\n",
      "model.model.22.cv2.2.2.bias True\n",
      "model.model.22.cv3.0.0.conv.weight True\n",
      "model.model.22.cv3.0.0.bn.weight True\n",
      "model.model.22.cv3.0.0.bn.bias True\n",
      "model.model.22.cv3.0.1.conv.weight True\n",
      "model.model.22.cv3.0.1.bn.weight True\n",
      "model.model.22.cv3.0.1.bn.bias True\n",
      "model.model.22.cv3.0.2.weight True\n",
      "model.model.22.cv3.0.2.bias True\n",
      "model.model.22.cv3.1.0.conv.weight True\n",
      "model.model.22.cv3.1.0.bn.weight True\n",
      "model.model.22.cv3.1.0.bn.bias True\n",
      "model.model.22.cv3.1.1.conv.weight True\n",
      "model.model.22.cv3.1.1.bn.weight True\n",
      "model.model.22.cv3.1.1.bn.bias True\n",
      "model.model.22.cv3.1.2.weight True\n",
      "model.model.22.cv3.1.2.bias True\n",
      "model.model.22.cv3.2.0.conv.weight True\n",
      "model.model.22.cv3.2.0.bn.weight True\n",
      "model.model.22.cv3.2.0.bn.bias True\n",
      "model.model.22.cv3.2.1.conv.weight True\n",
      "model.model.22.cv3.2.1.bn.weight True\n",
      "model.model.22.cv3.2.1.bn.bias True\n",
      "model.model.22.cv3.2.2.weight True\n",
      "model.model.22.cv3.2.2.bias True\n",
      "model.model.22.dfl.conv.weight True\n",
      "Ultralytics YOLOv8.2.91 ðŸš€ Python-3.9.19 torch-1.12.1+cu113 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "WARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8m.pt, data=wheelchair-detection-1/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train_yolov8_roboflow_GAM24_subset, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train_yolov8_roboflow_GAM24_subset\n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3776854  ultralytics.nn.modules.head.Detect           [2, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25,857,478 parameters, 25,857,462 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train_yolov8_roboflow_GAM24_subset', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/vtoscano/VToscano/GA_M24/yolov8/wheelchair-detection-1/train/labels... 232 images, 0 backgrounds, \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/vtoscano/VToscano/GA_M24/yolov8/wheelchair-detection-1/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/vtoscano/VToscano/GA_M24/yolov8/wheelchair-detection-1/test/labels.cache... 51 images, 0 backgrounds\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train_yolov8_roboflow_GAM24_subset/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train_yolov8_roboflow_GAM24_subset\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      7.09G      1.408      2.672      1.661         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.429       0.65      0.557      0.285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      7.11G      1.281      1.587       1.56         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.439      0.477      0.438      0.209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      7.06G      1.435       1.73      1.668         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.327      0.571       0.41      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      7.07G      1.464      1.666      1.665         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.271      0.401      0.247     0.0922\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100      7.05G      1.519      1.676      1.724         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120     0.0644      0.327     0.0349     0.0101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      7.05G      1.541      1.707      1.722         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120     0.0875      0.285     0.0587     0.0173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      7.03G      1.553      1.653      1.694         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.101      0.163     0.0694     0.0261\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100      6.93G      1.534      1.712      1.724         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.155      0.364      0.118     0.0332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      7.05G       1.47      1.639      1.682         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.225      0.242      0.101     0.0254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      7.05G      1.504      1.605        1.7         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.373       0.34      0.298     0.0977\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      7.06G       1.55      1.623       1.71         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.346      0.462      0.388      0.166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      6.93G      1.481      1.548      1.659         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.311      0.386      0.245     0.0999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      7.06G      1.517       1.61      1.707         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.368      0.279      0.213      0.076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      7.06G      1.478      1.563      1.672         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.503      0.435       0.44      0.169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      7.08G      1.429      1.546      1.653         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.527      0.425      0.464      0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      6.93G      1.451      1.498      1.659         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.561      0.545      0.579      0.287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      7.05G       1.39      1.488      1.618         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120       0.28      0.627      0.418      0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      7.03G      1.364      1.454      1.569         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.497      0.632      0.544      0.284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      7.03G      1.352       1.36      1.555         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.709      0.659      0.677      0.345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      7.07G      1.397       1.38      1.616         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.558      0.577      0.556      0.243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      7.08G      1.288      1.359      1.566         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.611      0.539      0.617      0.296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      7.08G      1.349      1.367      1.565         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.469      0.554      0.463      0.225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      7.03G      1.327      1.349      1.559         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.598      0.541      0.583      0.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      7.05G      1.296      1.299      1.564         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.601      0.562      0.591      0.323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100      7.06G      1.327      1.329       1.57         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.523      0.507      0.519      0.244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      7.08G      1.253      1.264      1.498         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120       0.66      0.688      0.705       0.38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      7.03G       1.21      1.235      1.484         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.808      0.592      0.709      0.412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      7.05G       1.21      1.168      1.456         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.755      0.691      0.759      0.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      6.93G      1.188      1.214      1.453         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.832      0.653      0.724      0.423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      7.05G      1.191      1.158      1.454         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.791      0.722      0.789      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      7.08G      1.175      1.134      1.443         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.874      0.692      0.823      0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      7.05G      1.197      1.126      1.412         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.707      0.758      0.755      0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100      7.05G      1.188      1.119      1.442         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.743      0.792      0.807      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      7.05G      1.174      1.123      1.444         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.644      0.653      0.704      0.383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      7.08G      1.172      1.115      1.444         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.713      0.608      0.679      0.386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      7.08G      1.124      1.084      1.401         56        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.679      0.776      0.778      0.448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      7.03G       1.18      1.099      1.437         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.819      0.729      0.793      0.454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      7.08G      1.199      1.091      1.466         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.811      0.683      0.775      0.441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      7.05G      1.161      1.037      1.413         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.832      0.757      0.809      0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      7.05G      1.134      1.059      1.414         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.759      0.664      0.778      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      7.05G      1.082     0.9802      1.375         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.778      0.762      0.833      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      7.04G      1.091     0.9626      1.363         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.846      0.735       0.86      0.519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      7.05G      1.109     0.9733      1.372         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.753      0.727      0.794      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      6.92G      1.094     0.9962      1.392         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.736      0.762      0.784      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100      7.05G      1.051     0.9642      1.359         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.742      0.792      0.801      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100      7.05G      1.063     0.9894      1.369         58        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.718      0.811      0.839      0.526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      7.05G      1.035     0.9326      1.329         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.757      0.855      0.859      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      7.03G      1.059     0.9649      1.365         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.821      0.817      0.861      0.525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      7.05G      1.021     0.9057      1.329         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.853      0.804      0.879       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100      7.03G      1.033     0.9193      1.351         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.839      0.756       0.85       0.52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      7.05G      1.044     0.9819       1.33         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.826      0.747       0.85      0.514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      7.08G      1.007     0.9136      1.317         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.899      0.874      0.909      0.581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      7.05G      1.015     0.9071      1.307         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.851      0.806      0.868      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100      7.03G     0.9286     0.8631      1.278         60        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.861      0.763      0.833      0.543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      7.05G     0.9724     0.8894      1.308         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.852      0.795       0.84      0.539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      7.05G     0.9724     0.8632      1.304         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.919      0.787      0.858      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      7.08G     0.9676     0.8475      1.303         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.869      0.817      0.865      0.565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      7.05G     0.9609     0.8531      1.287         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.926      0.748      0.865      0.564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      7.09G     0.9379      0.834      1.271         54        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.892      0.806      0.871      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      7.03G     0.9676     0.8652      1.297         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.889        0.8      0.877      0.591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      7.04G     0.9428     0.8662      1.269         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.866      0.813       0.87      0.559\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      7.06G     0.9593     0.8487      1.302         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120       0.92      0.759      0.878      0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      7.06G     0.9378     0.8561      1.282         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.868      0.827      0.886      0.561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      7.05G      0.914     0.8083      1.266         44        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.876      0.843      0.901      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      7.06G     0.9377     0.7943      1.278         55        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.886      0.829      0.882      0.575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      7.05G     0.8801     0.7924       1.24         59        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.903       0.81      0.883      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      7.06G     0.9137     0.8029      1.263         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.794      0.848      0.876      0.588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      7.07G     0.8857     0.7834      1.251         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.774      0.825      0.867      0.567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      7.04G     0.8802     0.7624       1.24         45        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.907      0.822      0.906      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      7.05G     0.8458     0.7505      1.221         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.929      0.842      0.897      0.597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      7.06G     0.8651     0.7577      1.222         53        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.884      0.814      0.865      0.573\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      7.03G     0.8485     0.7288      1.221         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.887      0.777      0.858      0.555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      7.08G     0.8365     0.7232      1.223         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.839       0.83      0.863      0.571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      7.04G     0.8412     0.7117      1.207         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.915      0.841        0.9      0.597\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      7.03G     0.8686     0.7253      1.214         67        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.927      0.856      0.906      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      7.08G     0.8175      0.708      1.214         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.929      0.833      0.916      0.608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      7.03G     0.8217     0.7203      1.212         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.978      0.833       0.92      0.599\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      7.07G     0.8094      0.703      1.195         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.944      0.846      0.908      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      6.93G      0.822     0.6808      1.205         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.926      0.851      0.908      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      7.08G     0.7732     0.6629      1.173         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.927      0.828      0.893      0.613\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      7.08G     0.7638     0.6786      1.172         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.917      0.851       0.91       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      7.07G     0.7576      0.675      1.169         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.842      0.893      0.915       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      7.05G     0.7811     0.6782       1.19         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.896      0.868      0.912      0.614\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      7.03G     0.7954     0.7082      1.199         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.906      0.855      0.914      0.626\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      7.05G     0.7674      0.681      1.152         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.867      0.911      0.921       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      7.08G     0.7592      0.664      1.161         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.912      0.882       0.92       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      7.03G     0.7436     0.6426      1.163         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.902      0.879      0.917      0.621\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      7.06G     0.7365     0.6438      1.144         51        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.932       0.85      0.918      0.628\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      7.07G     0.7421     0.6349      1.164         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.928      0.836      0.915       0.62\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      7.03G     0.7255      0.618      1.152         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.915      0.843      0.913       0.63\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      7.08G     0.6078     0.4912      1.082         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.5\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.915      0.834      0.913      0.628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100      7.06G     0.5958     0.4489      1.059         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.876      0.858      0.895       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100      7.05G     0.5431     0.4237      1.022         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.903       0.83      0.893      0.621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      7.06G     0.5578     0.4202      1.047         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.921      0.845      0.917      0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      7.03G     0.5566     0.4162       1.05         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.913      0.825      0.907      0.624\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      7.06G     0.5428     0.4121      1.026         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.894      0.827      0.899      0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100      7.06G     0.5147     0.3864      1.002         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.931      0.836      0.904      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      7.03G     0.5325     0.4108      1.032         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.923      0.834      0.902      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      7.03G     0.5397     0.4152      1.027         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.9\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.948      0.843      0.911       0.63\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      7.05G     0.5068     0.3937      1.003         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15/15 [00:05<00:00,  2.8\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.947      0.843      0.913      0.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 0.191 hours.\n",
      "Optimizer stripped from runs/detect/train_yolov8_roboflow_GAM24_subset/weights/last.pt, 52.0MB\n",
      "Optimizer stripped from runs/detect/train_yolov8_roboflow_GAM24_subset/weights/best.pt, 52.0MB\n",
      "\n",
      "Validating runs/detect/train_yolov8_roboflow_GAM24_subset/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.91 ðŸš€ Python-3.9.19 torch-1.12.1+cu113 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "Model summary (fused): 218 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.947      0.843      0.913      0.637\n",
      "                people         27         55      0.926      0.764      0.853      0.517\n",
      "  peopleWithWheelchair         51         65      0.968      0.923      0.974      0.757\n",
      "Speed: 1.2ms preprocess, 9.0ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train_yolov8_roboflow_GAM24_subset\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fcb1c05e7c0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.010496,   0.0052481,           0],\n",
       "       [          1,           1,           1, ...,     0.44521,     0.44521,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.31832,     0.31832,     0.38924, ...,           0,           0,           0],\n",
       "       [    0.49242,     0.49242,     0.62646, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.19065,     0.19065,     0.24632, ...,           1,           1,           1],\n",
       "       [    0.32663,     0.32663,     0.45937, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.96364,     0.96364,     0.92727, ...,           0,           0,           0],\n",
       "       [          1,           1,     0.98462, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.6645956534744079\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.51737,     0.75655])\n",
       "names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9470349514439016, 'metrics/recall(B)': 0.8433566433566434, 'metrics/mAP50(B)': 0.9133062302955437, 'metrics/mAP50-95(B)': 0.636961144938726, 'fitness': 0.6645956534744079}\n",
       "save_dir: PosixPath('runs/detect/train_yolov8_roboflow_GAM24_subset')\n",
       "speed: {'preprocess': 1.2012275994992723, 'inference': 9.0485273622999, 'loss': 0.00044411303950291054, 'postprocess': 0.5681514739990234}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(pathInicial + '/yolov8')\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "\n",
    "freeze = 10\n",
    "freeze = [f'model.{x}.' for x in range(freeze)]  \n",
    "for k, v in model.named_parameters(): \n",
    "    v.requires_grad = True # train all layers \n",
    "    if any(x in k for x in freeze): \n",
    "      v.requires_grad = False\n",
    "    print(k, v.requires_grad)\n",
    "\n",
    "model.train(data = \"wheelchair-detection-1/data.yaml\", batch=16, imgsz=640, epochs=100, name =\"train_yolov8_roboflow_GAM24_subset\", seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "048a014c-531f-4257-be8c-e9e14638cbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.91 ðŸš€ Python-3.9.19 torch-1.12.1+cu113 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "Model summary (fused): 218 layers, 25,840,918 parameters, 0 gradients, 78.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/vtoscano/VToscano/GA_M24/yolov8/wheelchair-detection-1/test/labels.cache... 51 images, 0 backgrounds\u001b[0m\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:02<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         51        120      0.946      0.843      0.913      0.639\n",
      "                people         27         55      0.926      0.764      0.852      0.519\n",
      "  peopleWithWheelchair         51         65      0.966      0.923      0.974      0.759\n",
      "Speed: 3.2ms preprocess, 15.2ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7fcb4814c2b0>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,    0.010496,   0.0052481,           0],\n",
       "       [          1,           1,           1, ...,     0.45775,     0.45775,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.31832,     0.31832,     0.38901, ...,           0,           0,           0],\n",
       "       [    0.49242,     0.49242,      0.6302, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.19065,     0.19065,     0.24613, ...,           1,           1,           1],\n",
       "       [    0.32663,     0.32663,      0.4634, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.96364,     0.96364,     0.92727, ...,           0,           0,           0],\n",
       "       [          1,           1,     0.98462, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.6661982769482756\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.51851,     0.75898])\n",
       "names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.9461855094172646, 'metrics/recall(B)': 0.8433566433566434, 'metrics/mAP50(B)': 0.9132818121995666, 'metrics/mAP50-95(B)': 0.6387445508092432, 'fitness': 0.6661982769482756}\n",
       "save_dir: PosixPath('runs/detect/val2')\n",
       "speed: {'preprocess': 3.2327782874013864, 'inference': 15.211390513999788, 'loss': 0.0008274527157054228, 'postprocess': 1.98057586071538}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel = YOLO(\"runs/detect/train_yolov8_roboflow_GAM24_subset/weights/best.pt\")\n",
    "\n",
    "bestmodel.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac4e36e3-c640-41cc-88a2-1e0b7cabb7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING âš ï¸ inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.9ms\n",
      "video 1/1 (frame 2/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 3/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.4ms\n",
      "video 1/1 (frame 4/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 5/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 6/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 7/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 8/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 9/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 10/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 11/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 12/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 13/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 14/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 15/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 16/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 17/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 18/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 19/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 20/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 21/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 22/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 23/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 24/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 25/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 26/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 27/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 28/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 29/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 30/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 31/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 32/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 33/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 34/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 35/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 36/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 7 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 37/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 8 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 38/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 39/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 40/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 41/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 42/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 43/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 44/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 45/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 46/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 47/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 48/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 49/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 50/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 51/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 52/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 53/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 54/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 55/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 56/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 57/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 58/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 59/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 60/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 61/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 62/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 63/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 64/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 65/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 66/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 67/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 68/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 69/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 70/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 71/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 72/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 73/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 74/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 75/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 76/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 77/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 78/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 79/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 80/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 81/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 82/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 83/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 84/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 85/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 86/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 87/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 88/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 89/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 90/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 91/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 92/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 93/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 94/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 95/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 96/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 97/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 98/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 99/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 100/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 101/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 102/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 103/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 104/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 105/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 106/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 107/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 108/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 109/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 110/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 111/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 112/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 113/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 114/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 115/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 116/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 117/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 118/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 119/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 120/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 121/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 122/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 123/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 124/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 125/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 126/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 127/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 128/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 129/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 130/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 131/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 132/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 133/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 134/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 135/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 136/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 137/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 138/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 139/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 140/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 3 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 141/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 142/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 143/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 144/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 145/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 146/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 147/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 148/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 149/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 150/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 151/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 152/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 153/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 154/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 155/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 156/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 157/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 158/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 159/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 160/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 161/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 162/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 163/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 164/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 3 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 165/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 166/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 167/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 168/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 169/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 170/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 171/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 172/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 173/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 174/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 175/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 176/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 177/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 178/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 179/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 180/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 181/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 182/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 183/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 184/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 185/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 186/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 187/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 188/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 189/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 190/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 191/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 192/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 193/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 194/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 195/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 196/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 197/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 198/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 199/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 200/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 201/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 202/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 203/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 204/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 205/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 206/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 207/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 208/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 209/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.7ms\n",
      "video 1/1 (frame 210/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 211/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 212/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 213/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 214/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 215/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 216/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 217/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 218/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 219/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 220/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 221/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 222/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 223/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 224/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 225/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 226/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 227/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 228/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 229/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 230/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 231/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 232/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 233/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 234/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 235/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 236/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 237/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 238/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 239/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 240/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 241/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 242/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 243/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 244/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 245/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 246/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 247/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 248/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 249/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 250/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 251/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 252/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 253/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 254/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 255/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 256/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 257/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 258/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 259/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 260/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 261/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 262/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 263/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 264/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 265/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 266/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 267/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 268/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 269/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 270/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 271/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 272/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 273/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 274/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 275/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 276/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 277/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 278/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 279/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 280/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 281/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 282/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 283/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 284/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 285/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 286/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 287/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 288/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 289/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 290/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 291/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 292/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 293/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 294/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 295/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 296/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 297/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 298/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 299/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 16.3ms\n",
      "video 1/1 (frame 300/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 301/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 302/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 303/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 304/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 305/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 306/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 307/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 308/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 309/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 310/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 311/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 312/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 313/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 314/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 315/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 316/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 317/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 318/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 319/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 320/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 321/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 322/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 323/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 324/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 325/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 326/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 327/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 328/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 329/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 330/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 331/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 332/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 333/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 334/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 335/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 7 peoples, 16.3ms\n",
      "video 1/1 (frame 336/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 337/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 338/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 339/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 340/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 7 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 341/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 342/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 343/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 344/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 345/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 346/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 347/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 348/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 349/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 350/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 351/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 352/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 353/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 354/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 355/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 356/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 357/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 358/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 359/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 360/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 361/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 362/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 363/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.4ms\n",
      "video 1/1 (frame 364/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 365/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 366/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 367/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 368/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 369/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 370/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 371/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 372/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 373/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 374/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 375/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 376/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 377/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 378/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 379/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 380/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 381/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 382/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 383/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 384/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 385/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 386/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 387/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 388/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 389/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 390/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 391/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 392/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 7 peoples, 16.3ms\n",
      "video 1/1 (frame 393/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 394/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 395/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 396/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 397/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 398/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 399/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 400/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 401/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 402/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 403/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 404/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 405/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 406/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 407/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 408/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 409/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 410/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 411/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 412/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 413/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 414/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 415/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 416/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 417/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 418/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 16.3ms\n",
      "video 1/1 (frame 419/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 16.3ms\n",
      "video 1/1 (frame 420/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 421/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 422/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 423/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 424/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 425/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 426/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 427/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 428/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 429/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 430/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 431/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 16.3ms\n",
      "video 1/1 (frame 432/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 433/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 434/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 435/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 436/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 437/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 438/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 439/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 440/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 441/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 442/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 443/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 444/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 445/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 446/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 447/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 448/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 449/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 450/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 451/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 452/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 453/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 454/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 455/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 456/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 457/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 458/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 459/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 460/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 461/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 462/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 463/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 464/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 465/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 466/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 467/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 468/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 469/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 470/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 471/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 472/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 473/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 474/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 475/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 476/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 477/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 478/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 479/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 480/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 481/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 482/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 483/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 484/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 485/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 486/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 487/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 488/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 489/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 490/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 491/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 492/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 493/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 494/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 495/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 496/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 497/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 498/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 499/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 500/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 501/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 502/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 503/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 504/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 505/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 506/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 507/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 508/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 509/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 510/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 511/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 512/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 513/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 514/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 515/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 516/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 517/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 518/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 519/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 520/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 521/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 522/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 523/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 524/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 525/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 526/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 527/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 16.3ms\n",
      "video 1/1 (frame 528/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 529/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 530/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 531/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 532/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 533/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 534/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 535/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 536/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 537/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 538/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 539/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 540/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 541/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 542/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 543/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 544/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 545/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 546/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 547/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 548/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 549/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 550/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 551/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 552/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 553/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 554/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 555/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 556/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 557/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 558/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 559/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 560/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 561/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 562/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 563/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 564/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 565/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 566/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 567/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 568/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 569/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 570/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 571/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 572/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 573/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 574/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 575/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 576/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 577/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 578/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 579/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 580/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 581/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 582/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 583/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 584/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 585/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 586/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.5ms\n",
      "video 1/1 (frame 587/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 588/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 589/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 590/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 591/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 592/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 2 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 593/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 594/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 1 people, 2 peopleWithWheelchairs, 16.4ms\n",
      "video 1/1 (frame 595/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 596/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 597/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 598/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 1 peopleWithWheelchair, 16.3ms\n",
      "video 1/1 (frame 599/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 600/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 601/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 602/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 603/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 604/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 605/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 606/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 607/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 608/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 609/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 610/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 3 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 611/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 612/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 613/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 614/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 615/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 616/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 617/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 618/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 619/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 620/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 621/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 622/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 623/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 624/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 625/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 626/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 627/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 628/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 629/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 630/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 631/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 632/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 633/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 634/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 635/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 636/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 637/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 638/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 639/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 640/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 641/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 642/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 643/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 644/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 645/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 646/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 6 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 647/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 648/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 649/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 4 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 650/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 5 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 651/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 652/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 653/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 654/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 655/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 656/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 657/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 658/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 659/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 660/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 661/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 662/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 663/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "video 1/1 (frame 664/664) /home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4: 384x640 3 peoples, 2 peopleWithWheelchairs, 16.3ms\n",
      "Speed: 1.9ms preprocess, 16.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14,  4,  0],\n",
       "         [14,  4,  0],\n",
       "         [14,  4,  0],\n",
       "         ...,\n",
       "         [39, 21, 26],\n",
       "         [37, 19, 24],\n",
       "         [37, 19, 24]],\n",
       " \n",
       "        [[19,  9,  4],\n",
       "         [19,  9,  4],\n",
       "         [19,  9,  4],\n",
       "         ...,\n",
       "         [38, 20, 25],\n",
       "         [36, 18, 23],\n",
       "         [36, 18, 23]],\n",
       " \n",
       "        [[22, 12,  7],\n",
       "         [22, 12,  7],\n",
       "         [22, 12,  7],\n",
       "         ...,\n",
       "         [37, 19, 24],\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 2.769947052001953, 'inference': 16.882896423339844, 'postprocess': 0.9882450103759766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [21,  9,  9],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9731521606445312, 'inference': 16.379356384277344, 'postprocess': 0.9553432464599609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [21,  9,  9],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.996755599975586, 'inference': 16.370296478271484, 'postprocess': 0.9438991546630859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [20,  8,  8],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [21,  9,  9],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9326210021972656, 'inference': 16.287565231323242, 'postprocess': 0.9429454803466797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8641948699951172, 'inference': 16.29781723022461, 'postprocess': 0.9589195251464844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9183158874511719, 'inference': 16.312599182128906, 'postprocess': 0.9353160858154297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9385814666748047, 'inference': 16.31903648376465, 'postprocess': 0.9438991546630859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8739700317382812, 'inference': 16.277790069580078, 'postprocess': 0.9505748748779297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8634796142578125, 'inference': 16.33429527282715, 'postprocess': 0.946044921875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [18,  6,  6],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [28, 16, 16],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9290447235107422, 'inference': 16.302824020385742, 'postprocess': 0.9372234344482422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [18,  6,  6],\n",
       "         [14,  2,  2],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [19,  7,  7],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9969940185546875, 'inference': 16.286134719848633, 'postprocess': 0.9381771087646484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [18,  6,  6],\n",
       "         [14,  2,  2],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [19,  7,  7],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9009113311767578, 'inference': 16.28899574279785, 'postprocess': 0.9520053863525391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [18,  6,  6],\n",
       "         [14,  2,  2],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [19,  7,  7],\n",
       "         [19,  7,  7]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [23, 11, 11],\n",
       "         [23, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9485950469970703, 'inference': 16.30401611328125, 'postprocess': 0.9467601776123047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8584728240966797, 'inference': 16.302108764648438, 'postprocess': 0.9372234344482422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8339157104492188, 'inference': 16.332387924194336, 'postprocess': 0.9319782257080078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.829385757446289, 'inference': 16.340255737304688, 'postprocess': 0.9870529174804688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9168853759765625, 'inference': 16.297101974487305, 'postprocess': 0.9491443634033203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8548965454101562, 'inference': 16.274690628051758, 'postprocess': 0.9214878082275391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.852273941040039, 'inference': 16.284704208374023, 'postprocess': 0.9164810180664062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [15,  2,  6],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9161701202392578, 'inference': 16.297101974487305, 'postprocess': 0.9663105010986328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [20,  7, 11],\n",
       "         [18,  5,  9]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9385814666748047, 'inference': 16.28899574279785, 'postprocess': 0.9791851043701172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [20,  7, 11],\n",
       "         [18,  5,  9]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8885135650634766, 'inference': 16.30997657775879, 'postprocess': 0.9341239929199219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8358230590820312, 'inference': 16.289472579956055, 'postprocess': 0.9379386901855469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9638538360595703, 'inference': 16.282320022583008, 'postprocess': 1.0173320770263672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8088817596435547, 'inference': 16.298770904541016, 'postprocess': 0.9479522705078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8701553344726562, 'inference': 16.29185676574707, 'postprocess': 0.9377002716064453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9197463989257812, 'inference': 16.30568504333496, 'postprocess': 0.9381771087646484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8711090087890625, 'inference': 16.27659797668457, 'postprocess': 0.9274482727050781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.874685287475586, 'inference': 16.298294067382812, 'postprocess': 0.9281635284423828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 6,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         [24, 16, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.861572265625, 'inference': 16.330480575561523, 'postprocess': 0.9303092956542969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9350051879882812, 'inference': 16.30854606628418, 'postprocess': 0.9248256683349609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8954277038574219, 'inference': 16.286373138427734, 'postprocess': 0.9207725524902344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8870830535888672, 'inference': 16.303539276123047, 'postprocess': 0.9307861328125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8887519836425781, 'inference': 16.294240951538086, 'postprocess': 0.9341239929199219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8515586853027344, 'inference': 16.294002532958984, 'postprocess': 0.9584426879882812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.852273941040039, 'inference': 16.30377769470215, 'postprocess': 0.9291172027587891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.943349838256836, 'inference': 16.314983367919922, 'postprocess': 0.9412765502929688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.956939697265625, 'inference': 16.313791275024414, 'postprocess': 0.9608268737792969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8711090087890625, 'inference': 16.29042625427246, 'postprocess': 0.9355545043945312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8646717071533203, 'inference': 16.310691833496094, 'postprocess': 0.988006591796875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8537044525146484, 'inference': 16.324281692504883, 'postprocess': 0.9307861328125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9161701202392578, 'inference': 16.318798065185547, 'postprocess': 0.9336471557617188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.857757568359375, 'inference': 16.29185676574707, 'postprocess': 0.9443759918212891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8992424011230469, 'inference': 16.296863555908203, 'postprocess': 0.9398460388183594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.91497802734375, 'inference': 16.29471778869629, 'postprocess': 0.9403228759765625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.842498779296875, 'inference': 16.30234718322754, 'postprocess': 0.9860992431640625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.7933845520019531, 'inference': 16.309261322021484, 'postprocess': 0.9386539459228516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8870830535888672, 'inference': 16.301870346069336, 'postprocess': 0.9336471557617188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9741058349609375, 'inference': 16.306638717651367, 'postprocess': 0.9298324584960938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.863241195678711, 'inference': 16.33739471435547, 'postprocess': 0.9360313415527344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8510818481445312, 'inference': 16.27969741821289, 'postprocess': 0.9329319000244141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8765926361083984, 'inference': 16.293048858642578, 'postprocess': 0.9377002716064453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8382072448730469, 'inference': 16.288280487060547, 'postprocess': 0.9288787841796875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.926422119140625, 'inference': 16.286849975585938, 'postprocess': 0.9281635284423828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8339157104492188, 'inference': 16.299724578857422, 'postprocess': 0.9913444519042969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8472671508789062, 'inference': 16.288280487060547, 'postprocess': 0.9605884552001953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9252300262451172, 'inference': 16.2813663482666, 'postprocess': 0.9312629699707031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8723011016845703, 'inference': 16.313791275024414, 'postprocess': 0.9386539459228516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8372535705566406, 'inference': 16.268253326416016, 'postprocess': 0.9565353393554688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [34, 31, 32],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  7,  9],\n",
       "         [16,  4,  6],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]],\n",
       " \n",
       "        [[20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [20,  8, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.91497802734375, 'inference': 16.28589630126953, 'postprocess': 0.9429454803466797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [18,  3,  4],\n",
       "         [18,  3,  4],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9338130950927734, 'inference': 16.300439834594727, 'postprocess': 0.9334087371826172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9102096557617188, 'inference': 16.292572021484375, 'postprocess': 0.9570121765136719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.857757568359375, 'inference': 16.27635955810547, 'postprocess': 0.9434223175048828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8804073333740234, 'inference': 16.308069229125977, 'postprocess': 0.9319782257080078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.924753189086914, 'inference': 16.302824020385742, 'postprocess': 0.9360313415527344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.912832260131836, 'inference': 16.307592391967773, 'postprocess': 0.9462833404541016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9736289978027344, 'inference': 16.295909881591797, 'postprocess': 0.9276866912841797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9097328186035156, 'inference': 16.280651092529297, 'postprocess': 0.9307861328125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8467903137207031, 'inference': 16.289472579956055, 'postprocess': 0.9784698486328125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9006729125976562, 'inference': 16.304731369018555, 'postprocess': 0.9381771087646484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8436908721923828, 'inference': 16.283035278320312, 'postprocess': 0.9629726409912109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [22, 19, 18],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9152164459228516, 'inference': 16.292333602905273, 'postprocess': 0.9407997131347656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [16,  1,  2],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [21,  6,  7],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.851797103881836, 'inference': 16.266345977783203, 'postprocess': 0.9248256683349609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [15,  0,  1],\n",
       "         [13,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [22,  7,  8],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [27, 12, 13],\n",
       "         [29, 14, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.85394287109375, 'inference': 16.324996948242188, 'postprocess': 0.9288787841796875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [27, 11, 16],\n",
       "         [29, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8374919891357422, 'inference': 16.276121139526367, 'postprocess': 0.9300708770751953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8885135650634766, 'inference': 16.311168670654297, 'postprocess': 0.9524822235107422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8014907836914062, 'inference': 16.323566436767578, 'postprocess': 0.9653568267822266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8355846405029297, 'inference': 16.307592391967773, 'postprocess': 0.9350776672363281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8305778503417969, 'inference': 16.290664672851562, 'postprocess': 0.9338855743408203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [15,  0,  1],\n",
       "         [13,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [22,  7,  8],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8820762634277344, 'inference': 16.30711555480957, 'postprocess': 0.9317398071289062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9011497497558594, 'inference': 16.303300857543945, 'postprocess': 0.9438991546630859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31],\n",
       "         [35, 32, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8494129180908203, 'inference': 16.29495620727539, 'postprocess': 0.9257793426513672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [24, 19, 18],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9063949584960938, 'inference': 16.305208206176758, 'postprocess': 0.92315673828125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23,  7, 12],\n",
       "         [15,  0,  4],\n",
       "         [13,  0,  2]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11],\n",
       "         [23,  7, 12]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [24, 19, 18],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.844167709350586, 'inference': 16.28255844116211, 'postprocess': 0.9374618530273438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [15,  0,  1],\n",
       "         [13,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [22,  7,  8],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[23, 18, 17],\n",
       "         [23, 18, 17],\n",
       "         [24, 19, 18],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.909494400024414, 'inference': 16.275405883789062, 'postprocess': 0.926971435546875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31],\n",
       "         [30, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [15,  0,  1],\n",
       "         [13,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [22,  7,  8],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8353462219238281, 'inference': 16.30091667175293, 'postprocess': 0.9496212005615234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4],\n",
       "         [17,  2,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9228458404541016, 'inference': 16.268253326416016, 'postprocess': 0.9331703186035156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4],\n",
       "         [17,  2,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8470287322998047, 'inference': 16.31021499633789, 'postprocess': 0.9391307830810547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4],\n",
       "         [17,  2,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8405914306640625, 'inference': 16.280174255371094, 'postprocess': 0.9510517120361328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31],\n",
       "         [33, 33, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4],\n",
       "         [17,  2,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [21,  6,  7],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.917123794555664, 'inference': 16.275644302368164, 'postprocess': 0.9331703186035156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8503665924072266, 'inference': 16.2813663482666, 'postprocess': 0.9529590606689453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8858909606933594, 'inference': 16.281604766845703, 'postprocess': 0.9300708770751953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8792152404785156, 'inference': 16.27945899963379, 'postprocess': 0.9260177612304688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8527507781982422, 'inference': 16.28398895263672, 'postprocess': 0.9322166442871094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.863718032836914, 'inference': 16.27969741821289, 'postprocess': 0.9775161743164062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8513202667236328, 'inference': 16.272544860839844, 'postprocess': 0.93841552734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9140243530273438, 'inference': 16.277790069580078, 'postprocess': 0.9286403656005859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8916130065917969, 'inference': 16.301631927490234, 'postprocess': 0.9529590606689453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.880645751953125, 'inference': 16.27635955810547, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.85394287109375, 'inference': 16.28422737121582, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8],\n",
       "         [16,  4,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9152164459228516, 'inference': 16.274213790893555, 'postprocess': 0.9398460388183594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9164085388183594, 'inference': 16.300678253173828, 'postprocess': 0.9756088256835938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10],\n",
       "         [18,  6,  8]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8711090087890625, 'inference': 16.27635955810547, 'postprocess': 0.9365081787109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [16,  1,  4],\n",
       "         [ 9,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 15],\n",
       "         [16,  1,  4],\n",
       "         [ 9,  0,  0]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [15,  0,  3],\n",
       "         [10,  0,  0]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8515586853027344, 'inference': 16.29042625427246, 'postprocess': 0.9500980377197266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8618106842041016, 'inference': 16.287565231323242, 'postprocess': 0.9286403656005859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8639564514160156, 'inference': 16.298294067382812, 'postprocess': 0.9770393371582031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.867055892944336, 'inference': 16.297578811645508, 'postprocess': 0.9500980377197266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [18,  3,  6],\n",
       "         [15,  0,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8911361694335938, 'inference': 16.293048858642578, 'postprocess': 0.9357929229736328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  9],\n",
       "         [18,  3,  6],\n",
       "         [13,  0,  1]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [27, 12, 15],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8544197082519531, 'inference': 16.288042068481445, 'postprocess': 0.9286403656005859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [21,  6,  9],\n",
       "         [18,  3,  6],\n",
       "         [13,  0,  1]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [27, 12, 15],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9006729125976562, 'inference': 16.284704208374023, 'postprocess': 0.934600830078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [23,  8, 11],\n",
       "         [18,  3,  6]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [31, 16, 19],\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [35, 20, 23],\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8503665924072266, 'inference': 16.273021697998047, 'postprocess': 0.9508132934570312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [23,  8, 11],\n",
       "         [18,  3,  6]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [31, 16, 19],\n",
       "         [24,  9, 12],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [34, 19, 22],\n",
       "         [27, 12, 15],\n",
       "         [23,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9233226776123047, 'inference': 16.27969741821289, 'postprocess': 0.9369850158691406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [23,  8, 11],\n",
       "         [18,  3,  6]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [31, 16, 19],\n",
       "         [24,  9, 12],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [34, 19, 22],\n",
       "         [27, 12, 15],\n",
       "         [23,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.918792724609375, 'inference': 16.285419464111328, 'postprocess': 0.9436607360839844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8925666809082031, 'inference': 16.281604766845703, 'postprocess': 0.9417533874511719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9025802612304688, 'inference': 16.27659797668457, 'postprocess': 0.9319782257080078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.972198486328125, 'inference': 16.271352767944336, 'postprocess': 1.0676383972167969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9388198852539062, 'inference': 16.288280487060547, 'postprocess': 0.946044921875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8384456634521484, 'inference': 16.29495620727539, 'postprocess': 0.9529590606689453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8],\n",
       "         [15,  0,  3]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [21,  6,  9],\n",
       "         [17,  2,  5]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [22,  7, 10],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8360614776611328, 'inference': 16.277313232421875, 'postprocess': 0.9458065032958984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12],\n",
       "         [18,  3,  6]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [32, 17, 20],\n",
       "         [25, 10, 13],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         [22, 19, 20],\n",
       "         ...,\n",
       "         [35, 20, 23],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9435882568359375, 'inference': 16.27659797668457, 'postprocess': 0.9479522705078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [22,  7,  8],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [27, 12, 13],\n",
       "         [22,  7,  8]],\n",
       " \n",
       "        [[23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9423961639404297, 'inference': 16.29495620727539, 'postprocess': 0.9334087371826172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [22,  7,  8],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [27, 12, 13],\n",
       "         [22,  7,  8]],\n",
       " \n",
       "        [[23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [29, 14, 15],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8532276153564453, 'inference': 16.291141510009766, 'postprocess': 0.942230224609375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [18,  3,  4],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8687248229980469, 'inference': 16.2813663482666, 'postprocess': 0.9388923645019531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [20,  5,  6],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         [ 9,  1,  3],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         [23, 15, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.924276351928711, 'inference': 16.283512115478516, 'postprocess': 0.9660720825195312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [21,  6,  7],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9068717956542969, 'inference': 16.284704208374023, 'postprocess': 0.9367465972900391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [20,  5,  6],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.870870590209961, 'inference': 16.297340393066406, 'postprocess': 0.9386539459228516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9],\n",
       "         [16,  1,  2]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9252300262451172, 'inference': 16.27659797668457, 'postprocess': 0.9374618530273438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9],\n",
       "         [16,  1,  2]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9011497497558594, 'inference': 16.283512115478516, 'postprocess': 0.9415149688720703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9],\n",
       "         [16,  1,  2]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.856088638305664, 'inference': 16.28565788269043, 'postprocess': 0.9453296661376953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23,  8,  9],\n",
       "         [23,  8,  9],\n",
       "         [16,  1,  2]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [24,  9, 10],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.895904541015625, 'inference': 16.287803649902344, 'postprocess': 0.9949207305908203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [22,  7,  8],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [20,  5,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.901388168334961, 'inference': 16.267776489257812, 'postprocess': 0.9303092956542969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [22,  7,  8]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [29, 14, 15],\n",
       "         [23,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.954793930053711, 'inference': 16.303300857543945, 'postprocess': 0.9357929229736328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [15,  0,  1]],\n",
       " \n",
       "        [[ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [22,  7,  8]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [29, 14, 15],\n",
       "         [23,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8665790557861328, 'inference': 16.272544860839844, 'postprocess': 0.9481906890869141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [17,  7,  7],\n",
       "         [11,  1,  1],\n",
       "         [ 9,  0,  0]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [19,  9,  9],\n",
       "         [12,  2,  2],\n",
       "         [10,  0,  0]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [16,  6,  6],\n",
       "         [17,  7,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.898050308227539, 'inference': 16.280651092529297, 'postprocess': 0.9834766387939453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [17,  7,  7],\n",
       "         [11,  1,  1],\n",
       "         [ 9,  0,  0]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [19,  9,  9],\n",
       "         [12,  2,  2],\n",
       "         [10,  0,  0]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [16,  6,  6],\n",
       "         [17,  7,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8265247344970703, 'inference': 16.275882720947266, 'postprocess': 0.9381771087646484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [17,  7,  7],\n",
       "         [11,  1,  1],\n",
       "         [ 9,  0,  0]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [19,  9,  9],\n",
       "         [12,  2,  2],\n",
       "         [10,  0,  0]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [16,  6,  6],\n",
       "         [17,  7,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.901388168334961, 'inference': 16.281604766845703, 'postprocess': 0.9276866912841797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8398761749267578, 'inference': 16.306638717651367, 'postprocess': 0.9267330169677734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.922607421875, 'inference': 16.285419464111328, 'postprocess': 0.9372234344482422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8966197967529297, 'inference': 16.280651092529297, 'postprocess': 0.9303092956542969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8696784973144531, 'inference': 16.280412673950195, 'postprocess': 0.9293556213378906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8923282623291016, 'inference': 16.268491744995117, 'postprocess': 0.9386539459228516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [16,  6,  6],\n",
       "         [14,  4,  4]],\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [18,  8,  8],\n",
       "         [16,  6,  6]],\n",
       " \n",
       "        [[21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         [21, 18, 19],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8634796142578125, 'inference': 16.275644302368164, 'postprocess': 0.9317398071289062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [22,  7,  8],\n",
       "         [20,  5,  6]],\n",
       " \n",
       "        [[25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [27, 12, 13],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.85394287109375, 'inference': 16.264915466308594, 'postprocess': 0.9424686431884766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8243789672851562, 'inference': 16.293048858642578, 'postprocess': 0.9458065032958984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         [ 6,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         [25, 17, 19],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8258094787597656, 'inference': 16.2656307220459, 'postprocess': 0.9233951568603516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8775463104248047, 'inference': 16.279935836791992, 'postprocess': 0.9305477142333984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9087791442871094, 'inference': 16.288042068481445, 'postprocess': 0.9367465972900391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.893758773803711, 'inference': 16.29328727722168, 'postprocess': 0.9369850158691406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         [10,  2,  4],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [25, 10, 11],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8870830535888672, 'inference': 16.2961483001709, 'postprocess': 0.9584426879882812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32],\n",
       "         [31, 30, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [20,  5,  6],\n",
       "         [18,  3,  4]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [28, 13, 14],\n",
       "         [22,  7,  8],\n",
       "         [21,  6,  7]],\n",
       " \n",
       "        [[24, 21, 22],\n",
       "         [24, 21, 22],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [24,  9, 10],\n",
       "         [23,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.847982406616211, 'inference': 16.2811279296875, 'postprocess': 0.9331703186035156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [26, 14, 16],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9004344940185547, 'inference': 16.285419464111328, 'postprocess': 0.9362697601318359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8908977508544922, 'inference': 16.270160675048828, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8596649169921875, 'inference': 16.278505325317383, 'postprocess': 0.949859619140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8634796142578125, 'inference': 16.278982162475586, 'postprocess': 0.9300708770751953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9059181213378906, 'inference': 16.270875930786133, 'postprocess': 0.9794235229492188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9087791442871094, 'inference': 16.298532485961914, 'postprocess': 0.9546279907226562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9183158874511719, 'inference': 16.27826690673828, 'postprocess': 0.9329319000244141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8515586853027344, 'inference': 16.27969741821289, 'postprocess': 0.9393692016601562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8393993377685547, 'inference': 16.280174255371094, 'postprocess': 0.9405612945556641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.863718032836914, 'inference': 16.2811279296875, 'postprocess': 0.9467601776123047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.912832260131836, 'inference': 16.2811279296875, 'postprocess': 0.9372234344482422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.842498779296875, 'inference': 16.277074813842773, 'postprocess': 0.9350776672363281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 28, 31],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [33, 29, 32],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [18,  6,  8],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8467903137207031, 'inference': 16.26896858215332, 'postprocess': 0.9286403656005859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 21, 23],\n",
       "         [30, 18, 20],\n",
       "         [30, 18, 20]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 22, 24],\n",
       "         [33, 21, 23],\n",
       "         [33, 21, 23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9164085388183594, 'inference': 16.290664672851562, 'postprocess': 0.9706020355224609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [37, 20, 23],\n",
       "         [34, 17, 20],\n",
       "         [34, 17, 20]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [38, 21, 24],\n",
       "         [37, 20, 23],\n",
       "         [37, 20, 23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8761157989501953, 'inference': 16.2811279296875, 'postprocess': 0.9300708770751953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [38, 16, 20],\n",
       "         [35, 13, 17],\n",
       "         [34, 12, 16]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [41, 19, 23],\n",
       "         [38, 16, 20],\n",
       "         [38, 16, 20]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [42, 20, 24],\n",
       "         [41, 19, 23],\n",
       "         [41, 19, 23]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9309520721435547, 'inference': 16.292333602905273, 'postprocess': 0.9751319885253906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.888275146484375, 'inference': 16.292572021484375, 'postprocess': 0.9431838989257812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8727779388427734, 'inference': 16.284942626953125, 'postprocess': 0.9403228759765625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9080638885498047, 'inference': 16.29018783569336, 'postprocess': 0.9293556213378906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8525123596191406, 'inference': 16.275644302368164, 'postprocess': 0.9477138519287109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9197463989257812, 'inference': 16.286373138427734, 'postprocess': 0.9512901306152344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.863718032836914, 'inference': 16.28708839416504, 'postprocess': 0.9903907775878906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9114017486572266, 'inference': 16.289949417114258, 'postprocess': 0.9493827819824219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8680095672607422, 'inference': 16.286611557006836, 'postprocess': 0.9870529174804688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8565654754638672, 'inference': 16.283273696899414, 'postprocess': 0.9398460388183594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8329620361328125, 'inference': 16.278505325317383, 'postprocess': 0.9360313415527344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8711090087890625, 'inference': 16.272306442260742, 'postprocess': 0.9284019470214844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8627643585205078, 'inference': 16.284465789794922, 'postprocess': 0.9315013885498047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8336772918701172, 'inference': 16.272306442260742, 'postprocess': 0.9915828704833984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  1],\n",
       "         [ 4,  0,  1],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [ 9,  3,  6],\n",
       "         [ 9,  4,  5],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[26, 20, 23],\n",
       "         [27, 21, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9245147705078125, 'inference': 16.27802848815918, 'postprocess': 0.9329319000244141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [21,  6,  9],\n",
       "         [20,  5,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12],\n",
       "         [23,  8, 11]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9178390502929688, 'inference': 16.278982162475586, 'postprocess': 0.9267330169677734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [21,  6,  9],\n",
       "         [20,  5,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12],\n",
       "         [23,  8, 11]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8658638000488281, 'inference': 16.274452209472656, 'postprocess': 0.9417533874511719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  9, 12],\n",
       "         [21,  6,  9],\n",
       "         [20,  5,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12],\n",
       "         [23,  8, 11]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8930435180664062, 'inference': 16.286373138427734, 'postprocess': 0.9372234344482422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [20, 10, 12],\n",
       "         [17,  7,  9],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [20, 10, 12],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9419193267822266, 'inference': 16.286611557006836, 'postprocess': 0.9398460388183594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [20, 10, 12],\n",
       "         [17,  7,  9],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [20, 10, 12],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9168853759765625, 'inference': 16.28279685974121, 'postprocess': 0.942230224609375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [18,  8, 10],\n",
       "         [14,  4,  6],\n",
       "         [12,  2,  4]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [20, 10, 12],\n",
       "         [17,  7,  9],\n",
       "         [14,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [19,  9, 11],\n",
       "         [17,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9042491912841797, 'inference': 16.3116455078125, 'postprocess': 0.9365081787109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [18,  8, 10],\n",
       "         [14,  4,  6],\n",
       "         [12,  2,  4]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [20, 10, 12],\n",
       "         [17,  7,  9],\n",
       "         [14,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [19,  9, 11],\n",
       "         [17,  7,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.909017562866211, 'inference': 16.305923461914062, 'postprocess': 0.9334087371826172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9299983978271484, 'inference': 16.280174255371094, 'postprocess': 0.9403228759765625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8575191497802734, 'inference': 16.263961791992188, 'postprocess': 0.9396076202392578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9602775573730469, 'inference': 16.283035278320312, 'postprocess': 0.9579658508300781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [12,  5, 11],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [21, 17, 20],\n",
       "         [26, 19, 25],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9176006317138672, 'inference': 16.27206802368164, 'postprocess': 0.9386539459228516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [12,  5, 11],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [21, 17, 20],\n",
       "         [26, 19, 25],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.920461654663086, 'inference': 16.284942626953125, 'postprocess': 0.9524822235107422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34],\n",
       "         [36, 33, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [16,  6,  8]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [20, 10, 12],\n",
       "         [18,  8, 10]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [24, 14, 16],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8780231475830078, 'inference': 16.2808895111084, 'postprocess': 0.9319782257080078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [36, 16, 20],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [36, 16, 20],\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9412040710449219, 'inference': 16.281843185424805, 'postprocess': 0.9381771087646484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8415451049804688, 'inference': 16.27326011657715, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8575191497802734, 'inference': 16.28732681274414, 'postprocess': 0.9739398956298828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9130706787109375, 'inference': 16.283512115478516, 'postprocess': 0.9515285491943359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9528865814208984, 'inference': 16.275882720947266, 'postprocess': 0.9415149688720703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8045902252197266, 'inference': 16.2966251373291, 'postprocess': 0.9407997131347656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8868446350097656, 'inference': 16.28875732421875, 'postprocess': 0.9350776672363281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8756389617919922, 'inference': 16.274690628051758, 'postprocess': 0.9279251098632812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.893758773803711, 'inference': 16.297101974487305, 'postprocess': 0.9989738464355469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8923282623291016, 'inference': 16.28279685974121, 'postprocess': 0.9317398071289062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8825531005859375, 'inference': 16.29352569580078, 'postprocess': 0.9441375732421875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8868446350097656, 'inference': 16.301870346069336, 'postprocess': 0.9577274322509766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9037723541259766, 'inference': 16.284704208374023, 'postprocess': 0.93841552734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8987655639648438, 'inference': 16.276836395263672, 'postprocess': 0.9393692016601562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9297599792480469, 'inference': 16.289472579956055, 'postprocess': 0.9281635284423828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.865386962890625, 'inference': 16.68381690979004, 'postprocess': 0.9341239929199219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [29,  9, 13],\n",
       "         [25,  5,  9],\n",
       "         [22,  2,  6]],\n",
       " \n",
       "        [[10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         [10,  3,  9],\n",
       "         ...,\n",
       "         [35, 15, 19],\n",
       "         [32, 12, 16],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[21, 14, 20],\n",
       "         [22, 15, 21],\n",
       "         [23, 16, 22],\n",
       "         ...,\n",
       "         [38, 18, 22],\n",
       "         [34, 14, 18],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.913309097290039, 'inference': 16.284704208374023, 'postprocess': 0.9469985961914062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9202232360839844, 'inference': 16.295909881591797, 'postprocess': 0.9238719940185547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.901865005493164, 'inference': 16.284704208374023, 'postprocess': 0.9441375732421875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9152164459228516, 'inference': 16.285419464111328, 'postprocess': 0.9448528289794922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8477439880371094, 'inference': 16.278982162475586, 'postprocess': 0.9415149688720703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9230842590332031, 'inference': 16.280651092529297, 'postprocess': 0.9284019470214844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8792152404785156, 'inference': 16.303062438964844, 'postprocess': 0.9195804595947266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9025802612304688, 'inference': 16.28899574279785, 'postprocess': 0.926971435546875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8432140350341797, 'inference': 16.286373138427734, 'postprocess': 0.9398460388183594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8849372863769531, 'inference': 16.299962997436523, 'postprocess': 0.9272098541259766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8754005432128906, 'inference': 16.31617546081543, 'postprocess': 0.9412765502929688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8985271453857422, 'inference': 16.27039909362793, 'postprocess': 0.9520053863525391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8711090087890625, 'inference': 16.275882720947266, 'postprocess': 0.9388923645019531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [31, 31, 31],\n",
       "         [31, 31, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [23,  5, 10],\n",
       "         [16,  0,  3]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [34, 16, 21],\n",
       "         [31, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8146038055419922, 'inference': 16.277551651000977, 'postprocess': 0.9441375732421875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [27,  9, 14],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[10,  6,  9],\n",
       "         [10,  6,  9],\n",
       "         [ 8,  4,  7],\n",
       "         ...,\n",
       "         [31, 13, 18],\n",
       "         [30, 12, 17],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[18, 14, 17],\n",
       "         [18, 14, 17],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8782615661621094, 'inference': 16.279935836791992, 'postprocess': 0.9281635284423828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [31, 13, 18],\n",
       "         [30, 12, 17],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.890420913696289, 'inference': 16.2966251373291, 'postprocess': 0.942230224609375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8513202667236328, 'inference': 16.275644302368164, 'postprocess': 0.9315013885498047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.920938491821289, 'inference': 16.283035278320312, 'postprocess': 0.9365081787109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8978118896484375, 'inference': 16.28255844116211, 'postprocess': 0.9365081787109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9152164459228516, 'inference': 16.305208206176758, 'postprocess': 0.9300708770751953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8770694732666016, 'inference': 16.277313232421875, 'postprocess': 0.9479522705078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8813610076904297, 'inference': 16.314268112182617, 'postprocess': 0.9253025054931641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8622875213623047, 'inference': 16.29781723022461, 'postprocess': 0.9372234344482422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [26,  8, 13],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [24,  6, 11],\n",
       "         [19,  1,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8916130065917969, 'inference': 16.2813663482666, 'postprocess': 0.9310245513916016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [27,  9, 14],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14],\n",
       "         [24,  6, 11]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [27,  9, 14],\n",
       "         [23,  5, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.936197280883789, 'inference': 16.276836395263672, 'postprocess': 0.9403228759765625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [29, 11, 16],\n",
       "         [30, 12, 17]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [30, 12, 17],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9497871398925781, 'inference': 16.290664672851562, 'postprocess': 0.9381771087646484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [27,  9, 14],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [30, 12, 17],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9233226776123047, 'inference': 16.3271427154541, 'postprocess': 0.9424686431884766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [27,  9, 14],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [30, 12, 17],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8582344055175781, 'inference': 16.279220581054688, 'postprocess': 0.9379386901855469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [27,  9, 14],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16],\n",
       "         [29, 11, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [30, 12, 17],\n",
       "         [29, 11, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9898414611816406, 'inference': 16.29328727722168, 'postprocess': 0.9570121765136719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [24,  6, 11],\n",
       "         [25,  7, 12],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [36, 18, 23],\n",
       "         [36, 18, 23],\n",
       "         [34, 16, 21]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8155574798583984, 'inference': 16.290664672851562, 'postprocess': 0.9505748748779297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [33, 30, 31],\n",
       "         [33, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [20,  7, 11],\n",
       "         [21,  8, 12],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [27, 14, 18],\n",
       "         [27, 14, 18]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [32, 19, 23],\n",
       "         [32, 19, 23],\n",
       "         [30, 17, 21]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9807815551757812, 'inference': 16.29638671875, 'postprocess': 0.9274482727050781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[ 5,  5,  5],\n",
       "         [ 5,  5,  5],\n",
       "         [ 4,  4,  4],\n",
       "         ...,\n",
       "         [32, 20, 22],\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17]],\n",
       " \n",
       "        [[20, 20, 20],\n",
       "         [20, 20, 20],\n",
       "         [20, 20, 20],\n",
       "         ...,\n",
       "         [35, 23, 25],\n",
       "         [32, 20, 22],\n",
       "         [30, 18, 20]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8625259399414062, 'inference': 16.28422737121582, 'postprocess': 0.9407997131347656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [32, 20, 22],\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9202232360839844, 'inference': 16.28851890563965, 'postprocess': 0.9386539459228516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [32, 20, 22],\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9235610961914062, 'inference': 16.275882720947266, 'postprocess': 0.9393692016601562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [32, 20, 22],\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8885135650634766, 'inference': 16.280412673950195, 'postprocess': 1.0006427764892578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [32, 20, 22],\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8646717071533203, 'inference': 16.275882720947266, 'postprocess': 0.9429454803466797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 14, 17],\n",
       "         [25, 10, 13],\n",
       "         [24,  9, 12]],\n",
       " \n",
       "        [[ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [31, 16, 19],\n",
       "         [28, 13, 16],\n",
       "         [27, 12, 15]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [34, 19, 22],\n",
       "         [31, 16, 19],\n",
       "         [28, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8966197967529297, 'inference': 16.281604766845703, 'postprocess': 0.9510517120361328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [24,  7, 10],\n",
       "         [23,  6,  9]],\n",
       " \n",
       "        [[11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.867055892944336, 'inference': 16.287803649902344, 'postprocess': 0.9450912475585938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [24,  7, 10],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.898050308227539, 'inference': 16.28708839416504, 'postprocess': 1.0046958923339844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         [ 1,  1,  1],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [24,  7, 10],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         [11, 11, 11],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         [25, 25, 25],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8796920776367188, 'inference': 16.2966251373291, 'postprocess': 0.9825229644775391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [24,  7, 10],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9049644470214844, 'inference': 16.318798065185547, 'postprocess': 0.9427070617675781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9252300262451172, 'inference': 16.29185676574707, 'postprocess': 0.9365081787109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9068717956542969, 'inference': 16.289949417114258, 'postprocess': 0.9417533874511719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         [ 8,  8,  8],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         [22, 22, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.922607421875, 'inference': 16.29352569580078, 'postprocess': 0.93841552734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [30, 14, 19],\n",
       "         [28, 12, 17]],\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [31, 15, 20],\n",
       "         [28, 12, 17]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [35, 19, 24],\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9168853759765625, 'inference': 16.283512115478516, 'postprocess': 0.9400844573974609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8935203552246094, 'inference': 16.269683837890625, 'postprocess': 0.942230224609375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8880367279052734, 'inference': 16.284465789794922, 'postprocess': 0.9725093841552734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9216537475585938, 'inference': 16.286134719848633, 'postprocess': 0.9396076202392578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8770694732666016, 'inference': 16.28565788269043, 'postprocess': 0.9493827819824219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.867055892944336, 'inference': 16.283035278320312, 'postprocess': 0.9458065032958984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9068717956542969, 'inference': 16.295433044433594, 'postprocess': 0.9396076202392578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8873214721679688, 'inference': 16.275882720947266, 'postprocess': 0.942230224609375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9071102142333984, 'inference': 16.295909881591797, 'postprocess': 0.9415149688720703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [31, 11, 13],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [34, 14, 16],\n",
       "         [32, 12, 14],\n",
       "         [28,  8, 10]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [33, 13, 15],\n",
       "         [29,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.871347427368164, 'inference': 16.281604766845703, 'postprocess': 0.9458065032958984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8961429595947266, 'inference': 16.29638671875, 'postprocess': 0.9467601776123047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [19, 16, 17],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9061565399169922, 'inference': 16.28851890563965, 'postprocess': 0.9400844573974609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 7,  4,  5],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9223690032958984, 'inference': 16.289949417114258, 'postprocess': 0.9469985961914062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 7,  4,  5],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9502639770507812, 'inference': 16.299009323120117, 'postprocess': 0.9453296661376953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8889904022216797, 'inference': 16.288280487060547, 'postprocess': 0.9467601776123047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [28, 13, 14],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8889904022216797, 'inference': 16.269922256469727, 'postprocess': 0.9489059448242188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [29, 14, 15],\n",
       "         [25, 10, 11],\n",
       "         [23,  8,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [28, 13, 14],\n",
       "         [25, 10, 11]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 16, 17],\n",
       "         [28, 13, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9137859344482422, 'inference': 16.300678253173828, 'postprocess': 0.9334087371826172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9593238830566406, 'inference': 16.2961483001709, 'postprocess': 0.9365081787109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [27, 15, 17]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.966238021850586, 'inference': 16.286134719848633, 'postprocess': 0.9491443634033203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [38, 35, 34],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [27, 15, 17]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9054412841796875, 'inference': 16.285419464111328, 'postprocess': 1.0154247283935547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [27, 15, 17]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9230842590332031, 'inference': 16.297578811645508, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.888275146484375, 'inference': 16.29042625427246, 'postprocess': 0.9951591491699219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.905202865600586, 'inference': 16.30115509033203, 'postprocess': 0.9355545043945312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9066333770751953, 'inference': 16.29042625427246, 'postprocess': 1.0030269622802734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [34, 14, 18],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9521713256835938, 'inference': 16.289710998535156, 'postprocess': 0.9396076202392578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [34, 14, 18],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8525123596191406, 'inference': 16.272544860839844, 'postprocess': 0.9429454803466797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [34, 14, 18],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9774436950683594, 'inference': 16.285181045532227, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [34, 14, 18],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8396377563476562, 'inference': 16.284704208374023, 'postprocess': 0.9553432464599609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [34, 14, 18],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8908977508544922, 'inference': 16.29161834716797, 'postprocess': 0.9558200836181641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         [ 8,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         [15, 12, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8541812896728516, 'inference': 16.27063751220703, 'postprocess': 0.9448528289794922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9168853759765625, 'inference': 16.283035278320312, 'postprocess': 0.9424686431884766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9004344940185547, 'inference': 16.286134719848633, 'postprocess': 0.9639263153076172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [26,  9, 12],\n",
       "         [23,  6,  9]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9016265869140625, 'inference': 16.291379928588867, 'postprocess': 0.9391307830810547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         [ 8,  3,  4],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         [21, 16, 17],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8475055694580078, 'inference': 16.276836395263672, 'postprocess': 0.9493827819824219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 4,  0,  1],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [12,  6,  9],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [24, 18, 21],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8916130065917969, 'inference': 16.32094383239746, 'postprocess': 0.9360313415527344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8529891967773438, 'inference': 16.299962997436523, 'postprocess': 0.9560585021972656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9004344940185547, 'inference': 16.29638671875, 'postprocess': 0.9443759918212891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8622875213623047, 'inference': 16.299962997436523, 'postprocess': 0.942230224609375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8601417541503906, 'inference': 16.295433044433594, 'postprocess': 0.9870529174804688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8696784973144531, 'inference': 16.286373138427734, 'postprocess': 0.9598731994628906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9719600677490234, 'inference': 16.297340393066406, 'postprocess': 0.9522438049316406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [33, 11, 15],\n",
       "         [31,  9, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [34, 12, 16],\n",
       "         [33, 11, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [34, 12, 16],\n",
       "         [34, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8818378448486328, 'inference': 16.29328727722168, 'postprocess': 0.9486675262451172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [33, 11, 15],\n",
       "         [31,  9, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [34, 12, 16],\n",
       "         [33, 11, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [34, 12, 16],\n",
       "         [34, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9202232360839844, 'inference': 16.290903091430664, 'postprocess': 0.9446144104003906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [33, 11, 15],\n",
       "         [31,  9, 13]],\n",
       " \n",
       "        [[10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         [10,  4,  7],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [34, 12, 16],\n",
       "         [33, 11, 15]],\n",
       " \n",
       "        [[23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         [23, 17, 20],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [35, 13, 17],\n",
       "         [35, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8877983093261719, 'inference': 16.289949417114258, 'postprocess': 0.9531974792480469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [33, 11, 15],\n",
       "         [31,  9, 13]],\n",
       " \n",
       "        [[10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [34, 12, 16],\n",
       "         [33, 11, 15]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         ...,\n",
       "         [36, 14, 18],\n",
       "         [35, 13, 17],\n",
       "         [35, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9309520721435547, 'inference': 16.301870346069336, 'postprocess': 0.9362697601318359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.964569091796875, 'inference': 16.281604766845703, 'postprocess': 0.9503364562988281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [36, 33, 32],\n",
       "         [34, 31, 30],\n",
       "         [32, 29, 28]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 32, 31],\n",
       "         [34, 31, 30],\n",
       "         [33, 30, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         [23, 18, 19],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9147396087646484, 'inference': 16.28875732421875, 'postprocess': 0.9791851043701172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         [ 1,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[11,  3,  5],\n",
       "         [11,  3,  5],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[24, 16, 18],\n",
       "         [24, 16, 18],\n",
       "         [24, 16, 18],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9488334655761719, 'inference': 16.2966251373291, 'postprocess': 0.9367465972900391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8906593322753906, 'inference': 16.282320022583008, 'postprocess': 0.9388923645019531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.905202865600586, 'inference': 16.289949417114258, 'postprocess': 0.9417533874511719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8990039825439453, 'inference': 16.29471778869629, 'postprocess': 0.9407997131347656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [31, 11, 15],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17],\n",
       "         [33, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8796920776367188, 'inference': 16.290903091430664, 'postprocess': 0.9334087371826172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [33, 11, 15],\n",
       "         [31,  9, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [34, 12, 16],\n",
       "         [34, 12, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [35, 13, 17],\n",
       "         [35, 13, 17],\n",
       "         [35, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8925666809082031, 'inference': 16.336679458618164, 'postprocess': 0.9357929229736328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.905202865600586, 'inference': 16.290664672851562, 'postprocess': 0.9558200836181641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 11, 15],\n",
       "         [28,  8, 12],\n",
       "         [28,  8, 12]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 11, 15],\n",
       "         [29,  9, 13],\n",
       "         [29,  9, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16],\n",
       "         [32, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9690990447998047, 'inference': 16.288042068481445, 'postprocess': 0.9391307830810547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.901865005493164, 'inference': 16.298770904541016, 'postprocess': 0.957489013671875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9593238830566406, 'inference': 16.29495620727539, 'postprocess': 0.9474754333496094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19],\n",
       "         [33, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 2.0055770874023438, 'inference': 16.283512115478516, 'postprocess': 0.9481906890869141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9023418426513672, 'inference': 16.292333602905273, 'postprocess': 0.9670257568359375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16],\n",
       "         [30, 13, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8897056579589844, 'inference': 16.322612762451172, 'postprocess': 0.9377002716064453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9659996032714844, 'inference': 16.291379928588867, 'postprocess': 0.9644031524658203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8851757049560547, 'inference': 16.29018783569336, 'postprocess': 0.9510517120361328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.909494400024414, 'inference': 16.296863555908203, 'postprocess': 0.9598731994628906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9657611846923828, 'inference': 16.310453414916992, 'postprocess': 0.9541511535644531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.913309097290039, 'inference': 16.286134719848633, 'postprocess': 0.9613037109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9011497497558594, 'inference': 16.2961483001709, 'postprocess': 0.9565353393554688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8916130065917969, 'inference': 16.293048858642578, 'postprocess': 0.9579658508300781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9142627716064453, 'inference': 16.29781723022461, 'postprocess': 0.9512901306152344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 13, 16],\n",
       "         [29, 12, 15],\n",
       "         [27, 10, 13]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17],\n",
       "         [31, 14, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9009113311767578, 'inference': 16.2961483001709, 'postprocess': 0.9446144104003906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 10, 18],\n",
       "         [26,  7, 15],\n",
       "         [25,  6, 14]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [30, 11, 19],\n",
       "         [29, 10, 18],\n",
       "         [27,  8, 16]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [31, 12, 20],\n",
       "         [31, 12, 20],\n",
       "         [31, 12, 20]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9068717956542969, 'inference': 16.307353973388672, 'postprocess': 0.9548664093017578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [24,  7, 10],\n",
       "         [19,  2,  5]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [23,  6,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.871347427368164, 'inference': 16.292095184326172, 'postprocess': 0.9441375732421875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [24,  7, 10],\n",
       "         [19,  2,  5]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [23,  6,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9047260284423828, 'inference': 16.317367553710938, 'postprocess': 0.995635986328125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [24,  7, 10],\n",
       "         [20,  3,  6]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [23,  6,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9571781158447266, 'inference': 16.312599182128906, 'postprocess': 0.9479522705078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [24,  7, 10],\n",
       "         [20,  3,  6]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [23,  6,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9373893737792969, 'inference': 16.300678253173828, 'postprocess': 0.9520053863525391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [24,  7, 10],\n",
       "         [20,  3,  6]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [25,  8, 11],\n",
       "         [22,  5,  8]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 16, 19],\n",
       "         [27, 10, 13],\n",
       "         [23,  6,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9385814666748047, 'inference': 16.305923461914062, 'postprocess': 0.9453296661376953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [27, 10, 13],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [36, 19, 22],\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [38, 21, 24],\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9233226776123047, 'inference': 16.303062438964844, 'postprocess': 0.9524822235107422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [34, 17, 20],\n",
       "         [27, 10, 13],\n",
       "         [24,  7, 10]],\n",
       " \n",
       "        [[15,  7,  9],\n",
       "         [15,  7,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [36, 19, 22],\n",
       "         [30, 13, 16],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[28, 20, 22],\n",
       "         [28, 20, 22],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [38, 21, 24],\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9001960754394531, 'inference': 16.316652297973633, 'postprocess': 0.9453296661376953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8875598907470703, 'inference': 16.339540481567383, 'postprocess': 0.9477138519287109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.905679702758789, 'inference': 16.308069229125977, 'postprocess': 0.9572505950927734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9028186798095703, 'inference': 16.301870346069336, 'postprocess': 0.9560585021972656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [35, 20, 21],\n",
       "         [30, 15, 16],\n",
       "         [29, 14, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9061565399169922, 'inference': 16.305923461914062, 'postprocess': 0.9582042694091797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9245147705078125, 'inference': 16.298294067382812, 'postprocess': 0.9496212005615234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9142627716064453, 'inference': 16.303062438964844, 'postprocess': 0.9469985961914062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9059181213378906, 'inference': 16.335487365722656, 'postprocess': 0.9500980377197266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.89971923828125, 'inference': 16.315937042236328, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9536018371582031, 'inference': 16.30401611328125, 'postprocess': 0.9627342224121094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9009113311767578, 'inference': 16.309261322021484, 'postprocess': 0.9915828704833984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9354820251464844, 'inference': 16.31307601928711, 'postprocess': 0.9405612945556641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9483566284179688, 'inference': 16.311168670654297, 'postprocess': 1.0936260223388672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         [10,  7,  8],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9927024841308594, 'inference': 16.307353973388672, 'postprocess': 0.9913444519042969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[18, 15, 16],\n",
       "         [18, 15, 16],\n",
       "         [18, 15, 16],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9173622131347656, 'inference': 16.299962997436523, 'postprocess': 0.9403228759765625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[18, 15, 16],\n",
       "         [18, 15, 16],\n",
       "         [18, 15, 16],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9066333770751953, 'inference': 16.326904296875, 'postprocess': 0.9553432464599609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[29, 26, 27],\n",
       "         [29, 26, 27],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.920938491821289, 'inference': 16.301631927490234, 'postprocess': 0.9441375732421875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[29, 26, 27],\n",
       "         [29, 26, 27],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9559860229492188, 'inference': 16.3116455078125, 'postprocess': 0.9694099426269531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[29, 26, 27],\n",
       "         [29, 26, 27],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8393993377685547, 'inference': 16.324281692504883, 'postprocess': 0.9942054748535156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9376277923583984, 'inference': 16.337156295776367, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9543170928955078, 'inference': 16.311168670654297, 'postprocess': 0.9391307830810547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8987655639648438, 'inference': 16.302108764648438, 'postprocess': 1.3325214385986328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8763542175292969, 'inference': 16.324281692504883, 'postprocess': 0.9405612945556641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8415451049804688, 'inference': 16.298532485961914, 'postprocess': 0.9596347808837891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9142627716064453, 'inference': 16.326189041137695, 'postprocess': 0.9565353393554688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [28, 13, 14],\n",
       "         [27, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.888275146484375, 'inference': 16.306161880493164, 'postprocess': 0.9593963623046875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8982887268066406, 'inference': 16.29781723022461, 'postprocess': 0.9496212005615234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.926422119140625, 'inference': 16.30258560180664, 'postprocess': 0.9467601776123047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8949508666992188, 'inference': 16.330480575561523, 'postprocess': 0.9441375732421875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 19, 15],\n",
       "         [28, 15, 11],\n",
       "         [27, 14, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9335746765136719, 'inference': 16.293048858642578, 'postprocess': 0.9500980377197266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34],\n",
       "         [35, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         ...,\n",
       "         [32, 17, 20],\n",
       "         [28, 13, 16],\n",
       "         [27, 12, 15]],\n",
       " \n",
       "        [[12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         [12,  9, 10],\n",
       "         ...,\n",
       "         [32, 17, 20],\n",
       "         [28, 13, 16],\n",
       "         [27, 12, 15]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         ...,\n",
       "         [32, 17, 20],\n",
       "         [28, 13, 16],\n",
       "         [27, 12, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8894672393798828, 'inference': 16.299724578857422, 'postprocess': 0.9336471557617188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9333362579345703, 'inference': 16.29161834716797, 'postprocess': 0.9377002716064453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8770694732666016, 'inference': 16.318798065185547, 'postprocess': 0.934600830078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9032955169677734, 'inference': 16.390085220336914, 'postprocess': 0.9810924530029297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8322467803955078, 'inference': 16.310453414916992, 'postprocess': 0.9427070617675781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8968582153320312, 'inference': 16.310691833496094, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.903533935546875, 'inference': 16.312122344970703, 'postprocess': 0.949859619140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.912832260131836, 'inference': 16.30115509033203, 'postprocess': 0.95367431640625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.895904541015625, 'inference': 16.30568504333496, 'postprocess': 0.9243488311767578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9817352294921875, 'inference': 16.300678253173828, 'postprocess': 0.9477138519287109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9345283508300781, 'inference': 16.325950622558594, 'postprocess': 0.946044921875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9106864929199219, 'inference': 16.312360763549805, 'postprocess': 0.9436607360839844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9562244415283203, 'inference': 16.29924774169922, 'postprocess': 0.988006591796875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30],\n",
       "         [32, 32, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [30, 12, 17],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9521713256835938, 'inference': 16.308069229125977, 'postprocess': 0.9558200836181641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.897573471069336, 'inference': 16.31784439086914, 'postprocess': 0.946044921875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9462108612060547, 'inference': 16.29805564880371, 'postprocess': 0.9465217590332031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9495487213134766, 'inference': 16.315460205078125, 'postprocess': 0.9400844573974609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8885135650634766, 'inference': 16.332626342773438, 'postprocess': 0.9386539459228516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9297599792480469, 'inference': 16.310691833496094, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [26, 13, 17],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9571781158447266, 'inference': 16.30568504333496, 'postprocess': 0.9436607360839844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8987655639648438, 'inference': 16.31903648376465, 'postprocess': 0.9989738464355469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9702911376953125, 'inference': 16.29781723022461, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.897573471069336, 'inference': 16.292095184326172, 'postprocess': 0.9515285491943359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9702911376953125, 'inference': 16.29948616027832, 'postprocess': 0.9527206420898438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8858909606933594, 'inference': 16.304731369018555, 'postprocess': 0.9527206420898438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9009113311767578, 'inference': 16.311168670654297, 'postprocess': 0.9469985961914062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9049644470214844, 'inference': 16.30115509033203, 'postprocess': 0.9546279907226562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8970966339111328, 'inference': 16.314983367919922, 'postprocess': 0.9582042694091797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8908977508544922, 'inference': 16.2966251373291, 'postprocess': 0.9543895721435547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9078254699707031, 'inference': 16.299724578857422, 'postprocess': 0.9491443634033203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  0,  1],\n",
       "         [ 7,  0,  1],\n",
       "         [ 8,  0,  2],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [30, 12, 17],\n",
       "         [26,  8, 13]],\n",
       " \n",
       "        [[12,  4,  6],\n",
       "         [12,  4,  6],\n",
       "         [11,  3,  5],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[17,  9, 11],\n",
       "         [17,  9, 11],\n",
       "         [18, 10, 12],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8906593322753906, 'inference': 16.301870346069336, 'postprocess': 1.0099411010742188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8994808197021484, 'inference': 16.29948616027832, 'postprocess': 0.9503364562988281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8818378448486328, 'inference': 16.30258560180664, 'postprocess': 0.9503364562988281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9605159759521484, 'inference': 16.298294067382812, 'postprocess': 0.9450912475585938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8887519836425781, 'inference': 16.340255737304688, 'postprocess': 0.9467601776123047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.905679702758789, 'inference': 16.2961483001709, 'postprocess': 0.934600830078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.882791519165039, 'inference': 16.324758529663086, 'postprocess': 0.9434223175048828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8987655639648438, 'inference': 16.30568504333496, 'postprocess': 0.9446144104003906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9075870513916016, 'inference': 16.306400299072266, 'postprocess': 0.9474754333496094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [31, 14, 17],\n",
       "         [27, 10, 13],\n",
       "         [25,  8, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9497871398925781, 'inference': 16.313552856445312, 'postprocess': 0.9739398956298828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9328594207763672, 'inference': 16.29161834716797, 'postprocess': 0.9477138519287109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8703937530517578, 'inference': 16.326189041137695, 'postprocess': 0.9794235229492188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9474029541015625, 'inference': 16.308069229125977, 'postprocess': 0.93841552734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30],\n",
       "         [36, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]],\n",
       " \n",
       "        [[17, 12, 13],\n",
       "         [17, 12, 13],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [32, 15, 18],\n",
       "         [29, 12, 15],\n",
       "         [26,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8994808197021484, 'inference': 16.301631927490234, 'postprocess': 0.9698867797851562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9130706787109375, 'inference': 16.29948616027832, 'postprocess': 0.9362697601318359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.893758773803711, 'inference': 16.312837600708008, 'postprocess': 0.9517669677734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 15, 16],\n",
       "         [27, 12, 13],\n",
       "         [24,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8801689147949219, 'inference': 16.307353973388672, 'postprocess': 0.9746551513671875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 15, 20],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9276142120361328, 'inference': 16.310453414916992, 'postprocess': 0.9434223175048828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [31, 15, 20],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [27, 11, 16],\n",
       "         [24,  8, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.926422119140625, 'inference': 16.298294067382812, 'postprocess': 0.9481906890869141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.931905746459961, 'inference': 16.316652297973633, 'postprocess': 0.9486675262451172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9497871398925781, 'inference': 16.30234718322754, 'postprocess': 0.9443759918212891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9216537475585938, 'inference': 16.31331443786621, 'postprocess': 0.9474754333496094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9364356994628906, 'inference': 16.309499740600586, 'postprocess': 0.9443759918212891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.928091049194336, 'inference': 16.298770904541016, 'postprocess': 0.9477138519287109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.898050308227539, 'inference': 16.29638671875, 'postprocess': 0.9429454803466797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        [[40, 40, 40],\n",
       "         [40, 40, 40],\n",
       "         [39, 39, 39],\n",
       "         ...,\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30],\n",
       "         [34, 31, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9102096557617188, 'inference': 16.309499740600586, 'postprocess': 1.0929107666015625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [25,  9, 14],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [29, 13, 18],\n",
       "         [27, 11, 16]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [34, 18, 23],\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8115043640136719, 'inference': 16.34502410888672, 'postprocess': 0.9505748748779297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [21,  5, 10],\n",
       "         [17,  1,  6]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [28, 12, 17],\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [28, 12, 17],\n",
       "         [25,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9068717956542969, 'inference': 16.301870346069336, 'postprocess': 0.9391307830810547},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [21,  5, 10],\n",
       "         [17,  1,  6]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [28, 12, 17],\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [28, 12, 17],\n",
       "         [25,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8935203552246094, 'inference': 16.338825225830078, 'postprocess': 0.9493827819824219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [21,  5, 10],\n",
       "         [17,  1,  6]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [28, 12, 17],\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [28, 12, 17],\n",
       "         [25,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9540786743164062, 'inference': 16.31307601928711, 'postprocess': 0.9636878967285156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        [[40, 39, 41],\n",
       "         [40, 39, 41],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32],\n",
       "         [34, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [25,  9, 14],\n",
       "         [21,  5, 10],\n",
       "         [17,  1,  6]],\n",
       " \n",
       "        [[15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [28, 12, 17],\n",
       "         [24,  8, 13],\n",
       "         [22,  6, 11]],\n",
       " \n",
       "        [[28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         [28, 23, 24],\n",
       "         ...,\n",
       "         [30, 14, 19],\n",
       "         [28, 12, 17],\n",
       "         [25,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9724369049072266, 'inference': 16.303062438964844, 'postprocess': 0.9908676147460938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8990039825439453, 'inference': 16.32237434387207, 'postprocess': 0.9551048278808594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9664764404296875, 'inference': 16.29924774169922, 'postprocess': 0.9522438049316406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.974344253540039, 'inference': 16.31617546081543, 'postprocess': 0.9953975677490234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9116401672363281, 'inference': 16.298770904541016, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9626617431640625, 'inference': 16.313791275024414, 'postprocess': 0.9508132934570312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9004344940185547, 'inference': 16.306638717651367, 'postprocess': 0.9541511535644531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9173622131347656, 'inference': 16.327857971191406, 'postprocess': 0.9531974792480469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9257068634033203, 'inference': 16.317367553710938, 'postprocess': 0.9424686431884766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9478797912597656, 'inference': 16.318321228027344, 'postprocess': 0.9474754333496094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8963813781738281, 'inference': 16.329526901245117, 'postprocess': 0.9393692016601562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8088817596435547, 'inference': 16.347408294677734, 'postprocess': 0.9436607360839844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.917123794555664, 'inference': 16.3114070892334, 'postprocess': 0.9438991546630859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9063949584960938, 'inference': 16.30258560180664, 'postprocess': 0.9477138519287109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.894235610961914, 'inference': 16.299724578857422, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9104480743408203, 'inference': 16.309499740600586, 'postprocess': 0.988006591796875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.903533935546875, 'inference': 16.31474494934082, 'postprocess': 0.9825229644775391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8985271453857422, 'inference': 16.303062438964844, 'postprocess': 0.9980201721191406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9397735595703125, 'inference': 16.320466995239258, 'postprocess': 0.9465217590332031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8901824951171875, 'inference': 16.307830810546875, 'postprocess': 0.9398460388183594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8858909606933594, 'inference': 16.305208206176758, 'postprocess': 0.9489059448242188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9009113311767578, 'inference': 16.28851890563965, 'postprocess': 0.9469985961914062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8837451934814453, 'inference': 16.319990158081055, 'postprocess': 0.9334087371826172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8970966339111328, 'inference': 16.29781723022461, 'postprocess': 0.9477138519287109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9423961639404297, 'inference': 16.30687713623047, 'postprocess': 0.9779930114746094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.886129379272461, 'inference': 16.326904296875, 'postprocess': 0.9932518005371094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.878976821899414, 'inference': 16.340970993041992, 'postprocess': 1.0223388671875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.89208984375, 'inference': 16.31903648376465, 'postprocess': 1.0068416595458984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 12, 16],\n",
       "         [16,  3,  7],\n",
       "         [13,  0,  4]],\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [21,  8, 12],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9824504852294922, 'inference': 16.344308853149414, 'postprocess': 0.9579658508300781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [30, 17, 21],\n",
       "         [23, 10, 14],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [32, 19, 23],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[22, 17, 18],\n",
       "         [22, 17, 18],\n",
       "         [23, 18, 19],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8947124481201172, 'inference': 16.303300857543945, 'postprocess': 0.9732246398925781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [32, 19, 23],\n",
       "         [25, 12, 16],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[10,  5,  6],\n",
       "         [10,  5,  6],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [32, 19, 23],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[22, 17, 18],\n",
       "         [22, 17, 18],\n",
       "         [23, 18, 19],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [29, 16, 20],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9488334655761719, 'inference': 16.31021499633789, 'postprocess': 0.9398460388183594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.897573471069336, 'inference': 16.320228576660156, 'postprocess': 0.9396076202392578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9309520721435547, 'inference': 16.300201416015625, 'postprocess': 0.9441375732421875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [23, 11, 13],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.940011978149414, 'inference': 16.313552856445312, 'postprocess': 0.9558200836181641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9502639770507812, 'inference': 16.301393508911133, 'postprocess': 0.9472370147705078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9037723541259766, 'inference': 16.30115509033203, 'postprocess': 0.9620189666748047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8928050994873047, 'inference': 16.31760597229004, 'postprocess': 0.9415149688720703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8913745880126953, 'inference': 16.29948616027832, 'postprocess': 0.9503364562988281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9316673278808594, 'inference': 16.295433044433594, 'postprocess': 0.9403228759765625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         [14, 10, 13],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9533634185791016, 'inference': 16.31021499633789, 'postprocess': 0.9639263153076172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [18, 14, 17],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8885135650634766, 'inference': 16.34359359741211, 'postprocess': 0.9739398956298828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9032955169677734, 'inference': 16.29161834716797, 'postprocess': 0.9579658508300781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.94549560546875, 'inference': 16.294479370117188, 'postprocess': 0.9520053863525391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34],\n",
       "         [37, 31, 34]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [22, 10, 12],\n",
       "         [21,  9, 11]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [17, 13, 16],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.863241195678711, 'inference': 16.312122344970703, 'postprocess': 0.9572505950927734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [21, 17, 20],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [30, 18, 20],\n",
       "         [32, 20, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8889904022216797, 'inference': 16.295433044433594, 'postprocess': 0.9334087371826172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]],\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [21, 17, 20],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [30, 18, 20],\n",
       "         [32, 20, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8978118896484375, 'inference': 16.303062438964844, 'postprocess': 0.9570121765136719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  2],\n",
       "         [ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 3,  0,  2],\n",
       "         [ 3,  0,  2],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18],\n",
       "         [28, 16, 18]],\n",
       " \n",
       "        [[25, 21, 24],\n",
       "         [26, 22, 25],\n",
       "         [28, 24, 27],\n",
       "         ...,\n",
       "         [30, 18, 20],\n",
       "         [30, 18, 20],\n",
       "         [32, 20, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9004344940185547, 'inference': 16.315937042236328, 'postprocess': 0.9658336639404297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [23, 15, 17]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [24, 16, 18],\n",
       "         [24, 16, 18]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [22, 18, 21],\n",
       "         [25, 21, 24],\n",
       "         ...,\n",
       "         [26, 18, 20],\n",
       "         [26, 18, 20],\n",
       "         [28, 20, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.970052719116211, 'inference': 16.345500946044922, 'postprocess': 0.995635986328125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [21, 13, 15],\n",
       "         [21, 13, 15]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [22, 18, 21],\n",
       "         [25, 21, 24],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [25, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.882314682006836, 'inference': 16.309738159179688, 'postprocess': 0.9748935699462891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         [ 4,  0,  3],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [21, 13, 15],\n",
       "         [21, 13, 15]],\n",
       " \n",
       "        [[ 7,  3,  6],\n",
       "         [ 6,  2,  5],\n",
       "         [ 5,  1,  4],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16]],\n",
       " \n",
       "        [[21, 17, 20],\n",
       "         [22, 18, 21],\n",
       "         [25, 21, 24],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [25, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9006729125976562, 'inference': 16.31450653076172, 'postprocess': 0.9627342224121094},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [21, 13, 15],\n",
       "         [21, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [25, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.889944076538086, 'inference': 16.300678253173828, 'postprocess': 0.9469985961914062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [21, 13, 15],\n",
       "         [21, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [25, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9016265869140625, 'inference': 16.31021499633789, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [21, 13, 15],\n",
       "         [21, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16],\n",
       "         [22, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [24, 16, 18],\n",
       "         [23, 15, 17],\n",
       "         [25, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8908977508544922, 'inference': 16.303300857543945, 'postprocess': 0.9360313415527344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [29, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.920938491821289, 'inference': 16.302824020385742, 'postprocess': 0.95367431640625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [29, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.96075439453125, 'inference': 16.29352569580078, 'postprocess': 0.9407997131347656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [29, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9025802612304688, 'inference': 16.30425453186035, 'postprocess': 0.9613037109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [29, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9016265869140625, 'inference': 16.321659088134766, 'postprocess': 0.9489059448242188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9490718841552734, 'inference': 16.306161880493164, 'postprocess': 0.9715557098388672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [22, 10, 12],\n",
       "         [20,  8, 10],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13],\n",
       "         [26, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8849372863769531, 'inference': 16.30544662475586, 'postprocess': 0.946044921875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [28, 16, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8072128295898438, 'inference': 16.297340393066406, 'postprocess': 0.9672641754150391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [34, 28, 31],\n",
       "         [34, 28, 31]],\n",
       " \n",
       "        [[37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         [37, 36, 38],\n",
       "         ...,\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32],\n",
       "         [35, 29, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 2,  0,  1],\n",
       "         [ 2,  0,  1],\n",
       "         [ 5,  0,  2],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [23, 11, 13],\n",
       "         [22, 10, 12]],\n",
       " \n",
       "        [[ 4,  0,  3],\n",
       "         [ 4,  0,  3],\n",
       "         [ 6,  0,  3],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [25, 13, 15],\n",
       "         [26, 14, 16]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [30, 24, 27],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [26, 14, 16],\n",
       "         [28, 16, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8854141235351562, 'inference': 16.297578811645508, 'postprocess': 0.9493827819824219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [27, 12, 15],\n",
       "         [25, 10, 13],\n",
       "         [27, 12, 15]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [29, 14, 17],\n",
       "         [29, 14, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [31, 16, 19],\n",
       "         [30, 15, 18],\n",
       "         [31, 16, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.918792724609375, 'inference': 16.312122344970703, 'postprocess': 0.9512901306152344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [23, 11, 13],\n",
       "         [25, 13, 15]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [27, 15, 17],\n",
       "         [27, 15, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [28, 16, 18],\n",
       "         [29, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8982887268066406, 'inference': 16.29495620727539, 'postprocess': 0.9455680847167969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [23, 13, 15]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [25, 15, 17],\n",
       "         [25, 15, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [26, 16, 18],\n",
       "         [27, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8875598907470703, 'inference': 16.302824020385742, 'postprocess': 0.9512901306152344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [23, 13, 15]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [25, 15, 17],\n",
       "         [25, 15, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [26, 16, 18],\n",
       "         [27, 17, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9316673278808594, 'inference': 16.315221786499023, 'postprocess': 0.9465217590332031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8935203552246094, 'inference': 16.30115509033203, 'postprocess': 0.946044921875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9032955169677734, 'inference': 16.31641387939453, 'postprocess': 0.9374618530273438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.93023681640625, 'inference': 16.315221786499023, 'postprocess': 0.9832382202148438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.936197280883789, 'inference': 16.300678253173828, 'postprocess': 0.9415149688720703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.940011978149414, 'inference': 16.326904296875, 'postprocess': 0.9503364562988281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9042491912841797, 'inference': 16.29328727722168, 'postprocess': 0.9407997131347656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8849372863769531, 'inference': 16.308069229125977, 'postprocess': 0.9622573852539062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 6,  3,  4],\n",
       "         [ 5,  2,  3],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [18,  8, 10],\n",
       "         [19,  9, 11]],\n",
       " \n",
       "        [[ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         [ 6,  3,  4],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13],\n",
       "         [21, 11, 13]],\n",
       " \n",
       "        [[19, 16, 17],\n",
       "         [19, 16, 17],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9021034240722656, 'inference': 16.317129135131836, 'postprocess': 0.9479522705078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  4,  4],\n",
       "         [ 4,  4,  4],\n",
       "         [ 3,  3,  3],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [23, 13, 15],\n",
       "         [24, 14, 16]],\n",
       " \n",
       "        [[ 5,  5,  5],\n",
       "         [ 5,  5,  5],\n",
       "         [ 4,  4,  4],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [25, 15, 17],\n",
       "         [26, 16, 18]],\n",
       " \n",
       "        [[17, 17, 17],\n",
       "         [17, 17, 17],\n",
       "         [18, 18, 18],\n",
       "         ...,\n",
       "         [28, 18, 20],\n",
       "         [27, 17, 19],\n",
       "         [28, 18, 20]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9679069519042969, 'inference': 16.30854606628418, 'postprocess': 0.9555816650390625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13],\n",
       "         [24, 14, 14]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [25, 15, 15],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [26, 16, 16],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9993782043457031, 'inference': 16.30115509033203, 'postprocess': 0.9446144104003906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8725395202636719, 'inference': 16.299724578857422, 'postprocess': 0.9608268737792969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9059181213378906, 'inference': 16.308069229125977, 'postprocess': 0.9450912475585938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.905679702758789, 'inference': 16.30997657775879, 'postprocess': 0.9708404541015625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8978118896484375, 'inference': 16.323566436767578, 'postprocess': 0.9613037109375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8987655639648438, 'inference': 16.305208206176758, 'postprocess': 0.957489013671875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 11, 16],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [29, 13, 18],\n",
       "         [28, 12, 17],\n",
       "         [29, 13, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9321441650390625, 'inference': 16.321420669555664, 'postprocess': 1.0960102081298828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 11, 16],\n",
       "         [27, 11, 16],\n",
       "         [28, 12, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [29, 13, 18],\n",
       "         [28, 12, 17],\n",
       "         [29, 13, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [32, 16, 21],\n",
       "         [30, 14, 19],\n",
       "         [30, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9152164459228516, 'inference': 16.295671463012695, 'postprocess': 0.9541511535644531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         [26, 23, 24],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9135475158691406, 'inference': 16.301393508911133, 'postprocess': 0.9548664093017578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [12,  9, 10],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [29, 26, 27],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8982887268066406, 'inference': 16.30258560180664, 'postprocess': 0.9558200836181641},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [23, 12, 16],\n",
       "         [24, 13, 17]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [12,  9, 10],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [24, 13, 17],\n",
       "         [25, 14, 18]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [29, 26, 27],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [26, 15, 19],\n",
       "         [26, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9042491912841797, 'inference': 16.304969787597656, 'postprocess': 0.9899139404296875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13],\n",
       "         [24, 14, 14]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [12,  9, 10],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [25, 15, 15],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [29, 26, 27],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9083023071289062, 'inference': 16.294002532958984, 'postprocess': 0.9691715240478516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13],\n",
       "         [24, 14, 14]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [12,  9, 10],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [25, 15, 15],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [29, 26, 27],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9216537475585938, 'inference': 16.315937042236328, 'postprocess': 0.9577274322509766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  3,  4],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13],\n",
       "         [24, 14, 14]],\n",
       " \n",
       "        [[13, 10, 11],\n",
       "         [12,  9, 10],\n",
       "         [11,  8,  9],\n",
       "         ...,\n",
       "         [25, 15, 15],\n",
       "         [25, 15, 15],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[31, 28, 29],\n",
       "         [31, 28, 29],\n",
       "         [29, 26, 27],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.89208984375, 'inference': 16.336679458618164, 'postprocess': 0.9720325469970703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [31, 11, 13],\n",
       "         [31, 11, 13],\n",
       "         [32, 12, 14]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [33, 13, 15],\n",
       "         [33, 13, 15],\n",
       "         [34, 14, 16]],\n",
       " \n",
       "        [[28, 25, 26],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [35, 15, 17],\n",
       "         [35, 15, 17],\n",
       "         [35, 15, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8918514251708984, 'inference': 16.303539276123047, 'postprocess': 0.9541511535644531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [22, 10, 10],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 13, 13],\n",
       "         [23, 11, 11],\n",
       "         [25, 13, 13]],\n",
       " \n",
       "        [[28, 25, 26],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8770694732666016, 'inference': 16.30568504333496, 'postprocess': 1.0004043579101562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [22, 10, 10],\n",
       "         [23, 11, 11]],\n",
       " \n",
       "        [[ 8,  5,  6],\n",
       "         [ 7,  4,  5],\n",
       "         [ 7,  4,  5],\n",
       "         ...,\n",
       "         [25, 13, 13],\n",
       "         [23, 11, 11],\n",
       "         [25, 13, 13]],\n",
       " \n",
       "        [[28, 25, 26],\n",
       "         [27, 24, 25],\n",
       "         [27, 24, 25],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [26, 14, 14],\n",
       "         [26, 14, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8894672393798828, 'inference': 16.295909881591797, 'postprocess': 0.9658336639404297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8243789672851562, 'inference': 16.294240951538086, 'postprocess': 0.9641647338867188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9023418426513672, 'inference': 16.31331443786621, 'postprocess': 0.9484291076660156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9690990447998047, 'inference': 16.30425453186035, 'postprocess': 0.9906291961669922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9392967224121094, 'inference': 16.331911087036133, 'postprocess': 0.9491443634033203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9216537475585938, 'inference': 16.3118839263916, 'postprocess': 0.9672641754150391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9195079803466797, 'inference': 16.309022903442383, 'postprocess': 0.9300708770751953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9211769104003906, 'inference': 16.309261322021484, 'postprocess': 0.949859619140625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8832683563232422, 'inference': 16.32547378540039, 'postprocess': 0.9412765502929688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [21, 11, 11],\n",
       "         [23, 13, 13],\n",
       "         [23, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8916130065917969, 'inference': 16.305208206176758, 'postprocess': 0.965118408203125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [24, 14, 14],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [26, 16, 16],\n",
       "         [27, 17, 17]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8846988677978516, 'inference': 16.31760597229004, 'postprocess': 0.9517669677734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [24, 14, 14],\n",
       "         [26, 16, 16]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [26, 16, 16],\n",
       "         [27, 17, 17]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [26, 16, 16],\n",
       "         [27, 17, 17],\n",
       "         [27, 17, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8849372863769531, 'inference': 16.310691833496094, 'postprocess': 0.9539127349853516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [24, 12, 19],\n",
       "         [26, 14, 21]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [26, 14, 21],\n",
       "         [27, 15, 22]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [27, 15, 22],\n",
       "         [27, 15, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8968582153320312, 'inference': 16.3114070892334, 'postprocess': 0.9388923645019531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  1,  2],\n",
       "         [ 4,  1,  2],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [24, 12, 19],\n",
       "         [26, 14, 21]],\n",
       " \n",
       "        [[14, 11, 12],\n",
       "         [14, 11, 12],\n",
       "         [13, 10, 11],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [26, 14, 21],\n",
       "         [27, 15, 22]],\n",
       " \n",
       "        [[25, 22, 23],\n",
       "         [25, 22, 23],\n",
       "         [24, 21, 22],\n",
       "         ...,\n",
       "         [26, 14, 21],\n",
       "         [27, 15, 22],\n",
       "         [27, 15, 22]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9083023071289062, 'inference': 16.3116455078125, 'postprocess': 0.9448528289794922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         [15, 10, 11],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.943826675415039, 'inference': 16.312122344970703, 'postprocess': 0.9436607360839844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[35, 30, 31],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9047260284423828, 'inference': 16.310453414916992, 'postprocess': 0.9529590606689453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[14,  9, 10],\n",
       "         [14,  9, 10],\n",
       "         [12,  7,  8],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[24, 19, 20],\n",
       "         [24, 19, 20],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[35, 30, 31],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9686222076416016, 'inference': 16.307592391967773, 'postprocess': 0.9458065032958984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[22, 17, 18],\n",
       "         [22, 17, 18],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[26, 21, 22],\n",
       "         [26, 21, 22],\n",
       "         [22, 17, 18],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         [31, 26, 27],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9431114196777344, 'inference': 16.297578811645508, 'postprocess': 0.9508132934570312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[33, 28, 29],\n",
       "         [33, 28, 29],\n",
       "         [31, 26, 27],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[40, 35, 36],\n",
       "         [40, 35, 36],\n",
       "         [38, 33, 34],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[40, 35, 36],\n",
       "         [40, 35, 36],\n",
       "         [40, 35, 36],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9102096557617188, 'inference': 16.307592391967773, 'postprocess': 0.9446144104003906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[40, 35, 36],\n",
       "         [40, 35, 36],\n",
       "         [40, 35, 36],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[38, 33, 34],\n",
       "         [38, 33, 34],\n",
       "         [38, 33, 34],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[38, 33, 34],\n",
       "         [38, 33, 34],\n",
       "         [38, 33, 34],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9214153289794922, 'inference': 16.3116455078125, 'postprocess': 0.9431838989257812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [25, 12, 16],\n",
       "         [26, 13, 17]],\n",
       " \n",
       "        [[35, 30, 31],\n",
       "         [35, 30, 31],\n",
       "         [35, 30, 31],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]],\n",
       " \n",
       "        [[36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [35, 30, 31],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [28, 15, 19],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9333362579345703, 'inference': 16.309022903442383, 'postprocess': 0.9443759918212891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8887519836425781, 'inference': 16.304731369018555, 'postprocess': 0.957489013671875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         [34, 29, 30],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8949508666992188, 'inference': 16.31927490234375, 'postprocess': 0.9496212005615234},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[40, 30, 32],\n",
       "         [40, 30, 32],\n",
       "         [40, 30, 32],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[41, 31, 33],\n",
       "         [41, 31, 33],\n",
       "         [41, 31, 33],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[41, 31, 33],\n",
       "         [41, 31, 33],\n",
       "         [41, 31, 33],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.941680908203125, 'inference': 16.319990158081055, 'postprocess': 0.9551048278808594},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8985271453857422, 'inference': 16.300678253173828, 'postprocess': 0.9427070617675781},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33],\n",
       "         [35, 32, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.89208984375, 'inference': 16.30997657775879, 'postprocess': 0.9381771087646484},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8963813781738281, 'inference': 16.310691833496094, 'postprocess': 0.9338855743408203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8749237060546875, 'inference': 16.29805564880371, 'postprocess': 0.9541511535644531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9614696502685547, 'inference': 16.30115509033203, 'postprocess': 0.9446144104003906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8839836120605469, 'inference': 16.314029693603516, 'postprocess': 0.9758472442626953},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36],\n",
       "         [35, 30, 36]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19],\n",
       "         [29, 16, 20]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [33, 20, 24],\n",
       "         [30, 17, 21],\n",
       "         [28, 15, 19]],\n",
       " \n",
       "        [[37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         [37, 27, 29],\n",
       "         ...,\n",
       "         [35, 22, 26],\n",
       "         [30, 17, 21],\n",
       "         [27, 14, 18]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8863677978515625, 'inference': 16.30258560180664, 'postprocess': 0.946044921875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[33, 23, 25],\n",
       "         [33, 23, 25],\n",
       "         [34, 24, 26],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [24,  9, 12],\n",
       "         [25, 10, 13]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [35, 20, 23],\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8994808197021484, 'inference': 16.29781723022461, 'postprocess': 0.93841552734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 24, 26],\n",
       "         [34, 24, 26],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [22,  7, 10],\n",
       "         [24,  9, 12],\n",
       "         [25, 10, 13]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [27, 12, 15],\n",
       "         [24,  9, 12]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [35, 20, 23],\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8851757049560547, 'inference': 16.30234718322754, 'postprocess': 0.9353160858154297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 24, 26],\n",
       "         [34, 24, 26],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [20,  5,  8],\n",
       "         [23,  8, 11],\n",
       "         [23,  8, 11]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [28, 13, 16],\n",
       "         [24,  9, 12],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [32, 17, 20],\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.901388168334961, 'inference': 16.303300857543945, 'postprocess': 0.9284019470214844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 24, 26],\n",
       "         [34, 24, 26],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.89971923828125, 'inference': 16.303300857543945, 'postprocess': 0.9355545043945312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 24, 26],\n",
       "         [34, 24, 26],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9016265869140625, 'inference': 16.30234718322754, 'postprocess': 0.9491443634033203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33],\n",
       "         [33, 33, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[34, 24, 26],\n",
       "         [34, 24, 26],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         [35, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         [38, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9114017486572266, 'inference': 16.297340393066406, 'postprocess': 0.9450912475585938},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9383430480957031, 'inference': 16.29805564880371, 'postprocess': 0.9403228759765625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8856525421142578, 'inference': 16.283035278320312, 'postprocess': 0.9741783142089844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.890420913696289, 'inference': 16.3118839263916, 'postprocess': 0.9434223175048828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9719600677490234, 'inference': 16.2811279296875, 'postprocess': 0.9424686431884766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [22,  7, 10],\n",
       "         [22,  7, 10]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9032955169677734, 'inference': 16.291379928588867, 'postprocess': 0.9479522705078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [21,  6,  9],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9030570983886719, 'inference': 16.315937042236328, 'postprocess': 0.9393692016601562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         [32, 24, 26],\n",
       "         ...,\n",
       "         [17,  2,  5],\n",
       "         [21,  6,  9],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         [33, 25, 27],\n",
       "         ...,\n",
       "         [25, 10, 13],\n",
       "         [22,  7, 10],\n",
       "         [21,  6,  9]],\n",
       " \n",
       "        [[36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         [36, 28, 30],\n",
       "         ...,\n",
       "         [30, 15, 18],\n",
       "         [23,  8, 11],\n",
       "         [20,  5,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9087791442871094, 'inference': 16.29042625427246, 'postprocess': 0.946044921875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9292831420898438, 'inference': 16.28851890563965, 'postprocess': 0.9410381317138672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9147396087646484, 'inference': 16.293048858642578, 'postprocess': 0.9443759918212891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.89208984375, 'inference': 16.3118839263916, 'postprocess': 1.0077953338623047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [20,  8, 10]],\n",
       " \n",
       "        [[32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8954277038574219, 'inference': 16.312360763549805, 'postprocess': 0.9441375732421875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         [32, 28, 31],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.895904541015625, 'inference': 16.302108764648438, 'postprocess': 0.9553432464599609},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[28, 24, 27],\n",
       "         [28, 24, 27],\n",
       "         [27, 23, 26],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[29, 25, 28],\n",
       "         [29, 25, 28],\n",
       "         [29, 25, 28],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8868446350097656, 'inference': 16.315698623657227, 'postprocess': 0.9517669677734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[28, 24, 27],\n",
       "         [28, 24, 27],\n",
       "         [27, 23, 26],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[29, 25, 28],\n",
       "         [29, 25, 28],\n",
       "         [29, 25, 28],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         [31, 27, 30],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9783973693847656, 'inference': 16.30544662475586, 'postprocess': 0.9477138519287109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[24, 20, 23],\n",
       "         [24, 20, 23],\n",
       "         [22, 18, 21],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[25, 21, 24],\n",
       "         [25, 21, 24],\n",
       "         [25, 21, 24],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[27, 23, 26],\n",
       "         [27, 23, 26],\n",
       "         [26, 22, 25],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8966197967529297, 'inference': 16.31760597229004, 'postprocess': 0.9448528289794922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[20, 16, 19],\n",
       "         [20, 16, 19],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[22, 18, 21],\n",
       "         [22, 18, 21],\n",
       "         [21, 17, 20],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[25, 21, 24],\n",
       "         [25, 21, 24],\n",
       "         [24, 20, 23],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9156932830810547, 'inference': 16.30258560180664, 'postprocess': 0.9670257568359375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[13,  9, 12],\n",
       "         [13,  9, 12],\n",
       "         [13,  9, 12],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8949508666992188, 'inference': 16.318798065185547, 'postprocess': 0.9517669677734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9428730010986328, 'inference': 16.315221786499023, 'postprocess': 0.9577274322509766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.886606216430664, 'inference': 16.309738159179688, 'postprocess': 0.9694099426269531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [27, 15, 17],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [21,  9, 11],\n",
       "         [16,  4,  6]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [25, 13, 15],\n",
       "         [21,  9, 11],\n",
       "         [18,  6,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.888275146484375, 'inference': 16.30687713623047, 'postprocess': 0.9615421295166016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.934051513671875, 'inference': 16.291141510009766, 'postprocess': 0.9489059448242188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9271373748779297, 'inference': 16.3114070892334, 'postprocess': 0.9520053863525391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9063949584960938, 'inference': 16.308069229125977, 'postprocess': 0.9527206420898438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [29, 29, 29],\n",
       "         [26, 26, 26]],\n",
       " \n",
       "        [[39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         [39, 38, 40],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [30, 30, 30],\n",
       "         [27, 27, 27]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         [11,  7, 10],\n",
       "         ...,\n",
       "         [26, 14, 16],\n",
       "         [20,  8, 10],\n",
       "         [15,  3,  5]],\n",
       " \n",
       "        [[15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         [15, 11, 14],\n",
       "         ...,\n",
       "         [28, 16, 18],\n",
       "         [23, 11, 13],\n",
       "         [19,  7,  9]],\n",
       " \n",
       "        [[19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         [19, 15, 18],\n",
       "         ...,\n",
       "         [29, 17, 19],\n",
       "         [26, 14, 16],\n",
       "         [22, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8999576568603516, 'inference': 16.314029693603516, 'postprocess': 0.9934902191162109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9350051879882812, 'inference': 16.317367553710938, 'postprocess': 0.9486675262451172},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.890420913696289, 'inference': 16.333341598510742, 'postprocess': 0.9353160858154297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         [13,  8,  9],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         [16, 11, 12],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         [19, 14, 15],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8963813781738281, 'inference': 16.294479370117188, 'postprocess': 0.9934902191162109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9516944885253906, 'inference': 16.28708839416504, 'postprocess': 0.9429454803466797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9769668579101562, 'inference': 16.29185676574707, 'postprocess': 0.9636878967285156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9474029541015625, 'inference': 16.326904296875, 'postprocess': 0.9770393371582031},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9717216491699219, 'inference': 16.321897506713867, 'postprocess': 0.9813308715820312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.943349838256836, 'inference': 16.295433044433594, 'postprocess': 0.9505748748779297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.886606216430664, 'inference': 16.2966251373291, 'postprocess': 0.9489059448242188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8432140350341797, 'inference': 16.32523536682129, 'postprocess': 0.95367431640625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.947164535522461, 'inference': 16.299724578857422, 'postprocess': 0.9522438049316406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.898050308227539, 'inference': 16.298294067382812, 'postprocess': 0.9500980377197266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 6,  1,  2],\n",
       "         [ 6,  1,  2],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [19,  8, 12],\n",
       "         [15,  2,  6],\n",
       "         [14,  1,  5]],\n",
       " \n",
       "        [[ 9,  4,  5],\n",
       "         [ 9,  4,  5],\n",
       "         [10,  5,  6],\n",
       "         ...,\n",
       "         [25, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[27, 22, 23],\n",
       "         [27, 22, 23],\n",
       "         [26, 21, 22],\n",
       "         ...,\n",
       "         [26, 15, 19],\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9176006317138672, 'inference': 16.30258560180664, 'postprocess': 0.9484291076660156},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8863677978515625, 'inference': 16.29161834716797, 'postprocess': 0.9567737579345703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         [ 7,  2,  3],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         [20, 15, 16],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9028186798095703, 'inference': 16.293048858642578, 'postprocess': 0.9582042694091797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9068717956542969, 'inference': 16.45040512084961, 'postprocess': 0.9980201721191406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8863677978515625, 'inference': 16.30258560180664, 'postprocess': 0.9715557098388672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8968582153320312, 'inference': 16.307353973388672, 'postprocess': 0.9448528289794922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9593238830566406, 'inference': 16.307353973388672, 'postprocess': 0.9660720825195312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 12, 16],\n",
       "         [19,  6, 10],\n",
       "         [16,  3,  7]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 16, 20],\n",
       "         [25, 12, 16],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 17, 21],\n",
       "         [27, 14, 18],\n",
       "         [25, 12, 16]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9061565399169922, 'inference': 16.29328727722168, 'postprocess': 0.9529590606689453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [19,  7,  7],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [25, 13, 13],\n",
       "         [22, 10, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [27, 15, 15],\n",
       "         [25, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.93023681640625, 'inference': 16.301870346069336, 'postprocess': 0.9491443634033203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13, 13],\n",
       "         [19,  7,  7],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [27, 17, 17],\n",
       "         [25, 13, 13],\n",
       "         [22, 10, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [28, 18, 18],\n",
       "         [27, 15, 15],\n",
       "         [25, 13, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9326210021972656, 'inference': 16.294479370117188, 'postprocess': 0.9570121765136719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9674301147460938, 'inference': 16.301393508911133, 'postprocess': 0.9517669677734375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8923282623291016, 'inference': 16.377925872802734, 'postprocess': 0.9572505950927734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9464492797851562, 'inference': 16.28398895263672, 'postprocess': 0.9546279907226562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33],\n",
       "         [36, 30, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8656253814697266, 'inference': 16.31307601928711, 'postprocess': 0.9515285491943359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9161701202392578, 'inference': 16.28875732421875, 'postprocess': 0.9560585021972656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8985271453857422, 'inference': 16.2966251373291, 'postprocess': 0.9429454803466797},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 2.051115036010742, 'inference': 16.302108764648438, 'postprocess': 0.9570121765136719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        [[38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         [38, 38, 38],\n",
       "         ...,\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33],\n",
       "         [32, 31, 33]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 12, 13],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         [ 7,  3,  0],\n",
       "         ...,\n",
       "         [31, 16, 17],\n",
       "         [29, 12, 13],\n",
       "         [26,  9, 10]],\n",
       " \n",
       "        [[20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         [20, 16, 12],\n",
       "         ...,\n",
       "         [32, 17, 18],\n",
       "         [31, 14, 15],\n",
       "         [29, 12, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 2.0062923431396484, 'inference': 16.30854606628418, 'postprocess': 0.9913444519042969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [25,  8,  9],\n",
       "         [20,  3,  4],\n",
       "         [18,  1,  2]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [29, 12, 13],\n",
       "         [24,  7,  8],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [27, 10, 11],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9071102142333984, 'inference': 16.295433044433594, 'postprocess': 0.9663105010986328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [22,  5,  6],\n",
       "         [19,  2,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [25,  8,  9],\n",
       "         [23,  6,  7]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [32, 15, 16],\n",
       "         [27, 10, 11],\n",
       "         [26,  9, 10]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9266605377197266, 'inference': 16.312599182128906, 'postprocess': 0.9593963623046875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  5,  6],\n",
       "         [17,  0,  1],\n",
       "         [15,  0,  0]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [25,  8,  9],\n",
       "         [19,  2,  3],\n",
       "         [17,  0,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [20,  3,  4]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9147396087646484, 'inference': 16.331911087036133, 'postprocess': 0.9491443634033203},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  5,  6],\n",
       "         [17,  0,  1],\n",
       "         [15,  0,  0]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [25,  8,  9],\n",
       "         [19,  2,  3],\n",
       "         [17,  0,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [20,  3,  4]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9068717956542969, 'inference': 16.337871551513672, 'postprocess': 0.95367431640625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [22,  5,  6],\n",
       "         [17,  0,  1],\n",
       "         [15,  0,  0]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [25,  8,  9],\n",
       "         [19,  2,  3],\n",
       "         [17,  0,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [20,  3,  4]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9307136535644531, 'inference': 16.300678253173828, 'postprocess': 0.9477138519287109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [19,  2,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.935720443725586, 'inference': 16.302824020385742, 'postprocess': 0.9620189666748047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [19,  2,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9271373748779297, 'inference': 16.29042625427246, 'postprocess': 0.9539127349853516},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [20,  3,  4],\n",
       "         [18,  1,  2]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9717216491699219, 'inference': 16.32070541381836, 'postprocess': 1.0328292846679688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [20,  3,  4],\n",
       "         [19,  2,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9850730895996094, 'inference': 16.286611557006836, 'postprocess': 0.9489059448242188},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [20,  3,  4]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [20,  3,  4],\n",
       "         [19,  2,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9173622131347656, 'inference': 16.301393508911133, 'postprocess': 0.9634494781494141},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [19,  2,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9142627716064453, 'inference': 16.300439834594727, 'postprocess': 0.9672641754150391},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  9, 10],\n",
       "         [22,  5,  6],\n",
       "         [19,  2,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.909017562866211, 'inference': 16.33167266845703, 'postprocess': 0.9455680847167969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [22,  4,  9],\n",
       "         [19,  1,  6]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         ...,\n",
       "         [27,  9, 14],\n",
       "         [23,  5, 10],\n",
       "         [22,  4,  9]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [30, 12, 17],\n",
       "         [25,  7, 12],\n",
       "         [24,  6, 11]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.898050308227539, 'inference': 16.290903091430664, 'postprocess': 0.9562969207763672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [34, 16, 21],\n",
       "         [25,  7, 12],\n",
       "         [22,  4,  9]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [36, 18, 23],\n",
       "         [27,  9, 14],\n",
       "         [24,  6, 11]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [36, 18, 23],\n",
       "         [29, 11, 16],\n",
       "         [25,  7, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9772052764892578, 'inference': 16.299724578857422, 'postprocess': 0.9827613830566406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [19,  6, 10],\n",
       "         [18,  5,  9]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [21,  8, 12],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [21,  8, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9259452819824219, 'inference': 16.294002532958984, 'postprocess': 0.9531974792480469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [19,  6, 10],\n",
       "         [18,  5,  9]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [21,  8, 12],\n",
       "         [20,  7, 11]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [22,  9, 13],\n",
       "         [21,  8, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9257068634033203, 'inference': 16.30878448486328, 'postprocess': 0.9477138519287109},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 13,  8],\n",
       "         [19,  9,  4],\n",
       "         [18,  8,  3]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 16, 11],\n",
       "         [21, 11,  6],\n",
       "         [20, 10,  5]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 17, 12],\n",
       "         [22, 12,  7],\n",
       "         [21, 11,  6]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8875598907470703, 'inference': 16.309022903442383, 'postprocess': 0.95367431640625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [19,  7,  7],\n",
       "         [18,  6,  6]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [21,  9,  9],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [22, 10, 10],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8892288208007812, 'inference': 16.297101974487305, 'postprocess': 0.9653568267822266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [19,  7,  7],\n",
       "         [18,  6,  6]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [21,  9,  9],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [22, 10, 10],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9719600677490234, 'inference': 16.30115509033203, 'postprocess': 0.9872913360595703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         [ 0,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [19,  7,  7],\n",
       "         [18,  6,  6]],\n",
       " \n",
       "        [[ 6,  1,  0],\n",
       "         [ 6,  1,  0],\n",
       "         [ 5,  0,  0],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [21,  9,  9],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [22, 10, 10],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9154548645019531, 'inference': 16.297578811645508, 'postprocess': 0.9829998016357422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9140243530273438, 'inference': 16.284704208374023, 'postprocess': 0.9670257568359375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9176006317138672, 'inference': 16.306161880493164, 'postprocess': 0.9589195251464844},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9817352294921875, 'inference': 16.30568504333496, 'postprocess': 0.957489013671875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9085407257080078, 'inference': 16.29924774169922, 'postprocess': 0.9596347808837891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9028186798095703, 'inference': 16.295909881591797, 'postprocess': 0.9670257568359375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9173622131347656, 'inference': 16.324520111083984, 'postprocess': 0.9775161743164062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9099712371826172, 'inference': 16.307592391967773, 'postprocess': 0.9555816650390625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32],\n",
       "         [32, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8296241760253906, 'inference': 16.294240951538086, 'postprocess': 0.9567737579345703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 10, 11],\n",
       "         [23,  6,  7],\n",
       "         [22,  5,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [30, 13, 14],\n",
       "         [25,  8,  9],\n",
       "         [24,  7,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [31, 14, 15],\n",
       "         [26,  9, 10],\n",
       "         [25,  8,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9299983978271484, 'inference': 16.298294067382812, 'postprocess': 0.9567737579345703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        [[37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         [37, 37, 37],\n",
       "         ...,\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32],\n",
       "         [36, 31, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [19,  7,  7],\n",
       "         [18,  6,  6]],\n",
       " \n",
       "        [[ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         [ 5,  0,  1],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [21,  9,  9],\n",
       "         [20,  8,  8]],\n",
       " \n",
       "        [[29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         [29, 24, 25],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [22, 10, 10],\n",
       "         [21,  9,  9]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9483566284179688, 'inference': 16.309261322021484, 'postprocess': 0.957489013671875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9295215606689453, 'inference': 16.30091667175293, 'postprocess': 0.9529590606689453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9068717956542969, 'inference': 16.310453414916992, 'postprocess': 0.9362697601318359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [33, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [38, 33, 34],\n",
       "         [35, 30, 31],\n",
       "         [34, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 2.027750015258789, 'inference': 16.33739471435547, 'postprocess': 0.9601116180419922},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.913309097290039, 'inference': 16.294479370117188, 'postprocess': 0.9419918060302734},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9145011901855469, 'inference': 16.308307647705078, 'postprocess': 1.0137557983398438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9195079803466797, 'inference': 16.301870346069336, 'postprocess': 0.9548664093017578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9192695617675781, 'inference': 16.328096389770508, 'postprocess': 0.9524822235107422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.917123794555664, 'inference': 16.292810440063477, 'postprocess': 0.9808540344238281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9283294677734375, 'inference': 16.307592391967773, 'postprocess': 0.9565353393554688},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [23, 13, 15],\n",
       "         [18,  8, 10],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [25, 15, 17],\n",
       "         [21, 11, 13],\n",
       "         [20, 10, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [23, 13, 15],\n",
       "         [21, 11, 13]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.928091049194336, 'inference': 16.28708839416504, 'postprocess': 0.9889602661132812},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [18,  8, 10],\n",
       "         [10,  0,  2],\n",
       "         [ 6,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [13,  3,  5],\n",
       "         [10,  0,  2]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [16,  6,  8],\n",
       "         [12,  2,  4]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9385814666748047, 'inference': 16.29328727722168, 'postprocess': 0.9851455688476562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [18,  8, 10],\n",
       "         [10,  0,  2],\n",
       "         [ 6,  0,  0]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [19,  9, 11],\n",
       "         [13,  3,  5],\n",
       "         [10,  0,  2]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [21, 11, 13],\n",
       "         [16,  6,  8],\n",
       "         [12,  2,  4]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9042491912841797, 'inference': 16.342878341674805, 'postprocess': 0.9546279907226562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         [33, 36, 36],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [24, 14, 16],\n",
       "         [17,  7,  9],\n",
       "         [13,  3,  5]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [26, 16, 18],\n",
       "         [20, 10, 12],\n",
       "         [17,  7,  9]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [27, 17, 19],\n",
       "         [23, 13, 15],\n",
       "         [20, 10, 12]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.918792724609375, 'inference': 16.298294067382812, 'postprocess': 0.9620189666748047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9485950469970703, 'inference': 16.32094383239746, 'postprocess': 0.9446144104003906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.935720443725586, 'inference': 16.289472579956055, 'postprocess': 0.9529590606689453},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9145011901855469, 'inference': 16.306161880493164, 'postprocess': 0.9467601776123047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [21,  8, 12],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [27, 14, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9199848175048828, 'inference': 16.303539276123047, 'postprocess': 1.0111331939697266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9354820251464844, 'inference': 16.31307601928711, 'postprocess': 0.9622573852539062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8832683563232422, 'inference': 16.331911087036133, 'postprocess': 0.9593963623046875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9078254699707031, 'inference': 16.322851181030273, 'postprocess': 0.9458065032958984},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [31, 13, 18],\n",
       "         [31, 13, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [33, 15, 20],\n",
       "         [32, 14, 19],\n",
       "         [32, 14, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9061565399169922, 'inference': 16.297578811645508, 'postprocess': 0.9531974792480469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [21,  8, 12],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [27, 14, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8591880798339844, 'inference': 16.30878448486328, 'postprocess': 1.0020732879638672},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [22,  9, 13],\n",
       "         [21,  8, 12],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [28, 15, 19],\n",
       "         [27, 14, 18],\n",
       "         [27, 14, 18]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [29, 16, 20],\n",
       "         [28, 15, 19],\n",
       "         [28, 15, 19]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8513202667236328, 'inference': 16.295433044433594, 'postprocess': 0.9503364562988281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [19,  6, 10],\n",
       "         [18,  5,  9],\n",
       "         [18,  5,  9]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [21,  8, 12],\n",
       "         [21,  8, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [26, 13, 17],\n",
       "         [23, 10, 14],\n",
       "         [23, 10, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.9214153289794922, 'inference': 16.304969787597656, 'postprocess': 0.9479522705078125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [20,  7, 11],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [22,  9, 13],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [26, 13, 17],\n",
       "         [26, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.920461654663086, 'inference': 16.293048858642578, 'postprocess': 0.9443759918212891},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [20,  7, 11],\n",
       "         [19,  6, 10],\n",
       "         [19,  6, 10]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [23, 10, 14],\n",
       "         [22,  9, 13],\n",
       "         [22,  9, 13]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [27, 14, 18],\n",
       "         [26, 13, 17],\n",
       "         [26, 13, 17]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8939971923828125, 'inference': 16.302824020385742, 'postprocess': 0.9415149688720703},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [24,  6, 11],\n",
       "         [23,  5, 10],\n",
       "         [23,  5, 10]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8575191497802734, 'inference': 16.30234718322754, 'postprocess': 0.95367431640625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [25,  7, 12],\n",
       "         [24,  6, 11],\n",
       "         [24,  6, 11]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.911163330078125, 'inference': 16.295909881591797, 'postprocess': 0.9512901306152344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [25,  7, 12],\n",
       "         [24,  6, 11],\n",
       "         [24,  6, 11]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8963813781738281, 'inference': 16.29805564880371, 'postprocess': 0.9577274322509766},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [31, 28, 29]],\n",
       " \n",
       "        [[38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         [38, 37, 39],\n",
       "         ...,\n",
       "         [36, 33, 34],\n",
       "         [33, 30, 31],\n",
       "         [32, 29, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         [ 3,  0,  1],\n",
       "         ...,\n",
       "         [25,  7, 12],\n",
       "         [24,  6, 11],\n",
       "         [24,  6, 11]],\n",
       " \n",
       "        [[ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         [ 2,  0,  0],\n",
       "         ...,\n",
       "         [29, 11, 16],\n",
       "         [26,  8, 13],\n",
       "         [25,  7, 12]],\n",
       " \n",
       "        [[20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         [20, 17, 18],\n",
       "         ...,\n",
       "         [32, 14, 19],\n",
       "         [29, 11, 16],\n",
       "         [27,  9, 14]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8486976623535156, 'inference': 16.309499740600586, 'postprocess': 0.9357929229736328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32],\n",
       "         [29, 32, 32]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [25, 13, 13],\n",
       "         [18,  6,  6],\n",
       "         [14,  2,  2]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [27, 15, 15],\n",
       "         [20,  8,  8],\n",
       "         [16,  4,  4]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [29, 17, 17],\n",
       "         [23, 11, 11],\n",
       "         [19,  7,  7]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8641948699951172, 'inference': 16.29948616027832, 'postprocess': 1.0333061218261719},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [21,  9,  9],\n",
       "         [14,  2,  2],\n",
       "         [11,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [16,  4,  4],\n",
       "         [13,  1,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [20,  8,  8],\n",
       "         [15,  3,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.8343925476074219, 'inference': 16.28279685974121, 'postprocess': 0.9493827819824219},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [15,  3,  3],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [16,  4,  4],\n",
       "         [13,  1,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [20,  8,  8],\n",
       "         [15,  3,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 1.847982406616211, 'inference': 16.30854606628418, 'postprocess': 0.957489013671875},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'people', 1: 'peopleWithWheelchair'}\n",
       " obb: None\n",
       " orig_img: array([[[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [27, 30, 30],\n",
       "         [26, 29, 29],\n",
       "         [26, 29, 29]],\n",
       " \n",
       "        [[40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         [40, 37, 38],\n",
       "         ...,\n",
       "         [28, 31, 31],\n",
       "         [27, 30, 30],\n",
       "         [27, 30, 30]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [22, 10, 10],\n",
       "         [15,  3,  3],\n",
       "         [12,  0,  0]],\n",
       " \n",
       "        [[ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         [ 4,  0,  0],\n",
       "         ...,\n",
       "         [23, 11, 11],\n",
       "         [16,  4,  4],\n",
       "         [13,  1,  1]],\n",
       " \n",
       "        [[22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         [22, 17, 16],\n",
       "         ...,\n",
       "         [26, 14, 14],\n",
       "         [20,  8,  8],\n",
       "         [15,  3,  3]]], dtype=uint8)\n",
       " orig_shape: (1080, 1920)\n",
       " path: '/home/vtoscano/VToscano/GA_M24/yolov8/../GAM24_video.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs/detect/predict2'\n",
       " speed: {'preprocess': 2.062559127807617, 'inference': 16.298532485961914, 'postprocess': 0.9307861328125}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmodel.predict(\"../GAM24_video.mp4\",save=True,imgsz=640,conf=0.4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
